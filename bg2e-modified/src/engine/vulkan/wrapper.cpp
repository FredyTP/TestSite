/*
*	bg2 engine license
*	Copyright (c) 2016 Fernando Serrano <ferserc1@gmail.com>
*
*	Permission is hereby granted, free of charge, to any person obtaining a copy
*	of this software and associated documentation files (the "Software"), to deal
*	in the Software without restriction, including without limitation the rights
*	to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
*	of the Software, and to permit persons to whom the Software is furnished to do
*	so, subject to the following conditions:
*
*	The above copyright notice and this permission notice shall be included in all
*	copies or substantial portions of the Software.
*
*	THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
*	INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A
*	PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
*	HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
*	OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
*	SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
*
*/

#include <bg/platform.hpp>
#include <bg/engine.hpp>
#include <bg/base/exception.hpp>

#include <array>

#if BG2E_WINDOWS==1

#define VK_USE_PLATFORM_WIN32_KHR 
#include <vulkan/vulkan.h>

#ifndef WIN32
#define WIN32
#endif
#include <WinSock2.h>
#include <Windows.h>

#include <bg/wnd/win32_window.hpp>
#include <bg/wnd/window_controller.hpp>

#ifdef max
#undef max
#endif

#ifdef min
#undef min
#endif

#elif BG2E_MAC==1

#include <vulkan/vulkan.h>
#define VK_KHR_WIN32_SURFACE_EXTENSION_NAME ""

#include <vulkan/vulkan_macos.h>

#include <bg/wnd/cocoa_window.hpp>
#include <bg/wnd/cocoa_mvk_context.hpp>

#elif BG2E_IOS==1

#include <vulkan/vulkan.h>
#define VK_KHR_WIN32_SURFACE_EXTENSION_NAME ""

#elif BG2E_ANDROID==1

#include <vulkan/vulkan.h>
#define VK_KHR_WIN32_SURFACE_EXTENSION_NAME ""

#endif

#include <bg/platform.hpp>

#include <bg/engine/vulkan/wrapper.hpp>

namespace bg {
namespace engine {
namespace vulkan {

namespace vk {

const uint32_t SUCCESS = VK_SUCCESS;
const uint32_t NOT_READY = VK_NOT_READY;
const uint32_t TIMEOUT = VK_TIMEOUT;
const uint32_t EVENT_SET = VK_EVENT_SET;
const uint32_t EVENT_RESET = VK_EVENT_RESET;
const uint32_t INCOMPLETE = VK_INCOMPLETE;
const uint32_t ERROR_OUT_OF_HOST_MEMORY = VK_ERROR_OUT_OF_HOST_MEMORY;
const uint32_t ERROR_OUT_OF_DEVICE_MEMORY = VK_ERROR_OUT_OF_DEVICE_MEMORY;
const uint32_t ERROR_INITIALIZATION_FAILED = VK_ERROR_INITIALIZATION_FAILED;
const uint32_t ERROR_DEVICE_LOST = VK_ERROR_DEVICE_LOST;
const uint32_t ERROR_MEMORY_MAP_FAILED = VK_ERROR_MEMORY_MAP_FAILED;
const uint32_t ERROR_LAYER_NOT_PRESENT = VK_ERROR_LAYER_NOT_PRESENT;
const uint32_t ERROR_EXTENSION_NOT_PRESENT = VK_ERROR_EXTENSION_NOT_PRESENT;
const uint32_t ERROR_FEATURE_NOT_PRESENT = VK_ERROR_FEATURE_NOT_PRESENT;
const uint32_t ERROR_INCOMPATIBLE_DRIVER = VK_ERROR_INCOMPATIBLE_DRIVER;
const uint32_t ERROR_TOO_MANY_OBJECTS = VK_ERROR_TOO_MANY_OBJECTS;
const uint32_t ERROR_FORMAT_NOT_SUPPORTED = VK_ERROR_FORMAT_NOT_SUPPORTED;
const uint32_t ERROR_FRAGMENTED_POOL = VK_ERROR_FRAGMENTED_POOL;
const uint32_t ERROR_OUT_OF_POOL_MEMORY = VK_ERROR_OUT_OF_POOL_MEMORY;
const uint32_t ERROR_INVALID_EXTERNAL_HANDLE = VK_ERROR_INVALID_EXTERNAL_HANDLE;
const uint32_t ERROR_SURFACE_LOST_KHR = VK_ERROR_SURFACE_LOST_KHR;
const uint32_t ERROR_NATIVE_WINDOW_IN_USE_KHR = VK_ERROR_NATIVE_WINDOW_IN_USE_KHR;
const uint32_t SUBOPTIMAL_KHR = VK_SUBOPTIMAL_KHR;
const uint32_t ERROR_OUT_OF_DATE_KHR = VK_ERROR_OUT_OF_DATE_KHR;
const uint32_t ERROR_INCOMPATIBLE_DISPLAY_KHR = VK_ERROR_INCOMPATIBLE_DISPLAY_KHR;
const uint32_t ERROR_VALIDATION_FAILED_EXT = VK_ERROR_VALIDATION_FAILED_EXT;
const uint32_t ERROR_INVALID_SHADER_NV = VK_ERROR_INVALID_SHADER_NV;
const uint32_t ERROR_FRAGMENTATION_EXT = VK_ERROR_FRAGMENTATION_EXT;
const uint32_t ERROR_NOT_PERMITTED_EXT = VK_ERROR_NOT_PERMITTED_EXT;
const uint32_t ERROR_OUT_OF_POOL_MEMORY_KHR = VK_ERROR_OUT_OF_POOL_MEMORY_KHR;
const uint32_t ERROR_INVALID_EXTERNAL_HANDLE_KHR = VK_ERROR_INVALID_EXTERNAL_HANDLE_KHR;
const uint32_t RESULT_BEGIN_RANGE = VK_RESULT_BEGIN_RANGE;
const uint32_t RESULT_END_RANGE = VK_RESULT_END_RANGE;
const uint32_t RESULT_RANGE_SIZE = VK_RESULT_RANGE_SIZE;
const uint32_t RESULT_MAX_ENUM = VK_RESULT_MAX_ENUM;

uint32_t makeVersion(uint32_t major, uint32_t minor, uint32_t patch) { return VK_MAKE_VERSION(major, minor, patch); }
const uint32_t API_VERSION_1_0 = VK_API_VERSION_1_0;
const uint32_t API_VERSION_1_1 = VK_API_VERSION_1_1;

/* Extension names */
const char * KHR_SURFACE_EXTENSION_NAME = VK_KHR_SURFACE_EXTENSION_NAME;
const char * KHR_SWAPCHAIN_EXTENSION_NAME = VK_KHR_SWAPCHAIN_EXTENSION_NAME;
const char * KHR_WIN32_SURFACE_EXTENSION_NAME = VK_KHR_WIN32_SURFACE_EXTENSION_NAME;
const char * EXT_DEBUG_REPORT_EXTENSION_NAME = VK_EXT_DEBUG_REPORT_EXTENSION_NAME;
/* End extension names */

const uint32_t FORMAT_UNDEFINED = VK_FORMAT_UNDEFINED;
const uint32_t FORMAT_R4G4_UNORM_PACK8 = VK_FORMAT_R4G4_UNORM_PACK8;
const uint32_t FORMAT_R4G4B4A4_UNORM_PACK16 = VK_FORMAT_R4G4B4A4_UNORM_PACK16;
const uint32_t FORMAT_B4G4R4A4_UNORM_PACK16 = VK_FORMAT_B4G4R4A4_UNORM_PACK16;
const uint32_t FORMAT_R5G6B5_UNORM_PACK16 = VK_FORMAT_R5G6B5_UNORM_PACK16;
const uint32_t FORMAT_B5G6R5_UNORM_PACK16 = VK_FORMAT_B5G6R5_UNORM_PACK16;
const uint32_t FORMAT_R5G5B5A1_UNORM_PACK16 = VK_FORMAT_R5G5B5A1_UNORM_PACK16;
const uint32_t FORMAT_B5G5R5A1_UNORM_PACK16 = VK_FORMAT_B5G5R5A1_UNORM_PACK16;
const uint32_t FORMAT_A1R5G5B5_UNORM_PACK16 = VK_FORMAT_A1R5G5B5_UNORM_PACK16;
const uint32_t FORMAT_R8_UNORM = VK_FORMAT_R8_UNORM;
const uint32_t FORMAT_R8_SNORM = VK_FORMAT_R8_SNORM;
const uint32_t FORMAT_R8_USCALED = VK_FORMAT_R8_USCALED;
const uint32_t FORMAT_R8_SSCALED = VK_FORMAT_R8_SSCALED;
const uint32_t FORMAT_R8_UINT = VK_FORMAT_R8_UINT;
const uint32_t FORMAT_R8_SINT = VK_FORMAT_R8_SINT;
const uint32_t FORMAT_R8_SRGB = VK_FORMAT_R8_SRGB;
const uint32_t FORMAT_R8G8_UNORM = VK_FORMAT_R8G8_UNORM;
const uint32_t FORMAT_R8G8_SNORM = VK_FORMAT_R8G8_SNORM;
const uint32_t FORMAT_R8G8_USCALED = VK_FORMAT_R8G8_USCALED;
const uint32_t FORMAT_R8G8_SSCALED = VK_FORMAT_R8G8_SSCALED;
const uint32_t FORMAT_R8G8_UINT = VK_FORMAT_R8G8_UINT;
const uint32_t FORMAT_R8G8_SINT = VK_FORMAT_R8G8_SINT;
const uint32_t FORMAT_R8G8_SRGB = VK_FORMAT_R8G8_SRGB;
const uint32_t FORMAT_R8G8B8_UNORM = VK_FORMAT_R8G8B8_UNORM;
const uint32_t FORMAT_R8G8B8_SNORM = VK_FORMAT_R8G8B8_SNORM;
const uint32_t FORMAT_R8G8B8_USCALED = VK_FORMAT_R8G8B8_USCALED;
const uint32_t FORMAT_R8G8B8_SSCALED = VK_FORMAT_R8G8B8_SSCALED;
const uint32_t FORMAT_R8G8B8_UINT = VK_FORMAT_R8G8B8_UINT;
const uint32_t FORMAT_R8G8B8_SINT = VK_FORMAT_R8G8B8_SINT;
const uint32_t FORMAT_R8G8B8_SRGB = VK_FORMAT_R8G8B8_SRGB;
const uint32_t FORMAT_B8G8R8_UNORM = VK_FORMAT_B8G8R8_UNORM;
const uint32_t FORMAT_B8G8R8_SNORM = VK_FORMAT_B8G8R8_SNORM;
const uint32_t FORMAT_B8G8R8_USCALED = VK_FORMAT_B8G8R8_USCALED;
const uint32_t FORMAT_B8G8R8_SSCALED = VK_FORMAT_B8G8R8_SSCALED;
const uint32_t FORMAT_B8G8R8_UINT = VK_FORMAT_B8G8R8_UINT;
const uint32_t FORMAT_B8G8R8_SINT = VK_FORMAT_B8G8R8_SINT;
const uint32_t FORMAT_B8G8R8_SRGB = VK_FORMAT_B8G8R8_SRGB;
const uint32_t FORMAT_R8G8B8A8_UNORM = VK_FORMAT_R8G8B8A8_UNORM;
const uint32_t FORMAT_R8G8B8A8_SNORM = VK_FORMAT_R8G8B8A8_SNORM;
const uint32_t FORMAT_R8G8B8A8_USCALED = VK_FORMAT_R8G8B8A8_USCALED;
const uint32_t FORMAT_R8G8B8A8_SSCALED = VK_FORMAT_R8G8B8A8_SSCALED;
const uint32_t FORMAT_R8G8B8A8_UINT = VK_FORMAT_R8G8B8A8_UINT;
const uint32_t FORMAT_R8G8B8A8_SINT = VK_FORMAT_R8G8B8A8_SINT;
const uint32_t FORMAT_R8G8B8A8_SRGB = VK_FORMAT_R8G8B8A8_SRGB;
const uint32_t FORMAT_B8G8R8A8_UNORM = VK_FORMAT_B8G8R8A8_UNORM;
const uint32_t FORMAT_B8G8R8A8_SNORM = VK_FORMAT_B8G8R8A8_SNORM;
const uint32_t FORMAT_B8G8R8A8_USCALED = VK_FORMAT_B8G8R8A8_USCALED;
const uint32_t FORMAT_B8G8R8A8_SSCALED = VK_FORMAT_B8G8R8A8_SSCALED;
const uint32_t FORMAT_B8G8R8A8_UINT = VK_FORMAT_B8G8R8A8_UINT;
const uint32_t FORMAT_B8G8R8A8_SINT = VK_FORMAT_B8G8R8A8_SINT;
const uint32_t FORMAT_B8G8R8A8_SRGB = VK_FORMAT_B8G8R8A8_SRGB;
const uint32_t FORMAT_A8B8G8R8_UNORM_PACK32 = VK_FORMAT_A8B8G8R8_UNORM_PACK32;
const uint32_t FORMAT_A8B8G8R8_SNORM_PACK32 = VK_FORMAT_A8B8G8R8_SNORM_PACK32;
const uint32_t FORMAT_A8B8G8R8_USCALED_PACK32 = VK_FORMAT_A8B8G8R8_USCALED_PACK32;
const uint32_t FORMAT_A8B8G8R8_SSCALED_PACK32 = VK_FORMAT_A8B8G8R8_SSCALED_PACK32;
const uint32_t FORMAT_A8B8G8R8_UINT_PACK32 = VK_FORMAT_A8B8G8R8_UINT_PACK32;
const uint32_t FORMAT_A8B8G8R8_SINT_PACK32 = VK_FORMAT_A8B8G8R8_SINT_PACK32;
const uint32_t FORMAT_A8B8G8R8_SRGB_PACK32 = VK_FORMAT_A8B8G8R8_SRGB_PACK32;
const uint32_t FORMAT_A2R10G10B10_UNORM_PACK32 = VK_FORMAT_A2R10G10B10_UNORM_PACK32;
const uint32_t FORMAT_A2R10G10B10_SNORM_PACK32 = VK_FORMAT_A2R10G10B10_SNORM_PACK32;
const uint32_t FORMAT_A2R10G10B10_USCALED_PACK32 = VK_FORMAT_A2R10G10B10_USCALED_PACK32;
const uint32_t FORMAT_A2R10G10B10_SSCALED_PACK32 = VK_FORMAT_A2R10G10B10_SSCALED_PACK32;
const uint32_t FORMAT_A2R10G10B10_UINT_PACK32 = VK_FORMAT_A2R10G10B10_UINT_PACK32;
const uint32_t FORMAT_A2R10G10B10_SINT_PACK32 = VK_FORMAT_A2R10G10B10_SINT_PACK32;
const uint32_t FORMAT_A2B10G10R10_UNORM_PACK32 = VK_FORMAT_A2B10G10R10_UNORM_PACK32;
const uint32_t FORMAT_A2B10G10R10_SNORM_PACK32 = VK_FORMAT_A2B10G10R10_SNORM_PACK32;
const uint32_t FORMAT_A2B10G10R10_USCALED_PACK32 = VK_FORMAT_A2B10G10R10_USCALED_PACK32;
const uint32_t FORMAT_A2B10G10R10_SSCALED_PACK32 = VK_FORMAT_A2B10G10R10_SSCALED_PACK32;
const uint32_t FORMAT_A2B10G10R10_UINT_PACK32 = VK_FORMAT_A2B10G10R10_UINT_PACK32;
const uint32_t FORMAT_A2B10G10R10_SINT_PACK32 = VK_FORMAT_A2B10G10R10_SINT_PACK32;
const uint32_t FORMAT_R16_UNORM = VK_FORMAT_R16_UNORM;
const uint32_t FORMAT_R16_SNORM = VK_FORMAT_R16_SNORM;
const uint32_t FORMAT_R16_USCALED = VK_FORMAT_R16_USCALED;
const uint32_t FORMAT_R16_SSCALED = VK_FORMAT_R16_SSCALED;
const uint32_t FORMAT_R16_UINT = VK_FORMAT_R16_UINT;
const uint32_t FORMAT_R16_SINT = VK_FORMAT_R16_SINT;
const uint32_t FORMAT_R16_SFLOAT = VK_FORMAT_R16_SFLOAT;
const uint32_t FORMAT_R16G16_UNORM = VK_FORMAT_R16G16_UNORM;
const uint32_t FORMAT_R16G16_SNORM = VK_FORMAT_R16G16_SNORM;
const uint32_t FORMAT_R16G16_USCALED = VK_FORMAT_R16G16_USCALED;
const uint32_t FORMAT_R16G16_SSCALED = VK_FORMAT_R16G16_SSCALED;
const uint32_t FORMAT_R16G16_UINT = VK_FORMAT_R16G16_UINT;
const uint32_t FORMAT_R16G16_SINT = VK_FORMAT_R16G16_SINT;
const uint32_t FORMAT_R16G16_SFLOAT = VK_FORMAT_R16G16_SFLOAT;
const uint32_t FORMAT_R16G16B16_UNORM = VK_FORMAT_R16G16B16_UNORM;
const uint32_t FORMAT_R16G16B16_SNORM = VK_FORMAT_R16G16B16_SNORM;
const uint32_t FORMAT_R16G16B16_USCALED = VK_FORMAT_R16G16B16_USCALED;
const uint32_t FORMAT_R16G16B16_SSCALED = VK_FORMAT_R16G16B16_SSCALED;
const uint32_t FORMAT_R16G16B16_UINT = VK_FORMAT_R16G16B16_UINT;
const uint32_t FORMAT_R16G16B16_SINT = VK_FORMAT_R16G16B16_SINT;
const uint32_t FORMAT_R16G16B16_SFLOAT = VK_FORMAT_R16G16B16_SFLOAT;
const uint32_t FORMAT_R16G16B16A16_UNORM = VK_FORMAT_R16G16B16A16_UNORM;
const uint32_t FORMAT_R16G16B16A16_SNORM = VK_FORMAT_R16G16B16A16_SNORM;
const uint32_t FORMAT_R16G16B16A16_USCALED = VK_FORMAT_R16G16B16A16_USCALED;
const uint32_t FORMAT_R16G16B16A16_SSCALED = VK_FORMAT_R16G16B16A16_SSCALED;
const uint32_t FORMAT_R16G16B16A16_UINT = VK_FORMAT_R16G16B16A16_UINT;
const uint32_t FORMAT_R16G16B16A16_SINT = VK_FORMAT_R16G16B16A16_SINT;
const uint32_t FORMAT_R16G16B16A16_SFLOAT = VK_FORMAT_R16G16B16A16_SFLOAT;
const uint32_t FORMAT_R32_UINT = VK_FORMAT_R32_UINT;
const uint32_t FORMAT_R32_SINT = VK_FORMAT_R32_SINT;
const uint32_t FORMAT_R32_SFLOAT = VK_FORMAT_R32_SFLOAT;
const uint32_t FORMAT_R32G32_UINT = VK_FORMAT_R32G32_UINT;
const uint32_t FORMAT_R32G32_SINT = VK_FORMAT_R32G32_SINT;
const uint32_t FORMAT_R32G32_SFLOAT = VK_FORMAT_R32G32_SFLOAT;
const uint32_t FORMAT_R32G32B32_UINT = VK_FORMAT_R32G32B32_UINT;
const uint32_t FORMAT_R32G32B32_SINT = VK_FORMAT_R32G32B32_SINT;
const uint32_t FORMAT_R32G32B32_SFLOAT = VK_FORMAT_R32G32B32_SFLOAT;
const uint32_t FORMAT_R32G32B32A32_UINT = VK_FORMAT_R32G32B32A32_UINT;
const uint32_t FORMAT_R32G32B32A32_SINT = VK_FORMAT_R32G32B32A32_SINT;
const uint32_t FORMAT_R32G32B32A32_SFLOAT = VK_FORMAT_R32G32B32A32_SFLOAT;
const uint32_t FORMAT_R64_UINT = VK_FORMAT_R64_UINT;
const uint32_t FORMAT_R64_SINT = VK_FORMAT_R64_SINT;
const uint32_t FORMAT_R64_SFLOAT = VK_FORMAT_R64_SFLOAT;
const uint32_t FORMAT_R64G64_UINT = VK_FORMAT_R64G64_UINT;
const uint32_t FORMAT_R64G64_SINT = VK_FORMAT_R64G64_SINT;
const uint32_t FORMAT_R64G64_SFLOAT = VK_FORMAT_R64G64_SFLOAT;
const uint32_t FORMAT_R64G64B64_UINT = VK_FORMAT_R64G64B64_UINT;
const uint32_t FORMAT_R64G64B64_SINT = VK_FORMAT_R64G64B64_SINT;
const uint32_t FORMAT_R64G64B64_SFLOAT = VK_FORMAT_R64G64B64_SFLOAT;
const uint32_t FORMAT_R64G64B64A64_UINT = VK_FORMAT_R64G64B64A64_UINT;
const uint32_t FORMAT_R64G64B64A64_SINT = VK_FORMAT_R64G64B64A64_SINT;
const uint32_t FORMAT_R64G64B64A64_SFLOAT = VK_FORMAT_R64G64B64A64_SFLOAT;
const uint32_t FORMAT_B10G11R11_UFLOAT_PACK32 = VK_FORMAT_B10G11R11_UFLOAT_PACK32;
const uint32_t FORMAT_E5B9G9R9_UFLOAT_PACK32 = VK_FORMAT_E5B9G9R9_UFLOAT_PACK32;
const uint32_t FORMAT_D16_UNORM = VK_FORMAT_D16_UNORM;
const uint32_t FORMAT_X8_D24_UNORM_PACK32 = VK_FORMAT_X8_D24_UNORM_PACK32;
const uint32_t FORMAT_D32_SFLOAT = VK_FORMAT_D32_SFLOAT;
const uint32_t FORMAT_S8_UINT = VK_FORMAT_S8_UINT;
const uint32_t FORMAT_D16_UNORM_S8_UINT = VK_FORMAT_D16_UNORM_S8_UINT;
const uint32_t FORMAT_D24_UNORM_S8_UINT = VK_FORMAT_D24_UNORM_S8_UINT;
const uint32_t FORMAT_D32_SFLOAT_S8_UINT = VK_FORMAT_D32_SFLOAT_S8_UINT;
const uint32_t FORMAT_BC1_RGB_UNORM_BLOCK = VK_FORMAT_BC1_RGB_UNORM_BLOCK;
const uint32_t FORMAT_BC1_RGB_SRGB_BLOCK = VK_FORMAT_BC1_RGB_SRGB_BLOCK;
const uint32_t FORMAT_BC1_RGBA_UNORM_BLOCK = VK_FORMAT_BC1_RGBA_UNORM_BLOCK;
const uint32_t FORMAT_BC1_RGBA_SRGB_BLOCK = VK_FORMAT_BC1_RGBA_SRGB_BLOCK;
const uint32_t FORMAT_BC2_UNORM_BLOCK = VK_FORMAT_BC2_UNORM_BLOCK;
const uint32_t FORMAT_BC2_SRGB_BLOCK = VK_FORMAT_BC2_SRGB_BLOCK;
const uint32_t FORMAT_BC3_UNORM_BLOCK = VK_FORMAT_BC3_UNORM_BLOCK;
const uint32_t FORMAT_BC3_SRGB_BLOCK = VK_FORMAT_BC3_SRGB_BLOCK;
const uint32_t FORMAT_BC4_UNORM_BLOCK = VK_FORMAT_BC4_UNORM_BLOCK;
const uint32_t FORMAT_BC4_SNORM_BLOCK = VK_FORMAT_BC4_SNORM_BLOCK;
const uint32_t FORMAT_BC5_UNORM_BLOCK = VK_FORMAT_BC5_UNORM_BLOCK;
const uint32_t FORMAT_BC5_SNORM_BLOCK = VK_FORMAT_BC5_SNORM_BLOCK;
const uint32_t FORMAT_BC6H_UFLOAT_BLOCK = VK_FORMAT_BC6H_UFLOAT_BLOCK;
const uint32_t FORMAT_BC6H_SFLOAT_BLOCK = VK_FORMAT_BC6H_SFLOAT_BLOCK;
const uint32_t FORMAT_BC7_UNORM_BLOCK = VK_FORMAT_BC7_UNORM_BLOCK;
const uint32_t FORMAT_BC7_SRGB_BLOCK = VK_FORMAT_BC7_SRGB_BLOCK;
const uint32_t FORMAT_ETC2_R8G8B8_UNORM_BLOCK = VK_FORMAT_ETC2_R8G8B8_UNORM_BLOCK;
const uint32_t FORMAT_ETC2_R8G8B8_SRGB_BLOCK = VK_FORMAT_ETC2_R8G8B8_SRGB_BLOCK;
const uint32_t FORMAT_ETC2_R8G8B8A1_UNORM_BLOCK = VK_FORMAT_ETC2_R8G8B8A1_UNORM_BLOCK;
const uint32_t FORMAT_ETC2_R8G8B8A1_SRGB_BLOCK = VK_FORMAT_ETC2_R8G8B8A1_SRGB_BLOCK;
const uint32_t FORMAT_ETC2_R8G8B8A8_UNORM_BLOCK = VK_FORMAT_ETC2_R8G8B8A8_UNORM_BLOCK;
const uint32_t FORMAT_ETC2_R8G8B8A8_SRGB_BLOCK = VK_FORMAT_ETC2_R8G8B8A8_SRGB_BLOCK;
const uint32_t FORMAT_EAC_R11_UNORM_BLOCK = VK_FORMAT_EAC_R11_UNORM_BLOCK;
const uint32_t FORMAT_EAC_R11_SNORM_BLOCK = VK_FORMAT_EAC_R11_SNORM_BLOCK;
const uint32_t FORMAT_EAC_R11G11_UNORM_BLOCK = VK_FORMAT_EAC_R11G11_UNORM_BLOCK;
const uint32_t FORMAT_EAC_R11G11_SNORM_BLOCK = VK_FORMAT_EAC_R11G11_SNORM_BLOCK;
const uint32_t FORMAT_ASTC_4x4_UNORM_BLOCK = VK_FORMAT_ASTC_4x4_UNORM_BLOCK;
const uint32_t FORMAT_ASTC_4x4_SRGB_BLOCK = VK_FORMAT_ASTC_4x4_SRGB_BLOCK;
const uint32_t FORMAT_ASTC_5x4_UNORM_BLOCK = VK_FORMAT_ASTC_5x4_UNORM_BLOCK;
const uint32_t FORMAT_ASTC_5x4_SRGB_BLOCK = VK_FORMAT_ASTC_5x4_SRGB_BLOCK;
const uint32_t FORMAT_ASTC_5x5_UNORM_BLOCK = VK_FORMAT_ASTC_5x5_UNORM_BLOCK;
const uint32_t FORMAT_ASTC_5x5_SRGB_BLOCK = VK_FORMAT_ASTC_5x5_SRGB_BLOCK;
const uint32_t FORMAT_ASTC_6x5_UNORM_BLOCK = VK_FORMAT_ASTC_6x5_UNORM_BLOCK;
const uint32_t FORMAT_ASTC_6x5_SRGB_BLOCK = VK_FORMAT_ASTC_6x5_SRGB_BLOCK;
const uint32_t FORMAT_ASTC_6x6_UNORM_BLOCK = VK_FORMAT_ASTC_6x6_UNORM_BLOCK;
const uint32_t FORMAT_ASTC_6x6_SRGB_BLOCK = VK_FORMAT_ASTC_6x6_SRGB_BLOCK;
const uint32_t FORMAT_ASTC_8x5_UNORM_BLOCK = VK_FORMAT_ASTC_8x5_UNORM_BLOCK;
const uint32_t FORMAT_ASTC_8x5_SRGB_BLOCK = VK_FORMAT_ASTC_8x5_SRGB_BLOCK;
const uint32_t FORMAT_ASTC_8x6_UNORM_BLOCK = VK_FORMAT_ASTC_8x6_UNORM_BLOCK;
const uint32_t FORMAT_ASTC_8x6_SRGB_BLOCK = VK_FORMAT_ASTC_8x6_SRGB_BLOCK;
const uint32_t FORMAT_ASTC_8x8_UNORM_BLOCK = VK_FORMAT_ASTC_8x8_UNORM_BLOCK;
const uint32_t FORMAT_ASTC_8x8_SRGB_BLOCK = VK_FORMAT_ASTC_8x8_SRGB_BLOCK;
const uint32_t FORMAT_ASTC_10x5_UNORM_BLOCK = VK_FORMAT_ASTC_10x5_UNORM_BLOCK;
const uint32_t FORMAT_ASTC_10x5_SRGB_BLOCK = VK_FORMAT_ASTC_10x5_SRGB_BLOCK;
const uint32_t FORMAT_ASTC_10x6_UNORM_BLOCK = VK_FORMAT_ASTC_10x6_UNORM_BLOCK;
const uint32_t FORMAT_ASTC_10x6_SRGB_BLOCK = VK_FORMAT_ASTC_10x6_SRGB_BLOCK;
const uint32_t FORMAT_ASTC_10x8_UNORM_BLOCK = VK_FORMAT_ASTC_10x8_UNORM_BLOCK;
const uint32_t FORMAT_ASTC_10x8_SRGB_BLOCK = VK_FORMAT_ASTC_10x8_SRGB_BLOCK;
const uint32_t FORMAT_ASTC_10x10_UNORM_BLOCK = VK_FORMAT_ASTC_10x10_UNORM_BLOCK;
const uint32_t FORMAT_ASTC_10x10_SRGB_BLOCK = VK_FORMAT_ASTC_10x10_SRGB_BLOCK;
const uint32_t FORMAT_ASTC_12x10_UNORM_BLOCK = VK_FORMAT_ASTC_12x10_UNORM_BLOCK;
const uint32_t FORMAT_ASTC_12x10_SRGB_BLOCK = VK_FORMAT_ASTC_12x10_SRGB_BLOCK;
const uint32_t FORMAT_ASTC_12x12_UNORM_BLOCK = VK_FORMAT_ASTC_12x12_UNORM_BLOCK;
const uint32_t FORMAT_ASTC_12x12_SRGB_BLOCK = VK_FORMAT_ASTC_12x12_SRGB_BLOCK;
const uint32_t FORMAT_G8B8G8R8_422_UNORM = VK_FORMAT_G8B8G8R8_422_UNORM;
const uint32_t FORMAT_B8G8R8G8_422_UNORM = VK_FORMAT_B8G8R8G8_422_UNORM;
const uint32_t FORMAT_G8_B8_R8_3PLANE_420_UNORM = VK_FORMAT_G8_B8_R8_3PLANE_420_UNORM;
const uint32_t FORMAT_G8_B8R8_2PLANE_420_UNORM = VK_FORMAT_G8_B8R8_2PLANE_420_UNORM;
const uint32_t FORMAT_G8_B8_R8_3PLANE_422_UNORM = VK_FORMAT_G8_B8_R8_3PLANE_422_UNORM;
const uint32_t FORMAT_G8_B8R8_2PLANE_422_UNORM = VK_FORMAT_G8_B8R8_2PLANE_422_UNORM;
const uint32_t FORMAT_G8_B8_R8_3PLANE_444_UNORM = VK_FORMAT_G8_B8_R8_3PLANE_444_UNORM;
const uint32_t FORMAT_R10X6_UNORM_PACK16 = VK_FORMAT_R10X6_UNORM_PACK16;
const uint32_t FORMAT_R10X6G10X6_UNORM_2PACK16 = VK_FORMAT_R10X6G10X6_UNORM_2PACK16;
const uint32_t FORMAT_R10X6G10X6B10X6A10X6_UNORM_4PACK16 = VK_FORMAT_R10X6G10X6B10X6A10X6_UNORM_4PACK16;
const uint32_t FORMAT_G10X6B10X6G10X6R10X6_422_UNORM_4PACK16 = VK_FORMAT_G10X6B10X6G10X6R10X6_422_UNORM_4PACK16;
const uint32_t FORMAT_B10X6G10X6R10X6G10X6_422_UNORM_4PACK16 = VK_FORMAT_B10X6G10X6R10X6G10X6_422_UNORM_4PACK16;
const uint32_t FORMAT_G10X6_B10X6_R10X6_3PLANE_420_UNORM_3PACK16 = VK_FORMAT_G10X6_B10X6_R10X6_3PLANE_420_UNORM_3PACK16;
const uint32_t FORMAT_G10X6_B10X6R10X6_2PLANE_420_UNORM_3PACK16 = VK_FORMAT_G10X6_B10X6R10X6_2PLANE_420_UNORM_3PACK16;
const uint32_t FORMAT_G10X6_B10X6_R10X6_3PLANE_422_UNORM_3PACK16 = VK_FORMAT_G10X6_B10X6_R10X6_3PLANE_422_UNORM_3PACK16;
const uint32_t FORMAT_G10X6_B10X6R10X6_2PLANE_422_UNORM_3PACK16 = VK_FORMAT_G10X6_B10X6R10X6_2PLANE_422_UNORM_3PACK16;
const uint32_t FORMAT_G10X6_B10X6_R10X6_3PLANE_444_UNORM_3PACK16 = VK_FORMAT_G10X6_B10X6_R10X6_3PLANE_444_UNORM_3PACK16;
const uint32_t FORMAT_R12X4_UNORM_PACK16 = VK_FORMAT_R12X4_UNORM_PACK16;
const uint32_t FORMAT_R12X4G12X4_UNORM_2PACK16 = VK_FORMAT_R12X4G12X4_UNORM_2PACK16;
const uint32_t FORMAT_R12X4G12X4B12X4A12X4_UNORM_4PACK16 = VK_FORMAT_R12X4G12X4B12X4A12X4_UNORM_4PACK16;
const uint32_t FORMAT_G12X4B12X4G12X4R12X4_422_UNORM_4PACK16 = VK_FORMAT_G12X4B12X4G12X4R12X4_422_UNORM_4PACK16;
const uint32_t FORMAT_B12X4G12X4R12X4G12X4_422_UNORM_4PACK16 = VK_FORMAT_B12X4G12X4R12X4G12X4_422_UNORM_4PACK16;
const uint32_t FORMAT_G12X4_B12X4_R12X4_3PLANE_420_UNORM_3PACK16 = VK_FORMAT_G12X4_B12X4_R12X4_3PLANE_420_UNORM_3PACK16;
const uint32_t FORMAT_G12X4_B12X4R12X4_2PLANE_420_UNORM_3PACK16 = VK_FORMAT_G12X4_B12X4R12X4_2PLANE_420_UNORM_3PACK16;
const uint32_t FORMAT_G12X4_B12X4_R12X4_3PLANE_422_UNORM_3PACK16 = VK_FORMAT_G12X4_B12X4_R12X4_3PLANE_422_UNORM_3PACK16;
const uint32_t FORMAT_G12X4_B12X4R12X4_2PLANE_422_UNORM_3PACK16 = VK_FORMAT_G12X4_B12X4R12X4_2PLANE_422_UNORM_3PACK16;
const uint32_t FORMAT_G12X4_B12X4_R12X4_3PLANE_444_UNORM_3PACK16 = VK_FORMAT_G12X4_B12X4_R12X4_3PLANE_444_UNORM_3PACK16;
const uint32_t FORMAT_G16B16G16R16_422_UNORM = VK_FORMAT_G16B16G16R16_422_UNORM;
const uint32_t FORMAT_B16G16R16G16_422_UNORM = VK_FORMAT_B16G16R16G16_422_UNORM;
const uint32_t FORMAT_G16_B16_R16_3PLANE_420_UNORM = VK_FORMAT_G16_B16_R16_3PLANE_420_UNORM;
const uint32_t FORMAT_G16_B16R16_2PLANE_420_UNORM = VK_FORMAT_G16_B16R16_2PLANE_420_UNORM;
const uint32_t FORMAT_G16_B16_R16_3PLANE_422_UNORM = VK_FORMAT_G16_B16_R16_3PLANE_422_UNORM;
const uint32_t FORMAT_G16_B16R16_2PLANE_422_UNORM = VK_FORMAT_G16_B16R16_2PLANE_422_UNORM;
const uint32_t FORMAT_G16_B16_R16_3PLANE_444_UNORM = VK_FORMAT_G16_B16_R16_3PLANE_444_UNORM;
const uint32_t FORMAT_PVRTC1_2BPP_UNORM_BLOCK_IMG = VK_FORMAT_PVRTC1_2BPP_UNORM_BLOCK_IMG;
const uint32_t FORMAT_PVRTC1_4BPP_UNORM_BLOCK_IMG = VK_FORMAT_PVRTC1_4BPP_UNORM_BLOCK_IMG;
const uint32_t FORMAT_PVRTC2_2BPP_UNORM_BLOCK_IMG = VK_FORMAT_PVRTC2_2BPP_UNORM_BLOCK_IMG;
const uint32_t FORMAT_PVRTC2_4BPP_UNORM_BLOCK_IMG = VK_FORMAT_PVRTC2_4BPP_UNORM_BLOCK_IMG;
const uint32_t FORMAT_PVRTC1_2BPP_SRGB_BLOCK_IMG = VK_FORMAT_PVRTC1_2BPP_SRGB_BLOCK_IMG;
const uint32_t FORMAT_PVRTC1_4BPP_SRGB_BLOCK_IMG = VK_FORMAT_PVRTC1_4BPP_SRGB_BLOCK_IMG;
const uint32_t FORMAT_PVRTC2_2BPP_SRGB_BLOCK_IMG = VK_FORMAT_PVRTC2_2BPP_SRGB_BLOCK_IMG;
const uint32_t FORMAT_PVRTC2_4BPP_SRGB_BLOCK_IMG = VK_FORMAT_PVRTC2_4BPP_SRGB_BLOCK_IMG;
const uint32_t FORMAT_G8B8G8R8_422_UNORM_KHR = VK_FORMAT_G8B8G8R8_422_UNORM_KHR;
const uint32_t FORMAT_B8G8R8G8_422_UNORM_KHR = VK_FORMAT_B8G8R8G8_422_UNORM_KHR;
const uint32_t FORMAT_G8_B8_R8_3PLANE_420_UNORM_KHR = VK_FORMAT_G8_B8_R8_3PLANE_420_UNORM_KHR;
const uint32_t FORMAT_G8_B8R8_2PLANE_420_UNORM_KHR = VK_FORMAT_G8_B8R8_2PLANE_420_UNORM_KHR;
const uint32_t FORMAT_G8_B8_R8_3PLANE_422_UNORM_KHR = VK_FORMAT_G8_B8_R8_3PLANE_422_UNORM_KHR;
const uint32_t FORMAT_G8_B8R8_2PLANE_422_UNORM_KHR = VK_FORMAT_G8_B8R8_2PLANE_422_UNORM_KHR;
const uint32_t FORMAT_G8_B8_R8_3PLANE_444_UNORM_KHR = VK_FORMAT_G8_B8_R8_3PLANE_444_UNORM_KHR;
const uint32_t FORMAT_R10X6_UNORM_PACK16_KHR = VK_FORMAT_R10X6_UNORM_PACK16_KHR;
const uint32_t FORMAT_R10X6G10X6_UNORM_2PACK16_KHR = VK_FORMAT_R10X6G10X6_UNORM_2PACK16_KHR;
const uint32_t FORMAT_R10X6G10X6B10X6A10X6_UNORM_4PACK16_KHR = VK_FORMAT_R10X6G10X6B10X6A10X6_UNORM_4PACK16_KHR;
const uint32_t FORMAT_G10X6B10X6G10X6R10X6_422_UNORM_4PACK16_KHR = VK_FORMAT_G10X6B10X6G10X6R10X6_422_UNORM_4PACK16_KHR;
const uint32_t FORMAT_B10X6G10X6R10X6G10X6_422_UNORM_4PACK16_KHR = VK_FORMAT_B10X6G10X6R10X6G10X6_422_UNORM_4PACK16_KHR;
const uint32_t FORMAT_G10X6_B10X6_R10X6_3PLANE_420_UNORM_3PACK16_KHR = VK_FORMAT_G10X6_B10X6_R10X6_3PLANE_420_UNORM_3PACK16_KHR;
const uint32_t FORMAT_G10X6_B10X6R10X6_2PLANE_420_UNORM_3PACK16_KHR = VK_FORMAT_G10X6_B10X6R10X6_2PLANE_420_UNORM_3PACK16_KHR;
const uint32_t FORMAT_G10X6_B10X6_R10X6_3PLANE_422_UNORM_3PACK16_KHR = VK_FORMAT_G10X6_B10X6_R10X6_3PLANE_422_UNORM_3PACK16_KHR;
const uint32_t FORMAT_G10X6_B10X6R10X6_2PLANE_422_UNORM_3PACK16_KHR = VK_FORMAT_G10X6_B10X6R10X6_2PLANE_422_UNORM_3PACK16_KHR;
const uint32_t FORMAT_G10X6_B10X6_R10X6_3PLANE_444_UNORM_3PACK16_KHR = VK_FORMAT_G10X6_B10X6_R10X6_3PLANE_444_UNORM_3PACK16_KHR;
const uint32_t FORMAT_R12X4_UNORM_PACK16_KHR = VK_FORMAT_R12X4_UNORM_PACK16_KHR;
const uint32_t FORMAT_R12X4G12X4_UNORM_2PACK16_KHR = VK_FORMAT_R12X4G12X4_UNORM_2PACK16_KHR;
const uint32_t FORMAT_R12X4G12X4B12X4A12X4_UNORM_4PACK16_KHR = VK_FORMAT_R12X4G12X4B12X4A12X4_UNORM_4PACK16_KHR;
const uint32_t FORMAT_G12X4B12X4G12X4R12X4_422_UNORM_4PACK16_KHR = VK_FORMAT_G12X4B12X4G12X4R12X4_422_UNORM_4PACK16_KHR;
const uint32_t FORMAT_B12X4G12X4R12X4G12X4_422_UNORM_4PACK16_KHR = VK_FORMAT_B12X4G12X4R12X4G12X4_422_UNORM_4PACK16_KHR;
const uint32_t FORMAT_G12X4_B12X4_R12X4_3PLANE_420_UNORM_3PACK16_KHR = VK_FORMAT_G12X4_B12X4_R12X4_3PLANE_420_UNORM_3PACK16_KHR;
const uint32_t FORMAT_G12X4_B12X4R12X4_2PLANE_420_UNORM_3PACK16_KHR = VK_FORMAT_G12X4_B12X4R12X4_2PLANE_420_UNORM_3PACK16_KHR;
const uint32_t FORMAT_G12X4_B12X4_R12X4_3PLANE_422_UNORM_3PACK16_KHR = VK_FORMAT_G12X4_B12X4_R12X4_3PLANE_422_UNORM_3PACK16_KHR;
const uint32_t FORMAT_G12X4_B12X4R12X4_2PLANE_422_UNORM_3PACK16_KHR = VK_FORMAT_G12X4_B12X4R12X4_2PLANE_422_UNORM_3PACK16_KHR;
const uint32_t FORMAT_G12X4_B12X4_R12X4_3PLANE_444_UNORM_3PACK16_KHR = VK_FORMAT_G12X4_B12X4_R12X4_3PLANE_444_UNORM_3PACK16_KHR;
const uint32_t FORMAT_G16B16G16R16_422_UNORM_KHR = VK_FORMAT_G16B16G16R16_422_UNORM_KHR;
const uint32_t FORMAT_B16G16R16G16_422_UNORM_KHR = VK_FORMAT_B16G16R16G16_422_UNORM_KHR;
const uint32_t FORMAT_G16_B16_R16_3PLANE_420_UNORM_KHR = VK_FORMAT_G16_B16_R16_3PLANE_420_UNORM_KHR;
const uint32_t FORMAT_G16_B16R16_2PLANE_420_UNORM_KHR = VK_FORMAT_G16_B16R16_2PLANE_420_UNORM_KHR;
const uint32_t FORMAT_G16_B16_R16_3PLANE_422_UNORM_KHR = VK_FORMAT_G16_B16_R16_3PLANE_422_UNORM_KHR;
const uint32_t FORMAT_G16_B16R16_2PLANE_422_UNORM_KHR = VK_FORMAT_G16_B16R16_2PLANE_422_UNORM_KHR;
const uint32_t FORMAT_G16_B16_R16_3PLANE_444_UNORM_KHR = VK_FORMAT_G16_B16_R16_3PLANE_444_UNORM_KHR;
const uint32_t FORMAT_BEGIN_RANGE = VK_FORMAT_BEGIN_RANGE;
const uint32_t FORMAT_END_RANGE = VK_FORMAT_END_RANGE;
const uint32_t FORMAT_RANGE_SIZE = VK_FORMAT_RANGE_SIZE;
const uint32_t FORMAT_MAX_ENUM = VK_FORMAT_MAX_ENUM;

const uint32_t FORMAT_FEATURE_SAMPLED_IMAGE_BIT = VK_FORMAT_FEATURE_SAMPLED_IMAGE_BIT;
const uint32_t FORMAT_FEATURE_STORAGE_IMAGE_BIT = VK_FORMAT_FEATURE_STORAGE_IMAGE_BIT;
const uint32_t FORMAT_FEATURE_STORAGE_IMAGE_ATOMIC_BIT = VK_FORMAT_FEATURE_STORAGE_IMAGE_ATOMIC_BIT;
const uint32_t FORMAT_FEATURE_UNIFORM_TEXEL_BUFFER_BIT = VK_FORMAT_FEATURE_UNIFORM_TEXEL_BUFFER_BIT;
const uint32_t FORMAT_FEATURE_STORAGE_TEXEL_BUFFER_BIT = VK_FORMAT_FEATURE_STORAGE_TEXEL_BUFFER_BIT;
const uint32_t FORMAT_FEATURE_STORAGE_TEXEL_BUFFER_ATOMIC_BIT = VK_FORMAT_FEATURE_STORAGE_TEXEL_BUFFER_ATOMIC_BIT;
const uint32_t FORMAT_FEATURE_VERTEX_BUFFER_BIT = VK_FORMAT_FEATURE_VERTEX_BUFFER_BIT;
const uint32_t FORMAT_FEATURE_COLOR_ATTACHMENT_BIT = VK_FORMAT_FEATURE_COLOR_ATTACHMENT_BIT;
const uint32_t FORMAT_FEATURE_COLOR_ATTACHMENT_BLEND_BIT = VK_FORMAT_FEATURE_COLOR_ATTACHMENT_BLEND_BIT;
const uint32_t FORMAT_FEATURE_DEPTH_STENCIL_ATTACHMENT_BIT = VK_FORMAT_FEATURE_DEPTH_STENCIL_ATTACHMENT_BIT;
const uint32_t FORMAT_FEATURE_BLIT_SRC_BIT = VK_FORMAT_FEATURE_BLIT_SRC_BIT;
const uint32_t FORMAT_FEATURE_BLIT_DST_BIT = VK_FORMAT_FEATURE_BLIT_DST_BIT;
const uint32_t FORMAT_FEATURE_SAMPLED_IMAGE_FILTER_LINEAR_BIT = VK_FORMAT_FEATURE_SAMPLED_IMAGE_FILTER_LINEAR_BIT;
const uint32_t FORMAT_FEATURE_TRANSFER_SRC_BIT = VK_FORMAT_FEATURE_TRANSFER_SRC_BIT;
const uint32_t FORMAT_FEATURE_TRANSFER_DST_BIT = VK_FORMAT_FEATURE_TRANSFER_DST_BIT;
const uint32_t FORMAT_FEATURE_MIDPOINT_CHROMA_SAMPLES_BIT = VK_FORMAT_FEATURE_MIDPOINT_CHROMA_SAMPLES_BIT;
const uint32_t FORMAT_FEATURE_SAMPLED_IMAGE_YCBCR_CONVERSION_LINEAR_FILTER_BIT = VK_FORMAT_FEATURE_SAMPLED_IMAGE_YCBCR_CONVERSION_LINEAR_FILTER_BIT;
const uint32_t FORMAT_FEATURE_SAMPLED_IMAGE_YCBCR_CONVERSION_SEPARATE_RECONSTRUCTION_FILTER_BIT = VK_FORMAT_FEATURE_SAMPLED_IMAGE_YCBCR_CONVERSION_SEPARATE_RECONSTRUCTION_FILTER_BIT;
const uint32_t FORMAT_FEATURE_SAMPLED_IMAGE_YCBCR_CONVERSION_CHROMA_RECONSTRUCTION_EXPLICIT_BIT = VK_FORMAT_FEATURE_SAMPLED_IMAGE_YCBCR_CONVERSION_CHROMA_RECONSTRUCTION_EXPLICIT_BIT;
const uint32_t FORMAT_FEATURE_SAMPLED_IMAGE_YCBCR_CONVERSION_CHROMA_RECONSTRUCTION_EXPLICIT_FORCEABLE_BIT = VK_FORMAT_FEATURE_SAMPLED_IMAGE_YCBCR_CONVERSION_CHROMA_RECONSTRUCTION_EXPLICIT_FORCEABLE_BIT;
const uint32_t FORMAT_FEATURE_DISJOINT_BIT = VK_FORMAT_FEATURE_DISJOINT_BIT;
const uint32_t FORMAT_FEATURE_COSITED_CHROMA_SAMPLES_BIT = VK_FORMAT_FEATURE_COSITED_CHROMA_SAMPLES_BIT;
const uint32_t FORMAT_FEATURE_SAMPLED_IMAGE_FILTER_CUBIC_BIT_IMG = VK_FORMAT_FEATURE_SAMPLED_IMAGE_FILTER_CUBIC_BIT_IMG;
const uint32_t FORMAT_FEATURE_SAMPLED_IMAGE_FILTER_MINMAX_BIT_EXT = VK_FORMAT_FEATURE_SAMPLED_IMAGE_FILTER_MINMAX_BIT_EXT;
const uint32_t FORMAT_FEATURE_TRANSFER_SRC_BIT_KHR = VK_FORMAT_FEATURE_TRANSFER_SRC_BIT_KHR;
const uint32_t FORMAT_FEATURE_TRANSFER_DST_BIT_KHR = VK_FORMAT_FEATURE_TRANSFER_DST_BIT_KHR;
const uint32_t FORMAT_FEATURE_MIDPOINT_CHROMA_SAMPLES_BIT_KHR = VK_FORMAT_FEATURE_MIDPOINT_CHROMA_SAMPLES_BIT_KHR;
const uint32_t FORMAT_FEATURE_SAMPLED_IMAGE_YCBCR_CONVERSION_LINEAR_FILTER_BIT_KHR = VK_FORMAT_FEATURE_SAMPLED_IMAGE_YCBCR_CONVERSION_LINEAR_FILTER_BIT_KHR;
const uint32_t FORMAT_FEATURE_SAMPLED_IMAGE_YCBCR_CONVERSION_SEPARATE_RECONSTRUCTION_FILTER_BIT_KHR = VK_FORMAT_FEATURE_SAMPLED_IMAGE_YCBCR_CONVERSION_SEPARATE_RECONSTRUCTION_FILTER_BIT_KHR;
const uint32_t FORMAT_FEATURE_SAMPLED_IMAGE_YCBCR_CONVERSION_CHROMA_RECONSTRUCTION_EXPLICIT_BIT_KHR = VK_FORMAT_FEATURE_SAMPLED_IMAGE_YCBCR_CONVERSION_CHROMA_RECONSTRUCTION_EXPLICIT_BIT_KHR;
const uint32_t FORMAT_FEATURE_SAMPLED_IMAGE_YCBCR_CONVERSION_CHROMA_RECONSTRUCTION_EXPLICIT_FORCEABLE_BIT_KHR = VK_FORMAT_FEATURE_SAMPLED_IMAGE_YCBCR_CONVERSION_CHROMA_RECONSTRUCTION_EXPLICIT_FORCEABLE_BIT_KHR;
const uint32_t FORMAT_FEATURE_DISJOINT_BIT_KHR = VK_FORMAT_FEATURE_DISJOINT_BIT_KHR;
const uint32_t FORMAT_FEATURE_COSITED_CHROMA_SAMPLES_BIT_KHR = VK_FORMAT_FEATURE_COSITED_CHROMA_SAMPLES_BIT_KHR;
const uint32_t FORMAT_FEATURE_FLAG_BITS_MAX_ENUM = VK_FORMAT_FEATURE_FLAG_BITS_MAX_ENUM;

const uint32_t COLOR_SPACE_SRGB_NONLINEAR_KHR = VK_COLOR_SPACE_SRGB_NONLINEAR_KHR;
const uint32_t COLOR_SPACE_DISPLAY_P3_NONLINEAR_EXT = VK_COLOR_SPACE_DISPLAY_P3_NONLINEAR_EXT;
const uint32_t COLOR_SPACE_EXTENDED_SRGB_LINEAR_EXT = VK_COLOR_SPACE_EXTENDED_SRGB_LINEAR_EXT;
const uint32_t COLOR_SPACE_DCI_P3_LINEAR_EXT = VK_COLOR_SPACE_DCI_P3_LINEAR_EXT;
const uint32_t COLOR_SPACE_DCI_P3_NONLINEAR_EXT = VK_COLOR_SPACE_DCI_P3_NONLINEAR_EXT;
const uint32_t COLOR_SPACE_BT709_LINEAR_EXT = VK_COLOR_SPACE_BT709_LINEAR_EXT;
const uint32_t COLOR_SPACE_BT709_NONLINEAR_EXT = VK_COLOR_SPACE_BT709_NONLINEAR_EXT;
const uint32_t COLOR_SPACE_BT2020_LINEAR_EXT = VK_COLOR_SPACE_BT2020_LINEAR_EXT;
const uint32_t COLOR_SPACE_HDR10_ST2084_EXT = VK_COLOR_SPACE_HDR10_ST2084_EXT;
const uint32_t COLOR_SPACE_DOLBYVISION_EXT = VK_COLOR_SPACE_DOLBYVISION_EXT;
const uint32_t COLOR_SPACE_HDR10_HLG_EXT = VK_COLOR_SPACE_HDR10_HLG_EXT;
const uint32_t COLOR_SPACE_ADOBERGB_LINEAR_EXT = VK_COLOR_SPACE_ADOBERGB_LINEAR_EXT;
const uint32_t COLOR_SPACE_ADOBERGB_NONLINEAR_EXT = VK_COLOR_SPACE_ADOBERGB_NONLINEAR_EXT;
const uint32_t COLOR_SPACE_PASS_THROUGH_EXT = VK_COLOR_SPACE_PASS_THROUGH_EXT;
const uint32_t COLOR_SPACE_EXTENDED_SRGB_NONLINEAR_EXT = VK_COLOR_SPACE_EXTENDED_SRGB_NONLINEAR_EXT;
const uint32_t COLOR_SPACE_BEGIN_RANGE_KHR = VK_COLOR_SPACE_BEGIN_RANGE_KHR;
const uint32_t COLOR_SPACE_END_RANGE_KHR = VK_COLOR_SPACE_END_RANGE_KHR;
const uint32_t COLOR_SPACE_RANGE_SIZE_KHR = VK_COLOR_SPACE_RANGE_SIZE_KHR;
const uint32_t COLOR_SPACE_MAX_ENUM_KHR = VK_COLOR_SPACE_MAX_ENUM_KHR;

/* Instance */
Instance::Instance(Allocator * alloc) {}

Instance::~Instance() {
	if (_vk_instance) {
		VkInstance inst = native_cast<VkInstance>(_vk_instance);
		vkDestroyInstance(inst, nullptr);
		_vk_instance = nullptr;
	}
}

Result Instance::create() {
	Result res = SUCCESS;
	VkApplicationInfo appInfo = {};
	appInfo.sType = VK_STRUCTURE_TYPE_APPLICATION_INFO;
	appInfo.pApplicationName = applicationInfo.applicationName.c_str();
	appInfo.applicationVersion = applicationInfo.applicationVersion;
	appInfo.pEngineName = applicationInfo.engineName.c_str();
	appInfo.engineVersion = applicationInfo.engineVersion;
	appInfo.apiVersion = applicationInfo.apiVersion;

	VkInstanceCreateInfo createInfo = {};
	createInfo.sType = VK_STRUCTURE_TYPE_INSTANCE_CREATE_INFO;
	createInfo.pApplicationInfo = &appInfo;


	if (!LayerProperties::CheckSupport(enabledLayers)) {
		bg::log(bg::log::kWarning) << "Some Vulkan required layers are not supported in this system." << bg::endl;
	}

	if (!ExtensionProperties::CheckSupport(enabledExtensions)) {
		bg::log(bg::log::kError) << "Some required Vulkan extensions are not supported in this system." << bg::endl;
		return false;
	}

	std::vector<const char *> layers;
	for (auto & l : enabledLayers) {
		layers.push_back(l.c_str());
	}
	std::vector<const char *> ext;
	for (auto & e : enabledExtensions) {
		ext.push_back(e.c_str());
	}

	createInfo.enabledLayerCount = static_cast<uint32_t>(layers.size());
	createInfo.ppEnabledLayerNames = layers.data();
	createInfo.enabledExtensionCount = static_cast<uint32_t>(ext.size());
	createInfo.ppEnabledExtensionNames = ext.data();

	VkInstance instance;
	if ((res = vkCreateInstance(&createInfo, nullptr, &instance))==SUCCESS) {
		_vk_instance = instance;
	}
	return res;
}

void * Instance::getProcAddr(const std::string & fnName) {
	VkInstance instance = native_cast<VkInstance>(_vk_instance);
	return (void *) vkGetInstanceProcAddr(instance, fnName.c_str());
}
/* end Instance */

/* Extension properties */
void ExtensionProperties::Enumerate(Vector & result) {
	uint32_t extensionCount = 0;
	vkEnumerateInstanceExtensionProperties(nullptr, &extensionCount, nullptr);
	std::vector<VkExtensionProperties> prop(extensionCount);
	vkEnumerateInstanceExtensionProperties(nullptr, &extensionCount, prop.data());

	for (auto & p : prop) {
		result.push_back(ExtensionProperties{ p.extensionName, p.specVersion });
	}
}

void ExtensionProperties::Enumerate(PhysicalDevice * dev, Vector & result) {
	uint32_t extensionCount;
	VkPhysicalDevice vkDev = bg::native_cast<VkPhysicalDevice>(dev->vkDevice());
	vkEnumerateDeviceExtensionProperties(vkDev, nullptr, &extensionCount, nullptr);
	std::vector<VkExtensionProperties> extensions(extensionCount);
	vkEnumerateDeviceExtensionProperties(vkDev, nullptr, &extensionCount, extensions.data());

	for (auto e : extensions) {
		result.push_back(ExtensionProperties{ e.extensionName, e.specVersion });
	}
}

bool ExtensionProperties::CheckSupport(const std::vector<std::string> & required) {
	Vector prop;
	Enumerate(prop);

	for (auto & req : required) {
		bool found = false;
		for (auto & p : prop) {
			if (req == p.extensionName) {
				found = true;
				break;
			}
		}

		if (!found) {
			return false;
		}
	}
	return true;
}

bool ExtensionProperties::CheckSupport(const std::string & name) {
	Vector prop;
	Enumerate(prop);

	for (auto & p : prop) {
		if (name == p.extensionName) {
			return true;
		}
	}
	return false;
}

bool ExtensionProperties::CheckSupport(Vector & available, const std::vector<std::string> & required) {
	for (auto & req : required) {
		bool found = false;
		for (auto & p : available) {
			if (req == p.extensionName) {
				found = true;
				break;
			}
		}

		if (!found) {
			return false;
		}
	}
	return true;
}

ExtensionProperties::ExtensionProperties(const char * name, uint32_t specVersion)
	:extensionName(name)
	,specVersion(specVersion)
{
}
/* End extension properties */

/* Layer properties */
void LayerProperties::Enumerate(Vector & result) {
	uint32_t layerCount = 0;
	vkEnumerateInstanceLayerProperties(&layerCount, nullptr);
	std::vector<VkLayerProperties> prop(layerCount);
	vkEnumerateInstanceLayerProperties(&layerCount, prop.data());

	for (auto & p : prop) {
		result.push_back(LayerProperties(p.layerName, p.specVersion, p.implementationVersion, p.description));
	}
}

bool LayerProperties::CheckSupport(const std::vector<std::string> & required) {
	Vector prop;
	Enumerate(prop);

	for (auto & req : required) {
		bool found = false;
		for (auto & p : prop) {
			if (req == p.layerName) {
				found = true;
				break;
			}
		}

		if (!found) {
			return false;
		}
	}
	return true;
}

bool LayerProperties::CheckSupport(const std::string & name) {
	Vector prop;
	Enumerate(prop);

	for (auto & p : prop) {
		if (name == p.layerName) {
			return true;
		}
	}
	return false;
}

LayerProperties::LayerProperties(const char * name, uint32_t specVersion, uint32_t implementationVersion, const char * description)
	:layerName(name)
	,specVersion(specVersion)
	,implementationVersion(implementationVersion)
	,description(description)
{
}
/* End layer properties */

/* Physical device */
const int32_t PHYSICAL_DEVICE_TYPE_OTHER = VK_PHYSICAL_DEVICE_TYPE_OTHER;
const int32_t PHYSICAL_DEVICE_TYPE_INTEGRATED_GPU = VK_PHYSICAL_DEVICE_TYPE_INTEGRATED_GPU;
const int32_t PHYSICAL_DEVICE_TYPE_DISCRETE_GPU = VK_PHYSICAL_DEVICE_TYPE_DISCRETE_GPU;
const int32_t PHYSICAL_DEVICE_TYPE_VIRTUAL_GPU = VK_PHYSICAL_DEVICE_TYPE_VIRTUAL_GPU;
const int32_t PHYSICAL_DEVICE_TYPE_CPU = VK_PHYSICAL_DEVICE_TYPE_CPU;
const int32_t PHYSICAL_DEVICE_TYPE_BEGIN_RANGE = VK_PHYSICAL_DEVICE_TYPE_BEGIN_RANGE;
const int32_t PHYSICAL_DEVICE_TYPE_END_RANGE = VK_PHYSICAL_DEVICE_TYPE_END_RANGE;
const int32_t PHYSICAL_DEVICE_TYPE_RANGE_SIZE = VK_PHYSICAL_DEVICE_TYPE_RANGE_SIZE;
const int32_t PHYSICAL_DEVICE_TYPE_MAX_ENUM = VK_PHYSICAL_DEVICE_TYPE_MAX_ENUM;

const int32_t MEMORY_PROPERTY_DEVICE_LOCAL_BIT = VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT;
const int32_t MEMORY_PROPERTY_HOST_VISIBLE_BIT = VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT;
const int32_t MEMORY_PROPERTY_HOST_COHERENT_BIT = VK_MEMORY_PROPERTY_HOST_COHERENT_BIT;
const int32_t MEMORY_PROPERTY_HOST_CACHED_BIT = VK_MEMORY_PROPERTY_HOST_CACHED_BIT;
const int32_t MEMORY_PROPERTY_LAZILY_ALLOCATED_BIT = VK_MEMORY_PROPERTY_LAZILY_ALLOCATED_BIT;
const int32_t MEMORY_PROPERTY_PROTECTED_BIT = VK_MEMORY_PROPERTY_PROTECTED_BIT;
const int32_t MEMORY_PROPERTY_FLAG_BITS_MAX_ENUM = VK_MEMORY_PROPERTY_FLAG_BITS_MAX_ENUM;

const uint32_t MEMORY_HEAP_DEVICE_LOCAL_BIT = VK_MEMORY_HEAP_DEVICE_LOCAL_BIT;
const uint32_t MEMORY_HEAP_MULTI_INSTANCE_BIT = VK_MEMORY_HEAP_MULTI_INSTANCE_BIT;
const uint32_t MEMORY_HEAP_MULTI_INSTANCE_BIT_KHR = VK_MEMORY_HEAP_MULTI_INSTANCE_BIT_KHR;
const uint32_t MEMORY_HEAP_FLAG_BITS_MAX_ENUM = VK_MEMORY_HEAP_FLAG_BITS_MAX_ENUM;

const uint32_t QUEUE_GRAPHICS_BIT = VK_QUEUE_GRAPHICS_BIT;
const uint32_t QUEUE_COMPUTE_BIT = VK_QUEUE_COMPUTE_BIT;
const uint32_t QUEUE_TRANSFER_BIT = VK_QUEUE_TRANSFER_BIT;
const uint32_t QUEUE_SPARSE_BINDING_BIT = VK_QUEUE_SPARSE_BINDING_BIT;
const uint32_t QUEUE_PROTECTED_BIT = VK_QUEUE_PROTECTED_BIT;
const uint32_t QUEUE_FLAG_BITS_MAX_ENUM = VK_QUEUE_FLAG_BITS_MAX_ENUM;

const uint32_t COMPOSITE_ALPHA_OPAQUE_BIT_KHR = VK_COMPOSITE_ALPHA_OPAQUE_BIT_KHR;
const uint32_t COMPOSITE_ALPHA_PRE_MULTIPLIED_BIT_KHR = VK_COMPOSITE_ALPHA_PRE_MULTIPLIED_BIT_KHR;
const uint32_t COMPOSITE_ALPHA_POST_MULTIPLIED_BIT_KHR = VK_COMPOSITE_ALPHA_POST_MULTIPLIED_BIT_KHR;
const uint32_t COMPOSITE_ALPHA_INHERIT_BIT_KHR = VK_COMPOSITE_ALPHA_INHERIT_BIT_KHR;
const uint32_t COMPOSITE_ALPHA_FLAG_BITS_MAX_ENUM_KHR = VK_COMPOSITE_ALPHA_FLAG_BITS_MAX_ENUM_KHR;

void getVkDeviceLimits(const VkPhysicalDeviceLimits & vkLim, PhysicalDeviceLimits & lim) {
	lim.maxImageDimension1D = vkLim.maxImageDimension1D;
	lim.maxImageDimension2D = vkLim.maxImageDimension2D;
	lim.maxImageDimension3D = vkLim.maxImageDimension3D;
	lim.maxImageDimensionCube = vkLim.maxImageDimensionCube;
	lim.maxImageArrayLayers = vkLim.maxImageArrayLayers;
	lim.maxTexelBufferElements = vkLim.maxTexelBufferElements;
	lim.maxUniformBufferRange = vkLim.maxUniformBufferRange;
	lim.maxStorageBufferRange = vkLim.maxStorageBufferRange;
	lim.maxPushConstantsSize = vkLim.maxPushConstantsSize;
	lim.maxMemoryAllocationCount = vkLim.maxMemoryAllocationCount;
	lim.maxSamplerAllocationCount = vkLim.maxSamplerAllocationCount;
	lim.bufferImageGranularity = vkLim.bufferImageGranularity;
	lim.sparseAddressSpaceSize = vkLim.sparseAddressSpaceSize;
	lim.maxBoundDescriptorSets = vkLim.maxBoundDescriptorSets;
	lim.maxPerStageDescriptorSamplers = vkLim.maxPerStageDescriptorSamplers;
	lim.maxPerStageDescriptorUniformBuffers = vkLim.maxPerStageDescriptorUniformBuffers;
	lim.maxPerStageDescriptorStorageBuffers = vkLim.maxPerStageDescriptorStorageBuffers;
	lim.maxPerStageDescriptorSampledImages = vkLim.maxPerStageDescriptorSampledImages;
	lim.maxPerStageDescriptorStorageImages = vkLim.maxPerStageDescriptorStorageImages;
	lim.maxPerStageDescriptorInputAttachments = vkLim.maxPerStageDescriptorInputAttachments;
	lim.maxPerStageResources = vkLim.maxPerStageResources;
	lim.maxDescriptorSetSamplers = vkLim.maxDescriptorSetSamplers;
	lim.maxDescriptorSetUniformBuffers = vkLim.maxDescriptorSetUniformBuffers;
	lim.maxDescriptorSetUniformBuffersDynamic = vkLim.maxDescriptorSetUniformBuffersDynamic;
	lim.maxDescriptorSetStorageBuffers = vkLim.maxDescriptorSetStorageBuffers;
	lim.maxDescriptorSetStorageBuffersDynamic = vkLim.maxDescriptorSetStorageBuffersDynamic;
	lim.maxDescriptorSetSampledImages = vkLim.maxDescriptorSetSampledImages;
	lim.maxDescriptorSetStorageImages = vkLim.maxDescriptorSetStorageImages;
	lim.maxDescriptorSetInputAttachments = vkLim.maxDescriptorSetInputAttachments;
	lim.maxVertexInputAttributes = vkLim.maxVertexInputAttributes;
	lim.maxVertexInputBindings = vkLim.maxVertexInputBindings;
	lim.maxVertexInputAttributeOffset = vkLim.maxVertexInputAttributeOffset;
	lim.maxVertexInputBindingStride = vkLim.maxVertexInputBindingStride;
	lim.maxVertexOutputComponents = vkLim.maxVertexOutputComponents;
	lim.maxTessellationGenerationLevel = vkLim.maxTessellationGenerationLevel;
	lim.maxTessellationPatchSize = vkLim.maxTessellationPatchSize;
	lim.maxTessellationControlPerVertexInputComponents = vkLim.maxTessellationControlPerVertexInputComponents;
	lim.maxTessellationControlPerVertexOutputComponents = vkLim.maxTessellationControlPerVertexOutputComponents;
	lim.maxTessellationControlPerPatchOutputComponents = vkLim.maxTessellationControlPerPatchOutputComponents;
	lim.maxTessellationControlTotalOutputComponents = vkLim.maxTessellationControlTotalOutputComponents;
	lim.maxTessellationEvaluationInputComponents = vkLim.maxTessellationEvaluationInputComponents;
	lim.maxTessellationEvaluationOutputComponents = vkLim.maxTessellationEvaluationOutputComponents;
	lim.maxGeometryShaderInvocations = vkLim.maxGeometryShaderInvocations;
	lim.maxGeometryInputComponents = vkLim.maxGeometryInputComponents;
	lim.maxGeometryOutputComponents = vkLim.maxGeometryOutputComponents;
	lim.maxGeometryOutputVertices = vkLim.maxGeometryOutputVertices;
	lim.maxGeometryTotalOutputComponents = vkLim.maxGeometryTotalOutputComponents;
	lim.maxFragmentInputComponents = vkLim.maxFragmentInputComponents;
	lim.maxFragmentOutputAttachments = vkLim.maxFragmentOutputAttachments;
	lim.maxFragmentDualSrcAttachments = vkLim.maxFragmentDualSrcAttachments;
	lim.maxFragmentCombinedOutputResources = vkLim.maxFragmentCombinedOutputResources;
	lim.maxComputeSharedMemorySize = vkLim.maxComputeSharedMemorySize;
	lim.maxComputeWorkGroupCount[0] = vkLim.maxComputeWorkGroupCount[0];
	lim.maxComputeWorkGroupCount[1] = vkLim.maxComputeWorkGroupCount[1];
	lim.maxComputeWorkGroupCount[2] = vkLim.maxComputeWorkGroupCount[2];
	lim.maxComputeWorkGroupInvocations = vkLim.maxComputeWorkGroupInvocations;
	lim.maxComputeWorkGroupSize[0] = vkLim.maxComputeWorkGroupSize[0];
	lim.maxComputeWorkGroupSize[1] = vkLim.maxComputeWorkGroupSize[1];
	lim.maxComputeWorkGroupSize[2] = vkLim.maxComputeWorkGroupSize[2];
	lim.subPixelPrecisionBits = vkLim.subPixelPrecisionBits;
	lim.subTexelPrecisionBits = vkLim.subTexelPrecisionBits;
	lim.mipmapPrecisionBits = vkLim.mipmapPrecisionBits;
	lim.maxDrawIndexedIndexValue = vkLim.maxDrawIndexedIndexValue;
	lim.maxDrawIndirectCount = vkLim.maxDrawIndirectCount;
	lim.maxSamplerLodBias = vkLim.maxSamplerLodBias;
	lim.maxSamplerAnisotropy = vkLim.maxSamplerAnisotropy;
	lim.maxViewports = vkLim.maxViewports;
	lim.maxViewportDimensions[0] = vkLim.maxViewportDimensions[0];
	lim.maxViewportDimensions[1] = vkLim.maxViewportDimensions[1];
	lim.viewportBoundsRange[0] = vkLim.viewportBoundsRange[0];
	lim.viewportBoundsRange[1] = vkLim.viewportBoundsRange[1];
	lim.viewportSubPixelBits = vkLim.viewportSubPixelBits;
	lim.minMemoryMapAlignment = vkLim.minMemoryMapAlignment;
	lim.minTexelBufferOffsetAlignment = vkLim.minTexelBufferOffsetAlignment;
	lim.minUniformBufferOffsetAlignment = vkLim.minUniformBufferOffsetAlignment;
	lim.minStorageBufferOffsetAlignment = vkLim.minStorageBufferOffsetAlignment;
	lim.minTexelOffset = vkLim.minTexelOffset;
	lim.maxTexelOffset = vkLim.maxTexelOffset;
	lim.minTexelGatherOffset = vkLim.minTexelGatherOffset;
	lim.maxTexelGatherOffset = vkLim.maxTexelGatherOffset;
	lim.minInterpolationOffset = vkLim.minInterpolationOffset;
	lim.maxInterpolationOffset = vkLim.maxInterpolationOffset;
	lim.subPixelInterpolationOffsetBits = vkLim.subPixelInterpolationOffsetBits;
	lim.maxFramebufferWidth = vkLim.maxFramebufferWidth;
	lim.maxFramebufferHeight = vkLim.maxFramebufferHeight;
	lim.maxFramebufferLayers = vkLim.maxFramebufferLayers;
	lim.framebufferColorSampleCounts = vkLim.framebufferColorSampleCounts;
	lim.framebufferDepthSampleCounts = vkLim.framebufferDepthSampleCounts;
	lim.framebufferStencilSampleCounts = vkLim.framebufferStencilSampleCounts;
	lim.framebufferNoAttachmentsSampleCounts = vkLim.framebufferNoAttachmentsSampleCounts;
	lim.maxColorAttachments = vkLim.maxColorAttachments;
	lim.sampledImageColorSampleCounts = vkLim.sampledImageColorSampleCounts;
	lim.sampledImageIntegerSampleCounts = vkLim.sampledImageIntegerSampleCounts;
	lim.sampledImageDepthSampleCounts = vkLim.sampledImageDepthSampleCounts;
	lim.sampledImageStencilSampleCounts = vkLim.sampledImageStencilSampleCounts;
	lim.storageImageSampleCounts = vkLim.storageImageSampleCounts;
	lim.maxSampleMaskWords = vkLim.maxSampleMaskWords;
	lim.timestampComputeAndGraphics = vkLim.timestampComputeAndGraphics;
	lim.timestampPeriod = vkLim.timestampPeriod;
	lim.maxClipDistances = vkLim.maxClipDistances;
	lim.maxCullDistances = vkLim.maxCullDistances;
	lim.maxCombinedClipAndCullDistances = vkLim.maxCombinedClipAndCullDistances;
	lim.discreteQueuePriorities = vkLim.discreteQueuePriorities;
	lim.pointSizeRange[0] = vkLim.pointSizeRange[0];
	lim.pointSizeRange[1] = vkLim.pointSizeRange[1];
	lim.lineWidthRange[0] = vkLim.lineWidthRange[0];
	lim.lineWidthRange[1] = vkLim.lineWidthRange[1];
	lim.pointSizeGranularity = vkLim.pointSizeGranularity;
	lim.lineWidthGranularity = vkLim.lineWidthGranularity;
	lim.strictLines = vkLim.strictLines;
	lim.standardSampleLocations = vkLim.standardSampleLocations;
	lim.optimalBufferCopyOffsetAlignment = vkLim.optimalBufferCopyOffsetAlignment;
	lim.optimalBufferCopyRowPitchAlignment = vkLim.optimalBufferCopyRowPitchAlignment;
	lim.nonCoherentAtomSize = vkLim.nonCoherentAtomSize;
}

void getVkSparseProperties(const VkPhysicalDeviceSparseProperties & vkProp, PhysicalDeviceSparseProperties & prop) {
	prop.residencyStandard2DBlockShape = vkProp.residencyStandard2DBlockShape;
	prop.residencyStandard2DMultisampleBlockShape = vkProp.residencyStandard2DMultisampleBlockShape;
	prop.residencyStandard3DBlockShape = vkProp.residencyStandard3DBlockShape;
	prop.residencyAlignedMipSize = vkProp.residencyAlignedMipSize;
	prop.residencyNonResidentStrict = vkProp.residencyNonResidentStrict;
}

void PhysicalDevice::Enumerate(Instance * instance, Vector & result) {
	uint32_t deviceCount = 0;
	VkInstance vkInst = bg::native_cast<VkInstance>(instance->vkInstance());
	vkEnumeratePhysicalDevices(vkInst, &deviceCount, nullptr);
	std::vector<VkPhysicalDevice> devices(deviceCount);
	vkEnumeratePhysicalDevices(vkInst, &deviceCount, devices.data());

	for (auto d : devices) {
		VkPhysicalDeviceProperties props;
		vkGetPhysicalDeviceProperties(d, &props);
		PhysicalDevice * dev = new PhysicalDevice();
		dev->_vk_device = d;
		dev->_instance = instance;

		dev->apiVersion = props.apiVersion;
		dev->driverVersion = props.driverVersion;
		dev->vendorID = props.vendorID;
		dev->deviceID = props.deviceID;
		dev->deviceName = props.deviceName;
		dev->deviceType = props.deviceType;
		for (auto i = 0; i < BG_VK_UUID_SIZE; ++i) {
			dev->pipelineCacheUUID[i] = dev->pipelineCacheUUID[i];
		}
		getVkDeviceLimits(props.limits, dev->limits);
		getVkSparseProperties(props.sparseProperties, dev->sparseProperties);

		result.push_back(dev);
		
		switch (dev->vendorID) {
		case 0x1002:
			dev->vendorName = "AMD";
			break;
		case 0x1010:
			dev->vendorName = "ImageGec";
			break;
		case 0x10DE:
			dev->vendorName = "NVIDIA";
			break;
		case 0x13B5:
			dev->vendorName = "ARM";
			break;
		case 0x5143:
			dev->vendorName = "Qualcomm";
			break;
		case 0x8086:
			dev->vendorName = "Intel";
			break;
		default:
			dev->vendorName = "Unknown";
		}

		VkPhysicalDeviceMemoryProperties mem;
		vkGetPhysicalDeviceMemoryProperties(d, &mem);

		dev->memoryProperties.memoryTypeCount = mem.memoryTypeCount;
		for (uint32_t i = 0; i < mem.memoryTypeCount; ++i) {
			dev->memoryProperties.memoryTypes[i].heapIndex = mem.memoryTypes[i].heapIndex;
			dev->memoryProperties.memoryTypes[i].propertyFlags = mem.memoryTypes[i].propertyFlags;
		}

		dev->memoryProperties.memoryHeapCount = mem.memoryHeapCount;
		for (uint32_t i = 0; i < mem.memoryHeapCount; ++i) {
			dev->memoryProperties.memoryHeaps[i].size = mem.memoryHeaps[i].size;
			dev->memoryProperties.memoryHeaps[i].flags = mem.memoryHeaps[i].flags;
		}

		// Build VRAM size and VRAM string
		for (uint32_t i = 0; i < dev->memoryProperties.memoryHeapCount; ++i) {
			auto & heap = dev->memoryProperties.memoryHeaps[i];
			if (heap.flags & MEMORY_PROPERTY_DEVICE_LOCAL_BIT) {
				dev->vramSize = heap.size;
				break;
			}
		}
		uint64_t vramReadable = dev->vramSize / 1000000;
		std::string units = "MB";
		if (vramReadable > 1000) {
			vramReadable /= 1000;
			units = "GB";
		}
		dev->vramString = std::to_string(vramReadable) + units;

		ExtensionProperties::Enumerate(dev, dev->extensions);

		uint32_t queuePropCount;
		vkGetPhysicalDeviceQueueFamilyProperties(d, &queuePropCount, nullptr);
		std::vector<VkQueueFamilyProperties> queueProps(queuePropCount);
		vkGetPhysicalDeviceQueueFamilyProperties(d, &queuePropCount, queueProps.data());
		for (auto & q : queueProps) {
			dev->queueFamilyProperties.push_back(QueueFamilyProperties{
					q.queueFlags,
					q.queueCount,
					q.timestampValidBits,
					Extent3D{
						q.minImageTransferGranularity.width,
						q.minImageTransferGranularity.height,
						q.minImageTransferGranularity.depth
					}
				});
		}
	}
}

PhysicalDevice::PhysicalDevice()
{

}

PhysicalDevice::~PhysicalDevice() {

}
/* End physical device */

/* SurfaceKHR */

const uint32_t SURFACE_TRANSFORM_IDENTITY_BIT_KHR = VK_SURFACE_TRANSFORM_IDENTITY_BIT_KHR;
const uint32_t SURFACE_TRANSFORM_ROTATE_90_BIT_KHR = VK_SURFACE_TRANSFORM_ROTATE_90_BIT_KHR;
const uint32_t SURFACE_TRANSFORM_ROTATE_180_BIT_KHR = VK_SURFACE_TRANSFORM_ROTATE_180_BIT_KHR;
const uint32_t SURFACE_TRANSFORM_ROTATE_270_BIT_KHR = VK_SURFACE_TRANSFORM_ROTATE_270_BIT_KHR;
const uint32_t SURFACE_TRANSFORM_HORIZONTAL_MIRROR_BIT_KHR = VK_SURFACE_TRANSFORM_HORIZONTAL_MIRROR_BIT_KHR;
const uint32_t SURFACE_TRANSFORM_HORIZONTAL_MIRROR_ROTATE_90_BIT_KHR = VK_SURFACE_TRANSFORM_HORIZONTAL_MIRROR_ROTATE_90_BIT_KHR;
const uint32_t SURFACE_TRANSFORM_HORIZONTAL_MIRROR_ROTATE_180_BIT_KHR = VK_SURFACE_TRANSFORM_HORIZONTAL_MIRROR_ROTATE_180_BIT_KHR;
const uint32_t SURFACE_TRANSFORM_HORIZONTAL_MIRROR_ROTATE_270_BIT_KHR = VK_SURFACE_TRANSFORM_HORIZONTAL_MIRROR_ROTATE_270_BIT_KHR;
const uint32_t SURFACE_TRANSFORM_INHERIT_BIT_KHR = VK_SURFACE_TRANSFORM_INHERIT_BIT_KHR;
const uint32_t SURFACE_TRANSFORM_FLAG_BITS_MAX_ENUM_KHR = VK_SURFACE_TRANSFORM_FLAG_BITS_MAX_ENUM_KHR;

const uint32_t IMAGE_USAGE_TRANSFER_SRC_BIT = VK_IMAGE_USAGE_TRANSFER_SRC_BIT;
const uint32_t IMAGE_USAGE_TRANSFER_DST_BIT = VK_IMAGE_USAGE_TRANSFER_DST_BIT;
const uint32_t IMAGE_USAGE_SAMPLED_BIT = VK_IMAGE_USAGE_SAMPLED_BIT;
const uint32_t IMAGE_USAGE_STORAGE_BIT = VK_IMAGE_USAGE_STORAGE_BIT;
const uint32_t IMAGE_USAGE_COLOR_ATTACHMENT_BIT = VK_IMAGE_USAGE_COLOR_ATTACHMENT_BIT;
const uint32_t IMAGE_USAGE_DEPTH_STENCIL_ATTACHMENT_BIT = VK_IMAGE_USAGE_DEPTH_STENCIL_ATTACHMENT_BIT;
const uint32_t IMAGE_USAGE_TRANSIENT_ATTACHMENT_BIT = VK_IMAGE_USAGE_TRANSIENT_ATTACHMENT_BIT;
const uint32_t IMAGE_USAGE_INPUT_ATTACHMENT_BIT = VK_IMAGE_USAGE_INPUT_ATTACHMENT_BIT;
const uint32_t IMAGE_USAGE_FLAG_BITS_MAX_ENUM = VK_IMAGE_USAGE_FLAG_BITS_MAX_ENUM;

const uint32_t PRESENT_MODE_IMMEDIATE_KHR = VK_PRESENT_MODE_IMMEDIATE_KHR;
const uint32_t PRESENT_MODE_MAILBOX_KHR = VK_PRESENT_MODE_MAILBOX_KHR;
const uint32_t PRESENT_MODE_FIFO_KHR = VK_PRESENT_MODE_FIFO_KHR;
const uint32_t PRESENT_MODE_FIFO_RELAXED_KHR = VK_PRESENT_MODE_FIFO_RELAXED_KHR;
const uint32_t PRESENT_MODE_SHARED_DEMAND_REFRESH_KHR = VK_PRESENT_MODE_SHARED_DEMAND_REFRESH_KHR;
const uint32_t PRESENT_MODE_SHARED_CONTINUOUS_REFRESH_KHR = VK_PRESENT_MODE_SHARED_CONTINUOUS_REFRESH_KHR;
const uint32_t PRESENT_MODE_BEGIN_RANGE_KHR = VK_PRESENT_MODE_BEGIN_RANGE_KHR;
const uint32_t PRESENT_MODE_END_RANGE_KHR = VK_PRESENT_MODE_END_RANGE_KHR;
const uint32_t PRESENT_MODE_RANGE_SIZE_KHR = VK_PRESENT_MODE_RANGE_SIZE_KHR;
const uint32_t PRESENT_MODE_MAX_ENUM_KHR = VK_PRESENT_MODE_MAX_ENUM_KHR;

const uint32_t SHARING_MODE_EXCLUSIVE = VK_SHARING_MODE_EXCLUSIVE;
const uint32_t SHARING_MODE_CONCURRENT = VK_SHARING_MODE_CONCURRENT;
const uint32_t SHARING_MODE_BEGIN_RANGE = VK_SHARING_MODE_BEGIN_RANGE;
const uint32_t SHARING_MODE_END_RANGE = VK_SHARING_MODE_END_RANGE;
const uint32_t SHARING_MODE_RANGE_SIZE = VK_SHARING_MODE_RANGE_SIZE;
const uint32_t SHARING_MODE_MAX_ENUM = VK_SHARING_MODE_MAX_ENUM;

const uint32_t IMAGE_VIEW_TYPE_1D = VK_IMAGE_VIEW_TYPE_1D;
const uint32_t IMAGE_VIEW_TYPE_2D = VK_IMAGE_VIEW_TYPE_2D;
const uint32_t IMAGE_VIEW_TYPE_3D = VK_IMAGE_VIEW_TYPE_3D;
const uint32_t IMAGE_VIEW_TYPE_CUBE = VK_IMAGE_VIEW_TYPE_CUBE;
const uint32_t IMAGE_VIEW_TYPE_1D_ARRAY = VK_IMAGE_VIEW_TYPE_1D_ARRAY;
const uint32_t IMAGE_VIEW_TYPE_2D_ARRAY = VK_IMAGE_VIEW_TYPE_2D_ARRAY;
const uint32_t IMAGE_VIEW_TYPE_CUBE_ARRAY = VK_IMAGE_VIEW_TYPE_CUBE_ARRAY;
const uint32_t IMAGE_VIEW_TYPE_BEGIN_RANGE = VK_IMAGE_VIEW_TYPE_BEGIN_RANGE;
const uint32_t IMAGE_VIEW_TYPE_END_RANGE = VK_IMAGE_VIEW_TYPE_END_RANGE;
const uint32_t IMAGE_VIEW_TYPE_RANGE_SIZE = VK_IMAGE_VIEW_TYPE_RANGE_SIZE;
const uint32_t IMAGE_VIEW_TYPE_MAX_ENUM = VK_IMAGE_VIEW_TYPE_MAX_ENUM;

const uint32_t COMPONENT_SWIZZLE_IDENTITY = VK_COMPONENT_SWIZZLE_IDENTITY;
const uint32_t COMPONENT_SWIZZLE_ZERO = VK_COMPONENT_SWIZZLE_ZERO;
const uint32_t COMPONENT_SWIZZLE_ONE = VK_COMPONENT_SWIZZLE_ONE;
const uint32_t COMPONENT_SWIZZLE_R = VK_COMPONENT_SWIZZLE_R;
const uint32_t COMPONENT_SWIZZLE_G = VK_COMPONENT_SWIZZLE_G;
const uint32_t COMPONENT_SWIZZLE_B = VK_COMPONENT_SWIZZLE_B;
const uint32_t COMPONENT_SWIZZLE_A = VK_COMPONENT_SWIZZLE_A;
const uint32_t COMPONENT_SWIZZLE_BEGIN_RANGE = VK_COMPONENT_SWIZZLE_BEGIN_RANGE;
const uint32_t COMPONENT_SWIZZLE_END_RANGE = VK_COMPONENT_SWIZZLE_END_RANGE;
const uint32_t COMPONENT_SWIZZLE_RANGE_SIZE = VK_COMPONENT_SWIZZLE_RANGE_SIZE;
const uint32_t COMPONENT_SWIZZLE_MAX_ENUM = VK_COMPONENT_SWIZZLE_MAX_ENUM;

const uint32_t IMAGE_ASPECT_COLOR_BIT = VK_IMAGE_ASPECT_COLOR_BIT;
const uint32_t IMAGE_ASPECT_DEPTH_BIT = VK_IMAGE_ASPECT_DEPTH_BIT;
const uint32_t IMAGE_ASPECT_STENCIL_BIT = VK_IMAGE_ASPECT_STENCIL_BIT;
const uint32_t IMAGE_ASPECT_METADATA_BIT = VK_IMAGE_ASPECT_METADATA_BIT;
const uint32_t IMAGE_ASPECT_PLANE_0_BIT = VK_IMAGE_ASPECT_PLANE_0_BIT;
const uint32_t IMAGE_ASPECT_PLANE_1_BIT = VK_IMAGE_ASPECT_PLANE_1_BIT;
const uint32_t IMAGE_ASPECT_PLANE_2_BIT = VK_IMAGE_ASPECT_PLANE_2_BIT;
const uint32_t IMAGE_ASPECT_PLANE_0_BIT_KHR = VK_IMAGE_ASPECT_PLANE_0_BIT_KHR;
const uint32_t IMAGE_ASPECT_PLANE_1_BIT_KHR = VK_IMAGE_ASPECT_PLANE_1_BIT_KHR;
const uint32_t IMAGE_ASPECT_PLANE_2_BIT_KHR = VK_IMAGE_ASPECT_PLANE_2_BIT_KHR;
const uint32_t IMAGE_ASPECT_FLAG_BITS_MAX_ENUM = VK_IMAGE_ASPECT_FLAG_BITS_MAX_ENUM;

SurfaceKHR::SurfaceKHR() {
}

SurfaceKHR::~SurfaceKHR() {
	if (_vk_surface) {
		VkInstance inst = bg::native_cast<VkInstance>(_vk_instance);
		VkSurfaceKHR surface = bg::native_cast<VkSurfaceKHR>(_vk_surface);
		vkDestroySurfaceKHR(inst, surface, nullptr);
		_vk_instance = nullptr;
		_vk_surface = nullptr;
	}
}

void SurfaceKHR::create(Instance * instance, bg::wnd::Window * window) {
	VkSurfaceKHR vkSurface;

#if BG2E_WINDOWS==1
	bg::wnd::Win32Window * win32Window = dynamic_cast<bg::wnd::Win32Window*>(window);
	if (win32Window) {
		VkWin32SurfaceCreateInfoKHR info = {};
		info.sType = VK_STRUCTURE_TYPE_WIN32_SURFACE_CREATE_INFO_KHR;
		info.hinstance = bg::native_cast<HINSTANCE>(win32Window->hInstance());
		info.hwnd = bg::native_cast<HWND>(win32Window->hWnd());
		if (vkCreateWin32SurfaceKHR(bg::native_cast<VkInstance>(instance->vkInstance()), &info, nullptr, &vkSurface) != VK_SUCCESS) {
			throw bg::base::VulkanEngineException("Error creating Win32 Vulkan surface.");
		}
	}
	else {
		throw bg::base::VulkanEngineException("Error creating Vulkan surface: invalid window found.");
	}
#elif BG2E_MAC==1
	bg::wnd::CocoaMVKContext * context = window != nullptr ? dynamic_cast<bg::wnd::CocoaMVKContext*>(window->context()) : nullptr;
	if (context) {
		VkMacOSSurfaceCreateInfoMVK createInfo = {};
		createInfo.sType = VK_STRUCTURE_TYPE_MACOS_SURFACE_CREATE_INFO_MVK;
		createInfo.pNext = nullptr;
		createInfo.flags = 0;
		createInfo.pView = context->cocoaView();
		if (vkCreateMacOSSurfaceMVK(bg::native_cast<VkInstance>(instance->vkInstance()), &createInfo, nullptr, &vkSurface) != VK_SUCCESS) {
			throw bg::base::VulkanEngineException("Error creating MacOS Vulkan surface.");
		}
	}
	else {
		throw bg::base::VulkanEngineException("Error creating surface: invalid window found.");
	}
#elif BG2E_LINUX==1
#endif

	_vk_instance = instance->vkInstance();
	_vk_surface = vkSurface;
}

void SurfaceKHR::getCapabilities(PhysicalDevice * dev, SurfaceCapabilitiesKHR & capabilities) {
	VkSurfaceKHR vkSurface = bg::native_cast<VkSurfaceKHR>(_vk_surface);

	VkSurfaceCapabilitiesKHR surfaceCapabilities;
	vkGetPhysicalDeviceSurfaceCapabilitiesKHR(bg::native_cast<VkPhysicalDevice>(dev->vkDevice()), vkSurface, &surfaceCapabilities);
	capabilities.minImageCount = surfaceCapabilities.minImageCount;
	capabilities.maxImageCount = surfaceCapabilities.maxImageCount;
	capabilities.currentExtent.width = surfaceCapabilities.currentExtent.width;
	capabilities.currentExtent.height = surfaceCapabilities.currentExtent.height;
	capabilities.minImageExtent.width = surfaceCapabilities.minImageExtent.width;
	capabilities.minImageExtent.height = surfaceCapabilities.minImageExtent.height;
	capabilities.maxImageExtent.width = surfaceCapabilities.maxImageExtent.width;
	capabilities.maxImageExtent.height = surfaceCapabilities.maxImageExtent.height;
	capabilities.supportedTransforms = surfaceCapabilities.supportedTransforms;
	capabilities.currentTransform = surfaceCapabilities.currentTransform;
	capabilities.supportedCompositeAlpha = surfaceCapabilities.supportedCompositeAlpha;
	capabilities.supportedUsageFlags = surfaceCapabilities.supportedUsageFlags;
	capabilities.maxImageArrayLayers = surfaceCapabilities.maxImageArrayLayers;
}

void SurfaceKHR::getFormats(PhysicalDevice * dev, std::vector<SurfaceFormatKHR> & formats) {
	VkSurfaceKHR vkSurface = bg::native_cast<VkSurfaceKHR>(_vk_surface);

	uint32_t fmtCount = 0;
	vkGetPhysicalDeviceSurfaceFormatsKHR(bg::native_cast<VkPhysicalDevice>(dev->vkDevice()), vkSurface, &fmtCount, nullptr);
	std::vector<VkSurfaceFormatKHR> vkFormats(fmtCount);
	vkGetPhysicalDeviceSurfaceFormatsKHR(bg::native_cast<VkPhysicalDevice>(dev->vkDevice()), vkSurface, &fmtCount, vkFormats.data());
	for (auto fmt : vkFormats) {
		formats.push_back(SurfaceFormatKHR{ static_cast<Format>(fmt.format), static_cast<ColorSpaceKHR>(fmt.colorSpace) });
	}
}

void SurfaceKHR::getPresentModes(PhysicalDevice * dev, std::vector<PresentModeKHR> & presentModes) {
    uint32_t count;
    VkSurfaceKHR surface = bg::native_cast<VkSurfaceKHR>(_vk_surface);
    vkGetPhysicalDeviceSurfacePresentModesKHR(bg::native_cast<VkPhysicalDevice>(dev->vkDevice()), surface, &count, nullptr);
    if (count>0) {
        std::vector<VkPresentModeKHR> modes(count);
        vkGetPhysicalDeviceSurfacePresentModesKHR(bg::native_cast<VkPhysicalDevice>(dev->vkDevice()), surface, &count, modes.data());
        for (auto pm : modes) {
            presentModes.push_back(pm);
        }
    }
}

/* End SurfaceKHR */


/* Device */
Device::~Device() {
	if (_vk_device) {
		// Invalidate queues
		for (auto & q : _queues) {
			q->_vk_queue = nullptr;
			q->_device = nullptr;
		}
		_queues.clear();

		VkDevice dev = bg::native_cast<VkDevice>(_vk_device);
		vkDestroyDevice(dev, nullptr);
		_vk_device = nullptr;
	}
}

void Device::setEnabledExtensions(const std::vector<std::string> & ext) {
	for (auto e : ext) {
		_extensions.push_back(e);
	}
}

void Device::setEnabledLayers(const std::vector<std::string> & layers) {
	for (auto l : layers) {
		_layers.push_back(l);
	}
}

void Device::create(PhysicalDevice * physicalDev, const std::set<int32_t> queueFamilies) {
    std::vector<VkDeviceQueueCreateInfo> queueCreateInfos;
    float queuePriority = 1.0f;
    for (int32_t queueFamily : queueFamilies) {
        VkDeviceQueueCreateInfo queueCreateInfo = {};
        queueCreateInfo.sType = VK_STRUCTURE_TYPE_DEVICE_QUEUE_CREATE_INFO;
        queueCreateInfo.queueFamilyIndex = queueFamily;
        queueCreateInfo.queueCount = 1;
        queueCreateInfo.pQueuePriorities = &queuePriority;
        queueCreateInfos.push_back(queueCreateInfo);
    }
    
	VkPhysicalDeviceFeatures features = {};
	
	features.robustBufferAccess = enabledFeatures.robustBufferAccess;
	features.fullDrawIndexUint32 = enabledFeatures.fullDrawIndexUint32;
	features.imageCubeArray = enabledFeatures.imageCubeArray;
	features.independentBlend = enabledFeatures.independentBlend;
	features.geometryShader = enabledFeatures.geometryShader;
	features.tessellationShader = enabledFeatures.tessellationShader;
	features.sampleRateShading = enabledFeatures.sampleRateShading;
	features.dualSrcBlend = enabledFeatures.dualSrcBlend;
	features.logicOp = enabledFeatures.logicOp;
	features.multiDrawIndirect = enabledFeatures.multiDrawIndirect;
	features.drawIndirectFirstInstance = enabledFeatures.drawIndirectFirstInstance;
	features.depthClamp = enabledFeatures.depthClamp;
	features.depthBiasClamp = enabledFeatures.depthBiasClamp;
	features.fillModeNonSolid = enabledFeatures.fillModeNonSolid;
	features.depthBounds = enabledFeatures.depthBounds;
	features.wideLines = enabledFeatures.wideLines;
	features.largePoints = enabledFeatures.largePoints;
	features.alphaToOne = enabledFeatures.alphaToOne;
	features.multiViewport = enabledFeatures.multiViewport;
	features.samplerAnisotropy = enabledFeatures.samplerAnisotropy;
	features.textureCompressionETC2 = enabledFeatures.textureCompressionETC2;
	features.textureCompressionASTC_LDR = enabledFeatures.textureCompressionASTC_LDR;
	features.textureCompressionBC = enabledFeatures.textureCompressionBC;
	features.occlusionQueryPrecise = enabledFeatures.occlusionQueryPrecise;
	features.pipelineStatisticsQuery = enabledFeatures.pipelineStatisticsQuery;
	features.vertexPipelineStoresAndAtomics = enabledFeatures.vertexPipelineStoresAndAtomics;
	features.fragmentStoresAndAtomics = enabledFeatures.fragmentStoresAndAtomics;
	features.shaderTessellationAndGeometryPointSize = enabledFeatures.shaderTessellationAndGeometryPointSize;
	features.shaderImageGatherExtended = enabledFeatures.shaderImageGatherExtended;
	features.shaderStorageImageExtendedFormats = enabledFeatures.shaderStorageImageExtendedFormats;
	features.shaderStorageImageMultisample = enabledFeatures.shaderStorageImageMultisample;
	features.shaderStorageImageReadWithoutFormat = enabledFeatures.shaderStorageImageReadWithoutFormat;
	features.shaderStorageImageWriteWithoutFormat = enabledFeatures.shaderStorageImageWriteWithoutFormat;
	features.shaderUniformBufferArrayDynamicIndexing = enabledFeatures.shaderUniformBufferArrayDynamicIndexing;
	features.shaderSampledImageArrayDynamicIndexing = enabledFeatures.shaderSampledImageArrayDynamicIndexing;
	features.shaderStorageBufferArrayDynamicIndexing = enabledFeatures.shaderStorageBufferArrayDynamicIndexing;
	features.shaderStorageImageArrayDynamicIndexing = enabledFeatures.shaderStorageImageArrayDynamicIndexing;
	features.shaderClipDistance = enabledFeatures.shaderClipDistance;
	features.shaderCullDistance = enabledFeatures.shaderCullDistance;
	features.shaderFloat64 = enabledFeatures.shaderFloat64;
	features.shaderInt64 = enabledFeatures.shaderInt64;
	features.shaderInt16 = enabledFeatures.shaderInt16;
	features.shaderResourceResidency = enabledFeatures.shaderResourceResidency;
	features.shaderResourceMinLod = enabledFeatures.shaderResourceMinLod;
	features.sparseBinding = enabledFeatures.sparseBinding;
	features.sparseResidencyBuffer = enabledFeatures.sparseResidencyBuffer;
	features.sparseResidencyImage2D = enabledFeatures.sparseResidencyImage2D;
	features.sparseResidencyImage3D = enabledFeatures.sparseResidencyImage3D;
	features.sparseResidency2Samples = enabledFeatures.sparseResidency2Samples;
	features.sparseResidency4Samples = enabledFeatures.sparseResidency4Samples;
	features.sparseResidency8Samples = enabledFeatures.sparseResidency8Samples;
	features.sparseResidency16Samples = enabledFeatures.sparseResidency16Samples;
	features.sparseResidencyAliased = enabledFeatures.sparseResidencyAliased;
	features.variableMultisampleRate = enabledFeatures.variableMultisampleRate;
	features.inheritedQueries = enabledFeatures.inheritedQueries;

	VkDeviceCreateInfo createInfo = {};
	createInfo.sType = VK_STRUCTURE_TYPE_DEVICE_CREATE_INFO;
	createInfo.pQueueCreateInfos = queueCreateInfos.data();
	createInfo.queueCreateInfoCount = static_cast<uint32_t>(queueCreateInfos.size());
	createInfo.pEnabledFeatures = &features;
    
	createInfo.enabledExtensionCount = static_cast<uint32_t>(_extensions.size());
    std::vector<const char *> ext;
	if (createInfo.enabledExtensionCount > 0) {
        for (auto & e : _extensions) {
            ext.push_back(e.c_str());
        }
		createInfo.ppEnabledExtensionNames = ext.data();
	}
	createInfo.enabledLayerCount = static_cast<uint32_t>(_layers.size());
    std::vector<const char *> layers;
	if (createInfo.enabledLayerCount > 0) {
        for (auto & l : _layers) {
            layers.push_back(l.c_str());
        }
		createInfo.ppEnabledLayerNames = layers.data();
	}
	
	VkDevice device;
	if (vkCreateDevice(bg::native_cast<VkPhysicalDevice>(physicalDev->vkDevice()), &createInfo, nullptr, &device) != VK_SUCCESS) {
		throw bg::base::VulkanEngineException("Error creating logical device.");
	}
	_vk_device = device;
}

Queue * Device::getDeviceQueue(uint32_t family) {
	Queue * q = new Queue(this, family);
	_queues.push_back(q);
	return q;
}

void Device::waitIdle() {
	vkDeviceWaitIdle(bg::native_cast<VkDevice>(_vk_device));
}

void Device::waitForFences(const std::vector<Fence *> & fences, bool waitAll, uint64_t timeout) {
	VkDevice vkDev = bg::native_cast<VkDevice>(_vk_device);
	std::vector<VkFence> vkFences;
	for (auto f : fences) {
		vkFences.push_back(bg::native_cast<VkFence>(f->vkFence()));
	}
	vkWaitForFences(vkDev, static_cast<uint32_t>(vkFences.size()), vkFences.data(), static_cast<VkBool32>(waitAll), timeout);
}

void Device::resetFences(const std::vector<Fence*> & fences) {
	VkDevice vkDev = bg::native_cast<VkDevice>(_vk_device);
	std::vector<VkFence> vkFences;
	for (auto f : fences) {
		vkFences.push_back(bg::native_cast<VkFence>(f->vkFence()));
	}
	vkResetFences(vkDev, static_cast<uint32_t>(vkFences.size()), vkFences.data());
}
/* End device */

/* Queue */
Queue::Queue(Device * dev, uint32_t familyIndex) :_device(dev) {
	VkQueue queue;
	vkGetDeviceQueue(bg::native_cast<VkDevice>(dev->vkDevice()), familyIndex, 0, &queue);
	_vk_queue = queue;
}

Queue::~Queue() {

}

void Queue::submit(const std::map<PipelineStageFlags, Semaphore*> & waitSem, const std::vector<CommandBuffer*> & cmdBuff, const std::vector<Semaphore*> & signalSem, Fence * fence) {
	VkSubmitInfo submitInfo = {};
	submitInfo.sType = VK_STRUCTURE_TYPE_SUBMIT_INFO;

	std::vector<VkSemaphore> waitSemaphores;
	std::vector<VkPipelineStageFlags> waitStages;
	std::vector<VkCommandBuffer> commandBuffers;
	std::vector<VkSemaphore> signalSemaphores;

	for (auto & ws : waitSem) {
		waitSemaphores.push_back(bg::native_cast<VkSemaphore>(ws.second->vkSemaphore()));
		waitStages.push_back(static_cast<VkPipelineStageFlags>(ws.first));
	}
	for (auto & b : cmdBuff) {
		commandBuffers.push_back(bg::native_cast<VkCommandBuffer>(b->vkCommandBuffer()));
	}
	for (auto & s : signalSem) {
		signalSemaphores.push_back(bg::native_cast<VkSemaphore>(s->vkSemaphore()));
	}

	submitInfo.waitSemaphoreCount = static_cast<uint32_t>(waitSemaphores.size());
	submitInfo.pWaitSemaphores = waitSemaphores.data();
	submitInfo.pWaitDstStageMask = waitStages.data();
	submitInfo.commandBufferCount = static_cast<uint32_t>(cmdBuff.size());
	submitInfo.pCommandBuffers = commandBuffers.data();
	submitInfo.signalSemaphoreCount = static_cast<uint32_t>(signalSemaphores.size());
	submitInfo.pSignalSemaphores = signalSemaphores.data();

	VkFence vkFence = fence ? bg::native_cast<VkFence>(fence->vkFence()) : VK_NULL_HANDLE;
	if (vkQueueSubmit(bg::native_cast<VkQueue>(_vk_queue), 1, &submitInfo, vkFence) != VK_SUCCESS) {
		throw bg::base::VulkanEngineException("Failed to submit command buffer.");
	}
}

void Queue::submitWaitIdle(const std::vector<CommandBuffer*> & cmdBuffer) {
    VkSubmitInfo submitInfo = {};
    submitInfo.sType = VK_STRUCTURE_TYPE_SUBMIT_INFO;
    
    std::vector<VkCommandBuffer> commandBuffers;
    for (auto c : cmdBuffer) {
        commandBuffers.push_back(bg::native_cast<VkCommandBuffer>(c->vkCommandBuffer()));
    }
    submitInfo.commandBufferCount = static_cast<uint32_t>(commandBuffers.size());
    submitInfo.pCommandBuffers = commandBuffers.data();
    
    vkQueueSubmit(bg::native_cast<VkQueue>(_vk_queue), 1, &submitInfo, VK_NULL_HANDLE);
    vkQueueWaitIdle(bg::native_cast<VkQueue>(_vk_queue));
}

void Queue::present(const std::vector<Semaphore*> & waitSem, const std::vector<SwapchainKHR*> & swapchains, const std::vector<uint32_t> & imgIndices) {
	VkPresentInfoKHR presentInfo = {};
	presentInfo.sType = VK_STRUCTURE_TYPE_PRESENT_INFO_KHR;
	std::vector<VkSemaphore> waitSemaphores;
	std::vector<VkSwapchainKHR> vkSwapchains;
	for (auto s : waitSem) {
		waitSemaphores.push_back(bg::native_cast<VkSemaphore>(s->vkSemaphore()));
	}
	for (auto s : swapchains) {
		vkSwapchains.push_back(bg::native_cast<VkSwapchainKHR>(s->vkSwapchain()));
	}
	presentInfo.waitSemaphoreCount = static_cast<uint32_t>(waitSemaphores.size());
	presentInfo.pWaitSemaphores = waitSemaphores.data();
	presentInfo.swapchainCount = static_cast<uint32_t>(swapchains.size());
	presentInfo.pSwapchains = vkSwapchains.data();
	presentInfo.pImageIndices = imgIndices.data();
	vkQueuePresentKHR(bg::native_cast<VkQueue>(_vk_queue), &presentInfo);
}

void Queue::waitIdle() {
	vkQueueWaitIdle(bg::native_cast<VkQueue>(_vk_queue));
}
/* End Queue */


/* SwapchainKHR */
SwapchainKHR::~SwapchainKHR() {
    if (_vk_swapchain) {
        VkSwapchainKHR sh = bg::native_cast<VkSwapchainKHR>(_vk_swapchain);
        VkDevice dev = bg::native_cast<VkDevice>(_vk_device);
        vkDestroySwapchainKHR(dev, sh, nullptr);
        _vk_swapchain = nullptr;
        _vk_device = nullptr;
    }
}

void SwapchainKHR::create(
    Device * dev,
    SurfaceKHR * surface,
    uint32_t minImageCount,
    Format imageFormat,
    ColorSpaceKHR colorSpace,
    Extent2D ext,
    uint32_t arrayLayers,
    ImageUsageFlags usageFlags,
    SharingMode sharingMode,
    std::vector<uint32_t> & queueFamilies,
    SurfaceTransformFlagBitsKHR preTransform,
    CompositeAlphaFlagBitsKHR compositeAlpha,
    PresentModeKHR presentMode,
    SwapchainKHR * oldSwapChain)
{
    VkDevice vkDev = bg::native_cast<VkDevice>(dev->vkDevice());
    VkSwapchainKHR swapchain = VK_NULL_HANDLE;
    
    VkSwapchainCreateInfoKHR createInfo = {};
    createInfo.sType = VK_STRUCTURE_TYPE_SWAPCHAIN_CREATE_INFO_KHR;
    createInfo.surface = bg::native_cast<VkSurfaceKHR>(surface->vkSurface());
    createInfo.minImageCount = minImageCount;
    createInfo.imageFormat = static_cast<VkFormat>(imageFormat);
    createInfo.imageColorSpace = static_cast<VkColorSpaceKHR>(colorSpace);
    createInfo.imageExtent.width = ext.width;
    createInfo.imageExtent.height = ext.height;
    createInfo.imageArrayLayers = arrayLayers;
    createInfo.imageUsage = static_cast<VkImageUsageFlags>(usageFlags);
    createInfo.imageSharingMode = static_cast<VkSharingMode>(sharingMode);
    if (queueFamilies.size()==0) {
        createInfo.queueFamilyIndexCount = 0;
        createInfo.pQueueFamilyIndices = nullptr;
    }
    else {
        createInfo.pQueueFamilyIndices = queueFamilies.data();
        createInfo.queueFamilyIndexCount = static_cast<uint32_t>(queueFamilies.size());
    }
    createInfo.preTransform = static_cast<VkSurfaceTransformFlagBitsKHR>(preTransform);
    createInfo.compositeAlpha = static_cast<VkCompositeAlphaFlagBitsKHR>(compositeAlpha);
    createInfo.presentMode = static_cast<VkPresentModeKHR>(presentMode);
    createInfo.clipped = VK_TRUE;
    createInfo.oldSwapchain = oldSwapChain ? bg::native_cast<VkSwapchainKHR>(oldSwapChain->vkSwapchain()) : nullptr;
	if (vkCreateSwapchainKHR(vkDev, &createInfo, nullptr, &swapchain) != VK_SUCCESS) {
		throw bg::base::VulkanEngineException("Error creating Vulkan swap chain.");
	}
    _vk_swapchain = swapchain;
    _vk_device = vkDev;
    _format = imageFormat;
    _extent = ext;
}

void SwapchainKHR::acquireNextImage(uint64_t timeout, Semaphore * sem, Fence * fence, uint32_t & imageIndex) {
	VkSemaphore vkSem = sem ? bg::native_cast<VkSemaphore>(sem->vkSemaphore()) : VK_NULL_HANDLE;
	VkFence vkFence = fence ? bg::native_cast<VkFence>(fence->vkFence()) : VK_NULL_HANDLE;
	vkAcquireNextImageKHR(bg::native_cast<VkDevice>(_vk_device), bg::native_cast<VkSwapchainKHR>(_vk_swapchain), timeout, vkSem, vkFence, &imageIndex);
}
/* End SwapchainKHR*/

/* Sampler */

const uint32_t FILTER_NEAREST = VK_FILTER_NEAREST;
const uint32_t FILTER_LINEAR = VK_FILTER_LINEAR;
const uint32_t FILTER_CUBIC_IMG = VK_FILTER_CUBIC_IMG;
const uint32_t FILTER_BEGIN_RANGE = VK_FILTER_BEGIN_RANGE;
const uint32_t FILTER_END_RANGE = VK_FILTER_END_RANGE;
const uint32_t FILTER_RANGE_SIZE = VK_FILTER_RANGE_SIZE;
const uint32_t FILTER_MAX_ENUM = VK_FILTER_MAX_ENUM;

const uint32_t SAMPLER_MIPMAP_MODE_NEAREST = VK_SAMPLER_MIPMAP_MODE_NEAREST;
const uint32_t SAMPLER_MIPMAP_MODE_LINEAR = VK_SAMPLER_MIPMAP_MODE_LINEAR;
const uint32_t SAMPLER_MIPMAP_MODE_BEGIN_RANGE = VK_SAMPLER_MIPMAP_MODE_BEGIN_RANGE;
const uint32_t SAMPLER_MIPMAP_MODE_END_RANGE = VK_SAMPLER_MIPMAP_MODE_END_RANGE;
const uint32_t SAMPLER_MIPMAP_MODE_RANGE_SIZE = VK_SAMPLER_MIPMAP_MODE_RANGE_SIZE;
const uint32_t SAMPLER_MIPMAP_MODE_MAX_ENUM = VK_SAMPLER_MIPMAP_MODE_MAX_ENUM;

const uint32_t SAMPLER_ADDRESS_MODE_REPEAT = VK_SAMPLER_ADDRESS_MODE_REPEAT;
const uint32_t SAMPLER_ADDRESS_MODE_MIRRORED_REPEAT = VK_SAMPLER_ADDRESS_MODE_MIRRORED_REPEAT;
const uint32_t SAMPLER_ADDRESS_MODE_CLAMP_TO_EDGE = VK_SAMPLER_ADDRESS_MODE_CLAMP_TO_EDGE;
const uint32_t SAMPLER_ADDRESS_MODE_CLAMP_TO_BORDER = VK_SAMPLER_ADDRESS_MODE_CLAMP_TO_BORDER;
const uint32_t SAMPLER_ADDRESS_MODE_MIRROR_CLAMP_TO_EDGE = VK_SAMPLER_ADDRESS_MODE_MIRROR_CLAMP_TO_EDGE;
const uint32_t SAMPLER_ADDRESS_MODE_BEGIN_RANGE = VK_SAMPLER_ADDRESS_MODE_BEGIN_RANGE;
const uint32_t SAMPLER_ADDRESS_MODE_END_RANGE = VK_SAMPLER_ADDRESS_MODE_END_RANGE;
const uint32_t SAMPLER_ADDRESS_MODE_RANGE_SIZE = VK_SAMPLER_ADDRESS_MODE_RANGE_SIZE;
const uint32_t SAMPLER_ADDRESS_MODE_MAX_ENUM = VK_SAMPLER_ADDRESS_MODE_MAX_ENUM;

const uint32_t BORDER_COLOR_FLOAT_TRANSPARENT_BLACK = VK_BORDER_COLOR_FLOAT_TRANSPARENT_BLACK;
const uint32_t BORDER_COLOR_INT_TRANSPARENT_BLACK = VK_BORDER_COLOR_FLOAT_TRANSPARENT_BLACK;
const uint32_t BORDER_COLOR_FLOAT_OPAQUE_BLACK = VK_BORDER_COLOR_FLOAT_OPAQUE_BLACK;
const uint32_t BORDER_COLOR_INT_OPAQUE_BLACK = VK_BORDER_COLOR_INT_OPAQUE_BLACK;
const uint32_t BORDER_COLOR_FLOAT_OPAQUE_WHITE = VK_BORDER_COLOR_FLOAT_OPAQUE_WHITE;
const uint32_t BORDER_COLOR_INT_OPAQUE_WHITE = VK_BORDER_COLOR_INT_OPAQUE_WHITE;
const uint32_t BORDER_COLOR_BEGIN_RANGE = VK_BORDER_COLOR_BEGIN_RANGE;
const uint32_t BORDER_COLOR_END_RANGE = VK_BORDER_COLOR_END_RANGE;
const uint32_t BORDER_COLOR_RANGE_SIZE = VK_BORDER_COLOR_RANGE_SIZE;
const uint32_t BORDER_COLOR_MAX_ENUM = VK_BORDER_COLOR_MAX_ENUM;

Sampler::~Sampler() {
	if (_vk_sampler) {
		VkDevice dev = bg::native_cast<VkDevice>(_vk_device);
		VkSampler sampler = bg::native_cast<VkSampler>(_vk_sampler);
		vkDestroySampler(dev, sampler, nullptr);
		_vk_sampler = nullptr;
		_vk_device = nullptr;
	}
}

void Sampler::create(Device * dev) {
	VkDevice vkDev = bg::native_cast<VkDevice>(dev->vkDevice());
	_vk_device = vkDev;
	VkSamplerCreateInfo info = {};
	info.sType = VK_STRUCTURE_TYPE_SAMPLER_CREATE_INFO;
	info.magFilter = static_cast<VkFilter>(createInfo.magFilter);
	info.minFilter = static_cast<VkFilter>(createInfo.minFilter);
	info.mipmapMode = static_cast<VkSamplerMipmapMode>(createInfo.mipmapMode);
	info.addressModeU = static_cast<VkSamplerAddressMode>(createInfo.addressModeU);
	info.addressModeV = static_cast<VkSamplerAddressMode>(createInfo.addressModeV);
	info.addressModeW = static_cast<VkSamplerAddressMode>(createInfo.addressModeW);
	info.mipLodBias = createInfo.mipLodBias;
	info.anisotropyEnable = createInfo.anisotropyEnable;
	info.maxAnisotropy = createInfo.maxAnisotropy;
	info.compareEnable = createInfo.compareEnable;
	info.compareOp = static_cast<VkCompareOp>(createInfo.compareOp);
	info.minLod = createInfo.minLod;
	info.maxLod = createInfo.maxLod;
	info.borderColor = static_cast<VkBorderColor>(createInfo.borderColor);
	info.unnormalizedCoordinates = createInfo.unnormalizedCoordinates;
	VkSampler sampler;
	if (vkCreateSampler(vkDev, &info, nullptr, &sampler) != VK_SUCCESS) {
		throw bg::base::VulkanEngineException("Could not create sampler.");
	}
	_vk_sampler = sampler;
}
/* End Sampler */

/* Image */
const uint32_t IMAGE_CREATE_SPARSE_BINDING_BIT = VK_IMAGE_CREATE_SPARSE_BINDING_BIT;
const uint32_t IMAGE_CREATE_SPARSE_RESIDENCY_BIT = VK_IMAGE_CREATE_SPARSE_RESIDENCY_BIT;
const uint32_t IMAGE_CREATE_SPARSE_ALIASED_BIT = VK_IMAGE_CREATE_SPARSE_ALIASED_BIT;
const uint32_t IMAGE_CREATE_MUTABLE_FORMAT_BIT = VK_IMAGE_CREATE_MUTABLE_FORMAT_BIT;
const uint32_t IMAGE_CREATE_CUBE_COMPATIBLE_BIT = VK_IMAGE_CREATE_CUBE_COMPATIBLE_BIT;
const uint32_t IMAGE_CREATE_ALIAS_BIT = VK_IMAGE_CREATE_ALIAS_BIT;
const uint32_t IMAGE_CREATE_SPLIT_INSTANCE_BIND_REGIONS_BIT = VK_IMAGE_CREATE_SPLIT_INSTANCE_BIND_REGIONS_BIT;
const uint32_t IMAGE_CREATE_2D_ARRAY_COMPATIBLE_BIT = VK_IMAGE_CREATE_2D_ARRAY_COMPATIBLE_BIT;
const uint32_t IMAGE_CREATE_BLOCK_TEXEL_VIEW_COMPATIBLE_BIT = VK_IMAGE_CREATE_BLOCK_TEXEL_VIEW_COMPATIBLE_BIT;
const uint32_t IMAGE_CREATE_EXTENDED_USAGE_BIT = VK_IMAGE_CREATE_EXTENDED_USAGE_BIT;
const uint32_t IMAGE_CREATE_PROTECTED_BIT = VK_IMAGE_CREATE_PROTECTED_BIT;
const uint32_t IMAGE_CREATE_DISJOINT_BIT = VK_IMAGE_CREATE_DISJOINT_BIT;
const uint32_t IMAGE_CREATE_SAMPLE_LOCATIONS_COMPATIBLE_DEPTH_BIT_EXT = VK_IMAGE_CREATE_SAMPLE_LOCATIONS_COMPATIBLE_DEPTH_BIT_EXT;
const uint32_t IMAGE_CREATE_SPLIT_INSTANCE_BIND_REGIONS_BIT_KHR = VK_IMAGE_CREATE_SPLIT_INSTANCE_BIND_REGIONS_BIT_KHR;
const uint32_t IMAGE_CREATE_2D_ARRAY_COMPATIBLE_BIT_KHR = VK_IMAGE_CREATE_2D_ARRAY_COMPATIBLE_BIT_KHR;
const uint32_t IMAGE_CREATE_BLOCK_TEXEL_VIEW_COMPATIBLE_BIT_KHR = VK_IMAGE_CREATE_BLOCK_TEXEL_VIEW_COMPATIBLE_BIT_KHR;
const uint32_t IMAGE_CREATE_EXTENDED_USAGE_BIT_KHR = VK_IMAGE_CREATE_EXTENDED_USAGE_BIT_KHR;
const uint32_t IMAGE_CREATE_DISJOINT_BIT_KHR = VK_IMAGE_CREATE_DISJOINT_BIT_KHR;
const uint32_t IMAGE_CREATE_ALIAS_BIT_KHR = VK_IMAGE_CREATE_ALIAS_BIT_KHR;
const uint32_t IMAGE_CREATE_FLAG_BITS_MAX_ENUM = VK_IMAGE_CREATE_FLAG_BITS_MAX_ENUM;

const uint32_t IMAGE_TYPE_1D = VK_IMAGE_TYPE_1D;
const uint32_t IMAGE_TYPE_2D = VK_IMAGE_TYPE_2D;
const uint32_t IMAGE_TYPE_3D = VK_IMAGE_TYPE_3D;
const uint32_t IMAGE_TYPE_BEGIN_RANGE = VK_IMAGE_TYPE_BEGIN_RANGE;
const uint32_t IMAGE_TYPE_END_RANGE = VK_IMAGE_TYPE_END_RANGE;
const uint32_t IMAGE_TYPE_RANGE_SIZE = VK_IMAGE_TYPE_RANGE_SIZE;
const uint32_t IMAGE_TYPE_MAX_ENUM = VK_IMAGE_TYPE_MAX_ENUM;

const uint32_t IMAGE_TILING_OPTIMAL = VK_IMAGE_TILING_OPTIMAL;
const uint32_t IMAGE_TILING_LINEAR = VK_IMAGE_TILING_LINEAR;
const uint32_t IMAGE_TILING_BEGIN_RANGE = VK_IMAGE_TILING_BEGIN_RANGE;
const uint32_t IMAGE_TILING_END_RANGE = VK_IMAGE_TILING_END_RANGE;
const uint32_t IMAGE_TILING_RANGE_SIZE = VK_IMAGE_TILING_RANGE_SIZE;
const uint32_t IMAGE_TILING_MAX_ENUM = VK_IMAGE_TILING_MAX_ENUM;

const uint32_t SAMPLE_COUNT_1_BIT = VK_SAMPLE_COUNT_1_BIT;
const uint32_t SAMPLE_COUNT_2_BIT = VK_SAMPLE_COUNT_2_BIT;
const uint32_t SAMPLE_COUNT_4_BIT = VK_SAMPLE_COUNT_4_BIT;
const uint32_t SAMPLE_COUNT_8_BIT = VK_SAMPLE_COUNT_8_BIT;
const uint32_t SAMPLE_COUNT_16_BIT = VK_SAMPLE_COUNT_16_BIT;
const uint32_t SAMPLE_COUNT_32_BIT = VK_SAMPLE_COUNT_32_BIT;
const uint32_t SAMPLE_COUNT_64_BIT = VK_SAMPLE_COUNT_64_BIT;
const uint32_t SAMPLE_COUNT_FLAG_BITS_MAX_ENUM = VK_SAMPLE_COUNT_FLAG_BITS_MAX_ENUM;


Image::Image() {

}

Image::Image(bg::plain_ptr vkImage)
    :_vk_image(vkImage)
{
}

Image::~Image() {
    // Only destroy the image if _vk_device is not null
    if (_vk_image && _vk_device) {
        VkDevice dev = bg::native_cast<VkDevice>(_vk_device);
        VkImage img = bg::native_cast<VkImage>(_vk_image);
        vkDestroyImage(dev, img, nullptr);
    }
    _vk_image = nullptr;
    _vk_device = nullptr;
}

void Image::create(Device * dev) {
    VkDevice vkDev = bg::native_cast<VkDevice>(dev->vkDevice());
    _vk_device = vkDev;
    
    VkImageCreateInfo info = {};
    info.sType = VK_STRUCTURE_TYPE_IMAGE_CREATE_INFO;
    info.flags = static_cast<VkImageCreateFlags>(createInfo.flags);
    info.imageType = static_cast<VkImageType>(createInfo.imageType);
    info.format = static_cast<VkFormat>(createInfo.format);
    info.extent.width = createInfo.extent.width;
    info.extent.height = createInfo.extent.height;
    info.extent.depth = createInfo.extent.depth;
    info.mipLevels = createInfo.mipLevels;
    info.arrayLayers = createInfo.arrayLayers;
    info.samples = static_cast<VkSampleCountFlagBits>(createInfo.samples);
    info.tiling = static_cast<VkImageTiling>(createInfo.tiling);
    info.sharingMode = static_cast<VkSharingMode>(createInfo.sharingMode);
    info.queueFamilyIndexCount = static_cast<uint32_t>(createInfo.queueFamilyIndices.size());
    info.pQueueFamilyIndices = createInfo.queueFamilyIndices.data();
    info.initialLayout = static_cast<VkImageLayout>(createInfo.initialLayout);
	info.usage = createInfo.usage;
    
    VkImage image;
    if (vkCreateImage(vkDev, &info, nullptr, &image)!=VK_SUCCESS) {
        throw bg::base::VulkanEngineException("Error creating Vulkan image.");
    }
    
    _vk_image = image;
}

void Image::geImageMemoryRequirements(MemoryRequirements & req) {
    VkMemoryRequirements memRequirements;
    vkGetImageMemoryRequirements(bg::native_cast<VkDevice>(_vk_device), bg::native_cast<VkImage>(_vk_image), &memRequirements);
    
    req.alignment = memRequirements.alignment;
    req.memoryTypeBits = memRequirements.memoryTypeBits;
    req.size = memRequirements.size;
}
/* End Image */


/* ImageView */
ImageView::~ImageView() {
    if (_vk_imageView) {
        VkImageView imgView = bg::native_cast<VkImageView>(_vk_imageView);
        VkDevice dev = bg::native_cast<VkDevice>(_vk_device);
        vkDestroyImageView(dev, imgView, nullptr);
        _vk_device = nullptr;
        _vk_imageView = nullptr;
    }
}

void ImageView::create(Device * dev, Image * img, ImageViewType type, Format format, const ComponentMapping & mapping, const ImageSubresourceRange & subresourceRange) {
    VkDevice vkDev = bg::native_cast<VkDevice>(dev->vkDevice());
    
    VkImageViewCreateInfo createInfo = {};
    createInfo.sType = VK_STRUCTURE_TYPE_IMAGE_VIEW_CREATE_INFO;
	createInfo.flags = 0;
    createInfo.image = bg::native_cast<VkImage>(img->vkImage());
    createInfo.viewType = static_cast<VkImageViewType>(type);
    createInfo.format = static_cast<VkFormat>(format);
    createInfo.components.r = static_cast<VkComponentSwizzle>(mapping.r);
    createInfo.components.g = static_cast<VkComponentSwizzle>(mapping.g);
    createInfo.components.b = static_cast<VkComponentSwizzle>(mapping.b);
    createInfo.components.a = static_cast<VkComponentSwizzle>(mapping.a);
    createInfo.subresourceRange.aspectMask = static_cast<VkImageAspectFlags>(subresourceRange.aspectMask);
    createInfo.subresourceRange.baseArrayLayer = subresourceRange.baseArrayLayer;
    createInfo.subresourceRange.baseMipLevel = subresourceRange.baseMipLevel;
    createInfo.subresourceRange.layerCount = subresourceRange.layerCount;
    createInfo.subresourceRange.levelCount = subresourceRange.levelCount;
    
    VkImageView imageView;
	if (vkCreateImageView(vkDev, &createInfo, nullptr, &imageView) != VK_SUCCESS) {
		throw bg::base::VulkanEngineException("Could not create Vulkan ImageView.");
	}
    _vk_imageView = imageView;
    _vk_device = vkDev;
}

void ImageView::create(Device * dev) {
	create(dev, createInfo.image, createInfo.viewType, createInfo.format, createInfo.components, createInfo.subresourceRange);
}
/* End ImageView */

const uint32_t SHADER_STAGE_VERTEX_BIT = VK_SHADER_STAGE_VERTEX_BIT;
const uint32_t SHADER_STAGE_TESSELLATION_CONTROL_BIT = VK_SHADER_STAGE_TESSELLATION_CONTROL_BIT;
const uint32_t SHADER_STAGE_TESSELLATION_EVALUATION_BIT = VK_SHADER_STAGE_TESSELLATION_EVALUATION_BIT;
const uint32_t SHADER_STAGE_GEOMETRY_BIT = VK_SHADER_STAGE_GEOMETRY_BIT;
const uint32_t SHADER_STAGE_FRAGMENT_BIT = VK_SHADER_STAGE_FRAGMENT_BIT;
const uint32_t SHADER_STAGE_COMPUTE_BIT = VK_SHADER_STAGE_COMPUTE_BIT;
const uint32_t SHADER_STAGE_ALL_GRAPHICS = VK_SHADER_STAGE_ALL_GRAPHICS;
const uint32_t SHADER_STAGE_ALL = VK_SHADER_STAGE_ALL;
const uint32_t SHADER_STAGE_FLAG_BITS_MAX_ENUM = VK_SHADER_STAGE_FLAG_BITS_MAX_ENUM;

const uint32_t VERTEX_INPUT_RATE_VERTEX = VK_VERTEX_INPUT_RATE_VERTEX;
const uint32_t VERTEX_INPUT_RATE_INSTANCE = VK_VERTEX_INPUT_RATE_INSTANCE;
const uint32_t VERTEX_INPUT_RATE_BEGIN_RANGE = VK_VERTEX_INPUT_RATE_BEGIN_RANGE;
const uint32_t VERTEX_INPUT_RATE_END_RANGE = VK_VERTEX_INPUT_RATE_END_RANGE;
const uint32_t VERTEX_INPUT_RATE_RANGE_SIZE = VK_VERTEX_INPUT_RATE_RANGE_SIZE;
const uint32_t VERTEX_INPUT_RATE_MAX_ENUM = VK_VERTEX_INPUT_RATE_MAX_ENUM;

const uint32_t PRIMITIVE_TOPOLOGY_POINT_LIST = VK_PRIMITIVE_TOPOLOGY_POINT_LIST;
const uint32_t PRIMITIVE_TOPOLOGY_LINE_LIST = VK_PRIMITIVE_TOPOLOGY_LINE_LIST;
const uint32_t PRIMITIVE_TOPOLOGY_LINE_STRIP = VK_PRIMITIVE_TOPOLOGY_LINE_STRIP;
const uint32_t PRIMITIVE_TOPOLOGY_TRIANGLE_LIST = VK_PRIMITIVE_TOPOLOGY_TRIANGLE_LIST;
const uint32_t PRIMITIVE_TOPOLOGY_TRIANGLE_STRIP = VK_PRIMITIVE_TOPOLOGY_TRIANGLE_STRIP;
const uint32_t PRIMITIVE_TOPOLOGY_TRIANGLE_FAN = VK_PRIMITIVE_TOPOLOGY_TRIANGLE_FAN;
const uint32_t PRIMITIVE_TOPOLOGY_LINE_LIST_WITH_ADJACENCY = VK_PRIMITIVE_TOPOLOGY_LINE_LIST_WITH_ADJACENCY;
const uint32_t PRIMITIVE_TOPOLOGY_LINE_STRIP_WITH_ADJACENCY = VK_PRIMITIVE_TOPOLOGY_LINE_STRIP_WITH_ADJACENCY;
const uint32_t PRIMITIVE_TOPOLOGY_TRIANGLE_LIST_WITH_ADJACENCY = VK_PRIMITIVE_TOPOLOGY_TRIANGLE_LIST_WITH_ADJACENCY;
const uint32_t PRIMITIVE_TOPOLOGY_TRIANGLE_STRIP_WITH_ADJACENCY = VK_PRIMITIVE_TOPOLOGY_TRIANGLE_STRIP_WITH_ADJACENCY;
const uint32_t PRIMITIVE_TOPOLOGY_PATCH_LIST = VK_PRIMITIVE_TOPOLOGY_PATCH_LIST;
const uint32_t PRIMITIVE_TOPOLOGY_BEGIN_RANGE = VK_PRIMITIVE_TOPOLOGY_BEGIN_RANGE;
const uint32_t PRIMITIVE_TOPOLOGY_END_RANGE = VK_PRIMITIVE_TOPOLOGY_END_RANGE;
const uint32_t PRIMITIVE_TOPOLOGY_RANGE_SIZE = VK_PRIMITIVE_TOPOLOGY_RANGE_SIZE;
const uint32_t PRIMITIVE_TOPOLOGY_MAX_ENUM = VK_PRIMITIVE_TOPOLOGY_MAX_ENUM;

const uint32_t POLYGON_MODE_FILL = VK_POLYGON_MODE_FILL;
const uint32_t POLYGON_MODE_LINE = VK_POLYGON_MODE_LINE;
const uint32_t POLYGON_MODE_POINT = VK_POLYGON_MODE_POINT;
const uint32_t POLYGON_MODE_FILL_RECTANGLE_NV = VK_POLYGON_MODE_FILL_RECTANGLE_NV;
const uint32_t POLYGON_MODE_BEGIN_RANGE = VK_POLYGON_MODE_BEGIN_RANGE;
const uint32_t POLYGON_MODE_END_RANGE = VK_POLYGON_MODE_END_RANGE;
const uint32_t POLYGON_MODE_RANGE_SIZE = VK_POLYGON_MODE_RANGE_SIZE;
const uint32_t POLYGON_MODE_MAX_ENUM = VK_POLYGON_MODE_MAX_ENUM;

const uint32_t FRONT_FACE_COUNTER_CLOCKWISE = VK_FRONT_FACE_COUNTER_CLOCKWISE;
const uint32_t FRONT_FACE_CLOCKWISE = VK_FRONT_FACE_CLOCKWISE;
const uint32_t FRONT_FACE_BEGIN_RANGE = VK_FRONT_FACE_BEGIN_RANGE;
const uint32_t FRONT_FACE_END_RANGE = VK_FRONT_FACE_END_RANGE;
const uint32_t FRONT_FACE_RANGE_SIZE = VK_FRONT_FACE_RANGE_SIZE;
const uint32_t FRONT_FACE_MAX_ENUM = VK_FRONT_FACE_MAX_ENUM;

const uint32_t COMPARE_OP_NEVER = VK_COMPARE_OP_NEVER;
const uint32_t COMPARE_OP_LESS = VK_COMPARE_OP_LESS;
const uint32_t COMPARE_OP_EQUAL = VK_COMPARE_OP_EQUAL;
const uint32_t COMPARE_OP_LESS_OR_EQUAL = VK_COMPARE_OP_LESS_OR_EQUAL;
const uint32_t COMPARE_OP_GREATER = VK_COMPARE_OP_GREATER;
const uint32_t COMPARE_OP_NOT_EQUAL = VK_COMPARE_OP_NOT_EQUAL;
const uint32_t COMPARE_OP_GREATER_OR_EQUAL = VK_COMPARE_OP_GREATER_OR_EQUAL;
const uint32_t COMPARE_OP_ALWAYS = VK_COMPARE_OP_ALWAYS;
const uint32_t COMPARE_OP_BEGIN_RANGE = VK_COMPARE_OP_BEGIN_RANGE;
const uint32_t COMPARE_OP_END_RANGE = VK_COMPARE_OP_END_RANGE;
const uint32_t COMPARE_OP_RANGE_SIZE = VK_COMPARE_OP_RANGE_SIZE;
const uint32_t COMPARE_OP_MAX_ENUM = VK_COMPARE_OP_MAX_ENUM;

const uint32_t STENCIL_OP_KEEP = VK_STENCIL_OP_KEEP;
const uint32_t STENCIL_OP_ZERO = VK_STENCIL_OP_ZERO;
const uint32_t STENCIL_OP_REPLACE = VK_STENCIL_OP_REPLACE;
const uint32_t STENCIL_OP_INCREMENT_AND_CLAMP = VK_STENCIL_OP_INCREMENT_AND_CLAMP;
const uint32_t STENCIL_OP_DECREMENT_AND_CLAMP = VK_STENCIL_OP_DECREMENT_AND_CLAMP;
const uint32_t STENCIL_OP_INVERT = VK_STENCIL_OP_INVERT;
const uint32_t STENCIL_OP_INCREMENT_AND_WRAP = VK_STENCIL_OP_INCREMENT_AND_WRAP;
const uint32_t STENCIL_OP_DECREMENT_AND_WRAP = VK_STENCIL_OP_DECREMENT_AND_WRAP;
const uint32_t STENCIL_OP_BEGIN_RANGE = VK_STENCIL_OP_BEGIN_RANGE;
const uint32_t STENCIL_OP_END_RANGE = VK_STENCIL_OP_END_RANGE;
const uint32_t STENCIL_OP_RANGE_SIZE = VK_STENCIL_OP_RANGE_SIZE;
const uint32_t STENCIL_OP_MAX_ENUM = VK_STENCIL_OP_MAX_ENUM;

const uint32_t LOGIC_OP_CLEAR = VK_LOGIC_OP_CLEAR;
const uint32_t LOGIC_OP_AND = VK_LOGIC_OP_AND;
const uint32_t LOGIC_OP_AND_REVERSE = VK_LOGIC_OP_AND_REVERSE;
const uint32_t LOGIC_OP_COPY = VK_LOGIC_OP_COPY;
const uint32_t LOGIC_OP_AND_INVERTED = VK_LOGIC_OP_AND_INVERTED;
const uint32_t LOGIC_OP_NO_OP = VK_LOGIC_OP_NO_OP;
const uint32_t LOGIC_OP_XOR = VK_LOGIC_OP_XOR;
const uint32_t LOGIC_OP_OR = VK_LOGIC_OP_OR;
const uint32_t LOGIC_OP_NOR = VK_LOGIC_OP_NOR;
const uint32_t LOGIC_OP_EQUIVALENT = VK_LOGIC_OP_EQUIVALENT;
const uint32_t LOGIC_OP_INVERT = VK_LOGIC_OP_INVERT;
const uint32_t LOGIC_OP_OR_REVERSE = VK_LOGIC_OP_OR_REVERSE;
const uint32_t LOGIC_OP_COPY_INVERTED = VK_LOGIC_OP_COPY_INVERTED;
const uint32_t LOGIC_OP_OR_INVERTED = VK_LOGIC_OP_OR_INVERTED;
const uint32_t LOGIC_OP_NAND = VK_LOGIC_OP_NAND;
const uint32_t LOGIC_OP_SET = VK_LOGIC_OP_SET;
const uint32_t LOGIC_OP_BEGIN_RANGE = VK_LOGIC_OP_BEGIN_RANGE;
const uint32_t LOGIC_OP_END_RANGE = VK_LOGIC_OP_END_RANGE;
const uint32_t LOGIC_OP_RANGE_SIZE = VK_LOGIC_OP_RANGE_SIZE;
const uint32_t LOGIC_OP_MAX_ENUM = VK_LOGIC_OP_MAX_ENUM;

const uint32_t BLEND_FACTOR_ZERO = VK_BLEND_FACTOR_ZERO;
const uint32_t BLEND_FACTOR_ONE = VK_BLEND_FACTOR_ONE;
const uint32_t BLEND_FACTOR_SRC_COLOR = VK_BLEND_FACTOR_SRC_COLOR;
const uint32_t BLEND_FACTOR_ONE_MINUS_SRC_COLOR = VK_BLEND_FACTOR_ONE_MINUS_SRC_COLOR;
const uint32_t BLEND_FACTOR_DST_COLOR = VK_BLEND_FACTOR_DST_COLOR;
const uint32_t BLEND_FACTOR_ONE_MINUS_DST_COLOR = VK_BLEND_FACTOR_ONE_MINUS_DST_COLOR;
const uint32_t BLEND_FACTOR_SRC_ALPHA = VK_BLEND_FACTOR_SRC_ALPHA;
const uint32_t BLEND_FACTOR_ONE_MINUS_SRC_ALPHA = VK_BLEND_FACTOR_ONE_MINUS_SRC_ALPHA;
const uint32_t BLEND_FACTOR_DST_ALPHA = VK_BLEND_FACTOR_DST_ALPHA;
const uint32_t BLEND_FACTOR_ONE_MINUS_DST_ALPHA = VK_BLEND_FACTOR_ONE_MINUS_DST_ALPHA;
const uint32_t BLEND_FACTOR_CONSTANT_COLOR = VK_BLEND_FACTOR_CONSTANT_COLOR;
const uint32_t BLEND_FACTOR_ONE_MINUS_CONSTANT_COLOR = VK_BLEND_FACTOR_ONE_MINUS_CONSTANT_COLOR;
const uint32_t BLEND_FACTOR_CONSTANT_ALPHA = VK_BLEND_FACTOR_CONSTANT_ALPHA;
const uint32_t BLEND_FACTOR_ONE_MINUS_CONSTANT_ALPHA = VK_BLEND_FACTOR_ONE_MINUS_CONSTANT_ALPHA;
const uint32_t BLEND_FACTOR_SRC_ALPHA_SATURATE = VK_BLEND_FACTOR_SRC_ALPHA_SATURATE;
const uint32_t BLEND_FACTOR_SRC1_COLOR = VK_BLEND_FACTOR_SRC1_COLOR;
const uint32_t BLEND_FACTOR_ONE_MINUS_SRC1_COLOR = VK_BLEND_FACTOR_ONE_MINUS_SRC1_COLOR;
const uint32_t BLEND_FACTOR_SRC1_ALPHA = VK_BLEND_FACTOR_SRC1_ALPHA;
const uint32_t BLEND_FACTOR_ONE_MINUS_SRC1_ALPHA = VK_BLEND_FACTOR_ONE_MINUS_SRC1_ALPHA;
const uint32_t BLEND_FACTOR_BEGIN_RANGE = VK_BLEND_FACTOR_BEGIN_RANGE;
const uint32_t BLEND_FACTOR_END_RANGE = VK_BLEND_FACTOR_END_RANGE;
const uint32_t BLEND_FACTOR_RANGE_SIZE = VK_BLEND_FACTOR_RANGE_SIZE;
const uint32_t BLEND_FACTOR_MAX_ENUM = VK_BLEND_FACTOR_MAX_ENUM;

const uint32_t BLEND_OP_ADD = VK_BLEND_OP_ADD;
const uint32_t BLEND_OP_SUBTRACT = VK_BLEND_OP_SUBTRACT;
const uint32_t BLEND_OP_REVERSE_SUBTRACT = VK_BLEND_OP_REVERSE_SUBTRACT;
const uint32_t BLEND_OP_MIN = VK_BLEND_OP_MIN;
const uint32_t BLEND_OP_MAX = VK_BLEND_OP_MAX;
const uint32_t BLEND_OP_ZERO_EXT = VK_BLEND_OP_ZERO_EXT;
const uint32_t BLEND_OP_SRC_EXT = VK_BLEND_OP_SRC_EXT;
const uint32_t BLEND_OP_DST_EXT = VK_BLEND_OP_DST_EXT;
const uint32_t BLEND_OP_SRC_OVER_EXT = VK_BLEND_OP_SRC_OVER_EXT;
const uint32_t BLEND_OP_DST_OVER_EXT = VK_BLEND_OP_DST_OVER_EXT;
const uint32_t BLEND_OP_SRC_IN_EXT = VK_BLEND_OP_SRC_IN_EXT;
const uint32_t BLEND_OP_DST_IN_EXT = VK_BLEND_OP_DST_IN_EXT;
const uint32_t BLEND_OP_SRC_OUT_EXT = VK_BLEND_OP_SRC_OUT_EXT;
const uint32_t BLEND_OP_DST_OUT_EXT = VK_BLEND_OP_DST_OUT_EXT;
const uint32_t BLEND_OP_SRC_ATOP_EXT = VK_BLEND_OP_SRC_ATOP_EXT;
const uint32_t BLEND_OP_DST_ATOP_EXT = VK_BLEND_OP_DST_ATOP_EXT;
const uint32_t BLEND_OP_XOR_EXT = VK_BLEND_OP_XOR_EXT;
const uint32_t BLEND_OP_MULTIPLY_EXT = VK_BLEND_OP_MULTIPLY_EXT;
const uint32_t BLEND_OP_SCREEN_EXT = VK_BLEND_OP_SCREEN_EXT;
const uint32_t BLEND_OP_OVERLAY_EXT = VK_BLEND_OP_OVERLAY_EXT;
const uint32_t BLEND_OP_DARKEN_EXT = VK_BLEND_OP_DARKEN_EXT;
const uint32_t BLEND_OP_LIGHTEN_EXT = VK_BLEND_OP_LIGHTEN_EXT;
const uint32_t BLEND_OP_COLORDODGE_EXT = VK_BLEND_OP_COLORDODGE_EXT;
const uint32_t BLEND_OP_COLORBURN_EXT = VK_BLEND_OP_COLORBURN_EXT;
const uint32_t BLEND_OP_HARDLIGHT_EXT = VK_BLEND_OP_HARDLIGHT_EXT;
const uint32_t BLEND_OP_SOFTLIGHT_EXT = VK_BLEND_OP_SOFTLIGHT_EXT;
const uint32_t BLEND_OP_DIFFERENCE_EXT = VK_BLEND_OP_DIFFERENCE_EXT;
const uint32_t BLEND_OP_EXCLUSION_EXT = VK_BLEND_OP_EXCLUSION_EXT;
const uint32_t BLEND_OP_INVERT_EXT = VK_BLEND_OP_INVERT_EXT;
const uint32_t BLEND_OP_INVERT_RGB_EXT = VK_BLEND_OP_INVERT_RGB_EXT;
const uint32_t BLEND_OP_LINEARDODGE_EXT = VK_BLEND_OP_LINEARDODGE_EXT;
const uint32_t BLEND_OP_LINEARBURN_EXT = VK_BLEND_OP_LINEARBURN_EXT;
const uint32_t BLEND_OP_VIVIDLIGHT_EXT = VK_BLEND_OP_VIVIDLIGHT_EXT;
const uint32_t BLEND_OP_LINEARLIGHT_EXT = VK_BLEND_OP_LINEARLIGHT_EXT;
const uint32_t BLEND_OP_PINLIGHT_EXT = VK_BLEND_OP_PINLIGHT_EXT;
const uint32_t BLEND_OP_HARDMIX_EXT = VK_BLEND_OP_HARDMIX_EXT;
const uint32_t BLEND_OP_HSL_HUE_EXT = VK_BLEND_OP_HSL_HUE_EXT;
const uint32_t BLEND_OP_HSL_SATURATION_EXT = VK_BLEND_OP_HSL_SATURATION_EXT;
const uint32_t BLEND_OP_HSL_COLOR_EXT = VK_BLEND_OP_HSL_COLOR_EXT;
const uint32_t BLEND_OP_HSL_LUMINOSITY_EXT = VK_BLEND_OP_HSL_LUMINOSITY_EXT;
const uint32_t BLEND_OP_PLUS_EXT = VK_BLEND_OP_PLUS_EXT;
const uint32_t BLEND_OP_PLUS_CLAMPED_EXT = VK_BLEND_OP_PLUS_CLAMPED_EXT;
const uint32_t BLEND_OP_PLUS_CLAMPED_ALPHA_EXT = VK_BLEND_OP_PLUS_CLAMPED_ALPHA_EXT;
const uint32_t BLEND_OP_PLUS_DARKER_EXT = VK_BLEND_OP_PLUS_DARKER_EXT;
const uint32_t BLEND_OP_MINUS_EXT = VK_BLEND_OP_MINUS_EXT;
const uint32_t BLEND_OP_MINUS_CLAMPED_EXT = VK_BLEND_OP_MINUS_CLAMPED_EXT;
const uint32_t BLEND_OP_CONTRAST_EXT = VK_BLEND_OP_CONTRAST_EXT;
const uint32_t BLEND_OP_INVERT_OVG_EXT = VK_BLEND_OP_INVERT_OVG_EXT;
const uint32_t BLEND_OP_RED_EXT = VK_BLEND_OP_RED_EXT;
const uint32_t BLEND_OP_GREEN_EXT = VK_BLEND_OP_GREEN_EXT;
const uint32_t BLEND_OP_BLUE_EXT = VK_BLEND_OP_BLUE_EXT;
const uint32_t BLEND_OP_BEGIN_RANGE = VK_BLEND_OP_BEGIN_RANGE;
const uint32_t BLEND_OP_END_RANGE = VK_BLEND_OP_END_RANGE;
const uint32_t BLEND_OP_RANGE_SIZE = VK_BLEND_OP_RANGE_SIZE;
const uint32_t BLEND_OP_MAX_ENUM = VK_BLEND_OP_MAX_ENUM;

const uint32_t DYNAMIC_STATE_VIEWPORT = VK_DYNAMIC_STATE_VIEWPORT;
const uint32_t DYNAMIC_STATE_SCISSOR = VK_DYNAMIC_STATE_SCISSOR;
const uint32_t DYNAMIC_STATE_LINE_WIDTH = VK_DYNAMIC_STATE_LINE_WIDTH;
const uint32_t DYNAMIC_STATE_DEPTH_BIAS = VK_DYNAMIC_STATE_DEPTH_BIAS;
const uint32_t DYNAMIC_STATE_BLEND_CONSTANTS = VK_DYNAMIC_STATE_BLEND_CONSTANTS;
const uint32_t DYNAMIC_STATE_DEPTH_BOUNDS = VK_DYNAMIC_STATE_DEPTH_BOUNDS;
const uint32_t DYNAMIC_STATE_STENCIL_COMPARE_MASK = VK_DYNAMIC_STATE_STENCIL_COMPARE_MASK;
const uint32_t DYNAMIC_STATE_STENCIL_WRITE_MASK = VK_DYNAMIC_STATE_STENCIL_WRITE_MASK;
const uint32_t DYNAMIC_STATE_STENCIL_REFERENCE = VK_DYNAMIC_STATE_STENCIL_REFERENCE;
const uint32_t DYNAMIC_STATE_VIEWPORT_W_SCALING_NV = VK_DYNAMIC_STATE_VIEWPORT_W_SCALING_NV;
const uint32_t DYNAMIC_STATE_DISCARD_RECTANGLE_EXT = VK_DYNAMIC_STATE_DISCARD_RECTANGLE_EXT;
const uint32_t DYNAMIC_STATE_SAMPLE_LOCATIONS_EXT = VK_DYNAMIC_STATE_SAMPLE_LOCATIONS_EXT;
const uint32_t DYNAMIC_STATE_BEGIN_RANGE = VK_DYNAMIC_STATE_BEGIN_RANGE;
const uint32_t DYNAMIC_STATE_END_RANGE = VK_DYNAMIC_STATE_END_RANGE;
const uint32_t DYNAMIC_STATE_RANGE_SIZE = VK_DYNAMIC_STATE_RANGE_SIZE;
const uint32_t DYNAMIC_STATE_MAX_ENUM = VK_DYNAMIC_STATE_MAX_ENUM;

const uint32_t CULL_MODE_NONE = VK_CULL_MODE_NONE;
const uint32_t CULL_MODE_FRONT_BIT = VK_CULL_MODE_FRONT_BIT;
const uint32_t CULL_MODE_BACK_BIT = VK_CULL_MODE_BACK_BIT;
const uint32_t CULL_MODE_FRONT_AND_BACK = VK_CULL_MODE_FRONT_AND_BACK;
const uint32_t CULL_MODE_FLAG_BITS_MAX_ENUM = VK_CULL_MODE_FLAG_BITS_MAX_ENUM;

const uint32_t COLOR_COMPONENT_R_BIT = VK_COLOR_COMPONENT_R_BIT;
const uint32_t COLOR_COMPONENT_G_BIT = VK_COLOR_COMPONENT_G_BIT;
const uint32_t COLOR_COMPONENT_B_BIT = VK_COLOR_COMPONENT_B_BIT;
const uint32_t COLOR_COMPONENT_A_BIT = VK_COLOR_COMPONENT_A_BIT;
const uint32_t COLOR_COMPONENT_FLAG_BITS_MAX_ENUM = VK_COLOR_COMPONENT_FLAG_BITS_MAX_ENUM;

const uint32_t DESCRIPTOR_TYPE_SAMPLER = VK_DESCRIPTOR_TYPE_SAMPLER;
const uint32_t DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER = VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER;
const uint32_t DESCRIPTOR_TYPE_SAMPLED_IMAGE = VK_DESCRIPTOR_TYPE_SAMPLED_IMAGE;
const uint32_t DESCRIPTOR_TYPE_STORAGE_IMAGE = VK_DESCRIPTOR_TYPE_STORAGE_IMAGE;
const uint32_t DESCRIPTOR_TYPE_UNIFORM_TEXEL_BUFFER = VK_DESCRIPTOR_TYPE_UNIFORM_TEXEL_BUFFER;
const uint32_t DESCRIPTOR_TYPE_STORAGE_TEXEL_BUFFER = VK_DESCRIPTOR_TYPE_STORAGE_TEXEL_BUFFER;
const uint32_t DESCRIPTOR_TYPE_UNIFORM_BUFFER = VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER;
const uint32_t DESCRIPTOR_TYPE_STORAGE_BUFFER = VK_DESCRIPTOR_TYPE_STORAGE_BUFFER;
const uint32_t DESCRIPTOR_TYPE_UNIFORM_BUFFER_DYNAMIC = VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER_DYNAMIC;
const uint32_t DESCRIPTOR_TYPE_STORAGE_BUFFER_DYNAMIC = VK_DESCRIPTOR_TYPE_STORAGE_BUFFER_DYNAMIC;
const uint32_t DESCRIPTOR_TYPE_INPUT_ATTACHMENT = VK_DESCRIPTOR_TYPE_INPUT_ATTACHMENT;
const uint32_t DESCRIPTOR_TYPE_BEGIN_RANGE = VK_DESCRIPTOR_TYPE_BEGIN_RANGE;
const uint32_t DESCRIPTOR_TYPE_END_RANGE = VK_DESCRIPTOR_TYPE_END_RANGE;
const uint32_t DESCRIPTOR_TYPE_RANGE_SIZE = VK_DESCRIPTOR_TYPE_RANGE_SIZE;
const uint32_t DESCRIPTOR_TYPE_MAX_ENUM = VK_DESCRIPTOR_TYPE_MAX_ENUM;

const uint32_t ATTACHMENT_LOAD_OP_LOAD = VK_ATTACHMENT_LOAD_OP_LOAD;
const uint32_t ATTACHMENT_LOAD_OP_CLEAR = VK_ATTACHMENT_LOAD_OP_CLEAR;
const uint32_t ATTACHMENT_LOAD_OP_DONT_CARE = VK_ATTACHMENT_LOAD_OP_DONT_CARE;
const uint32_t ATTACHMENT_LOAD_OP_BEGIN_RANGE = VK_ATTACHMENT_LOAD_OP_BEGIN_RANGE;
const uint32_t ATTACHMENT_LOAD_OP_END_RANGE = VK_ATTACHMENT_LOAD_OP_END_RANGE;
const uint32_t ATTACHMENT_LOAD_OP_RANGE_SIZE = VK_ATTACHMENT_LOAD_OP_RANGE_SIZE;
const uint32_t ATTACHMENT_LOAD_OP_MAX_ENUM = VK_ATTACHMENT_LOAD_OP_MAX_ENUM;

const uint32_t ATTACHMENT_STORE_OP_STORE = VK_ATTACHMENT_STORE_OP_STORE;
const uint32_t ATTACHMENT_STORE_OP_DONT_CARE = VK_ATTACHMENT_STORE_OP_DONT_CARE;
const uint32_t ATTACHMENT_STORE_OP_BEGIN_RANGE = VK_ATTACHMENT_STORE_OP_BEGIN_RANGE;
const uint32_t ATTACHMENT_STORE_OP_END_RANGE = VK_ATTACHMENT_STORE_OP_END_RANGE;
const uint32_t ATTACHMENT_STORE_OP_RANGE_SIZE = VK_ATTACHMENT_STORE_OP_RANGE_SIZE;
const uint32_t ATTACHMENT_STORE_OP_MAX_ENUM = VK_ATTACHMENT_STORE_OP_MAX_ENUM;

const uint32_t IMAGE_LAYOUT_UNDEFINED = VK_IMAGE_LAYOUT_UNDEFINED;
const uint32_t IMAGE_LAYOUT_GENERAL = VK_IMAGE_LAYOUT_GENERAL;
const uint32_t IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL = VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL;
const uint32_t IMAGE_LAYOUT_DEPTH_STENCIL_ATTACHMENT_OPTIMAL = VK_IMAGE_LAYOUT_DEPTH_STENCIL_ATTACHMENT_OPTIMAL;
const uint32_t IMAGE_LAYOUT_DEPTH_STENCIL_READ_ONLY_OPTIMAL = VK_IMAGE_LAYOUT_DEPTH_STENCIL_READ_ONLY_OPTIMAL;
const uint32_t IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL = VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL;
const uint32_t IMAGE_LAYOUT_TRANSFER_SRC_OPTIMAL = VK_IMAGE_LAYOUT_TRANSFER_SRC_OPTIMAL;
const uint32_t IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL = VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL;
const uint32_t IMAGE_LAYOUT_PREINITIALIZED = VK_IMAGE_LAYOUT_PREINITIALIZED;
const uint32_t IMAGE_LAYOUT_DEPTH_READ_ONLY_STENCIL_ATTACHMENT_OPTIMAL = VK_IMAGE_LAYOUT_DEPTH_READ_ONLY_STENCIL_ATTACHMENT_OPTIMAL;
const uint32_t IMAGE_LAYOUT_DEPTH_ATTACHMENT_STENCIL_READ_ONLY_OPTIMAL = VK_IMAGE_LAYOUT_DEPTH_ATTACHMENT_STENCIL_READ_ONLY_OPTIMAL;
const uint32_t IMAGE_LAYOUT_PRESENT_SRC_KHR = VK_IMAGE_LAYOUT_PRESENT_SRC_KHR;
const uint32_t IMAGE_LAYOUT_SHARED_PRESENT_KHR = VK_IMAGE_LAYOUT_SHARED_PRESENT_KHR;
const uint32_t IMAGE_LAYOUT_DEPTH_READ_ONLY_STENCIL_ATTACHMENT_OPTIMAL_KHR = VK_IMAGE_LAYOUT_DEPTH_READ_ONLY_STENCIL_ATTACHMENT_OPTIMAL_KHR;
const uint32_t IMAGE_LAYOUT_DEPTH_ATTACHMENT_STENCIL_READ_ONLY_OPTIMAL_KHR = VK_IMAGE_LAYOUT_DEPTH_ATTACHMENT_STENCIL_READ_ONLY_OPTIMAL_KHR;
const uint32_t IMAGE_LAYOUT_BEGIN_RANGE = VK_IMAGE_LAYOUT_BEGIN_RANGE;
const uint32_t IMAGE_LAYOUT_END_RANGE = VK_IMAGE_LAYOUT_END_RANGE;
const uint32_t IMAGE_LAYOUT_RANGE_SIZE = VK_IMAGE_LAYOUT_RANGE_SIZE;
const uint32_t IMAGE_LAYOUT_MAX_ENUM = VK_IMAGE_LAYOUT_MAX_ENUM;

const uint32_t SUBPASS_DESCRIPTION_PER_VIEW_ATTRIBUTES_BIT_NVX = VK_SUBPASS_DESCRIPTION_PER_VIEW_ATTRIBUTES_BIT_NVX;
const uint32_t SUBPASS_DESCRIPTION_PER_VIEW_POSITION_X_ONLY_BIT_NVX = VK_SUBPASS_DESCRIPTION_PER_VIEW_POSITION_X_ONLY_BIT_NVX;
const uint32_t SUBPASS_DESCRIPTION_FLAG_BITS_MAX_ENUM = VK_SUBPASS_DESCRIPTION_FLAG_BITS_MAX_ENUM;

const uint32_t PIPELINE_BIND_POINT_GRAPHICS = VK_PIPELINE_BIND_POINT_GRAPHICS;
const uint32_t PIPELINE_BIND_POINT_COMPUTE = VK_PIPELINE_BIND_POINT_COMPUTE;
const uint32_t PIPELINE_BIND_POINT_BEGIN_RANGE = VK_PIPELINE_BIND_POINT_BEGIN_RANGE;
const uint32_t PIPELINE_BIND_POINT_END_RANGE = VK_PIPELINE_BIND_POINT_END_RANGE;
const uint32_t PIPELINE_BIND_POINT_RANGE_SIZE = VK_PIPELINE_BIND_POINT_RANGE_SIZE;
const uint32_t PIPELINE_BIND_POINT_MAX_ENUM = VK_PIPELINE_BIND_POINT_MAX_ENUM;

const uint32_t PIPELINE_STAGE_TOP_OF_PIPE_BIT = VK_PIPELINE_STAGE_TOP_OF_PIPE_BIT;
const uint32_t PIPELINE_STAGE_DRAW_INDIRECT_BIT = VK_PIPELINE_STAGE_DRAW_INDIRECT_BIT;
const uint32_t PIPELINE_STAGE_VERTEX_INPUT_BIT = VK_PIPELINE_STAGE_VERTEX_INPUT_BIT;
const uint32_t PIPELINE_STAGE_VERTEX_SHADER_BIT = VK_PIPELINE_STAGE_VERTEX_SHADER_BIT;
const uint32_t PIPELINE_STAGE_TESSELLATION_CONTROL_SHADER_BIT = VK_PIPELINE_STAGE_TESSELLATION_CONTROL_SHADER_BIT;
const uint32_t PIPELINE_STAGE_TESSELLATION_EVALUATION_SHADER_BIT = VK_PIPELINE_STAGE_TESSELLATION_EVALUATION_SHADER_BIT;
const uint32_t PIPELINE_STAGE_GEOMETRY_SHADER_BIT = VK_PIPELINE_STAGE_GEOMETRY_SHADER_BIT;
const uint32_t PIPELINE_STAGE_FRAGMENT_SHADER_BIT = VK_PIPELINE_STAGE_FRAGMENT_SHADER_BIT;
const uint32_t PIPELINE_STAGE_EARLY_FRAGMENT_TESTS_BIT = VK_PIPELINE_STAGE_EARLY_FRAGMENT_TESTS_BIT;
const uint32_t PIPELINE_STAGE_LATE_FRAGMENT_TESTS_BIT = VK_PIPELINE_STAGE_LATE_FRAGMENT_TESTS_BIT;
const uint32_t PIPELINE_STAGE_COLOR_ATTACHMENT_OUTPUT_BIT = VK_PIPELINE_STAGE_COLOR_ATTACHMENT_OUTPUT_BIT;
const uint32_t PIPELINE_STAGE_COMPUTE_SHADER_BIT = VK_PIPELINE_STAGE_COMPUTE_SHADER_BIT;
const uint32_t PIPELINE_STAGE_TRANSFER_BIT = VK_PIPELINE_STAGE_TRANSFER_BIT;
const uint32_t PIPELINE_STAGE_BOTTOM_OF_PIPE_BIT = VK_PIPELINE_STAGE_BOTTOM_OF_PIPE_BIT;
const uint32_t PIPELINE_STAGE_HOST_BIT = VK_PIPELINE_STAGE_HOST_BIT;
const uint32_t PIPELINE_STAGE_ALL_GRAPHICS_BIT = VK_PIPELINE_STAGE_ALL_GRAPHICS_BIT;
const uint32_t PIPELINE_STAGE_ALL_COMMANDS_BIT = VK_PIPELINE_STAGE_ALL_COMMANDS_BIT;
const uint32_t PIPELINE_STAGE_COMMAND_PROCESS_BIT_NVX = VK_PIPELINE_STAGE_COMMAND_PROCESS_BIT_NVX;
const uint32_t PIPELINE_STAGE_FLAG_BITS_MAX_ENUM = VK_PIPELINE_STAGE_FLAG_BITS_MAX_ENUM;

const uint32_t ACCESS_INDIRECT_COMMAND_READ_BIT = VK_ACCESS_INDIRECT_COMMAND_READ_BIT;
const uint32_t ACCESS_INDEX_READ_BIT = VK_ACCESS_INDEX_READ_BIT;
const uint32_t ACCESS_VERTEX_ATTRIBUTE_READ_BIT = VK_ACCESS_VERTEX_ATTRIBUTE_READ_BIT;
const uint32_t ACCESS_UNIFORM_READ_BIT = VK_ACCESS_UNIFORM_READ_BIT;
const uint32_t ACCESS_INPUT_ATTACHMENT_READ_BIT = VK_ACCESS_INPUT_ATTACHMENT_READ_BIT;
const uint32_t ACCESS_SHADER_READ_BIT = VK_ACCESS_SHADER_READ_BIT;
const uint32_t ACCESS_SHADER_WRITE_BIT = VK_ACCESS_SHADER_WRITE_BIT;
const uint32_t ACCESS_COLOR_ATTACHMENT_READ_BIT = VK_ACCESS_COLOR_ATTACHMENT_READ_BIT;
const uint32_t ACCESS_COLOR_ATTACHMENT_WRITE_BIT = VK_ACCESS_COLOR_ATTACHMENT_WRITE_BIT;
const uint32_t ACCESS_DEPTH_STENCIL_ATTACHMENT_READ_BIT = VK_ACCESS_DEPTH_STENCIL_ATTACHMENT_READ_BIT;
const uint32_t ACCESS_DEPTH_STENCIL_ATTACHMENT_WRITE_BIT = VK_ACCESS_DEPTH_STENCIL_ATTACHMENT_WRITE_BIT;
const uint32_t ACCESS_TRANSFER_READ_BIT = VK_ACCESS_TRANSFER_READ_BIT;
const uint32_t ACCESS_TRANSFER_WRITE_BIT = VK_ACCESS_TRANSFER_WRITE_BIT;
const uint32_t ACCESS_HOST_READ_BIT = VK_ACCESS_HOST_READ_BIT;
const uint32_t ACCESS_HOST_WRITE_BIT = VK_ACCESS_HOST_WRITE_BIT;
const uint32_t ACCESS_MEMORY_READ_BIT = VK_ACCESS_MEMORY_READ_BIT;
const uint32_t ACCESS_MEMORY_WRITE_BIT = VK_ACCESS_MEMORY_WRITE_BIT;
const uint32_t ACCESS_COMMAND_PROCESS_READ_BIT_NVX = VK_ACCESS_COMMAND_PROCESS_READ_BIT_NVX;
const uint32_t ACCESS_COMMAND_PROCESS_WRITE_BIT_NVX = VK_ACCESS_COMMAND_PROCESS_WRITE_BIT_NVX;
const uint32_t ACCESS_COLOR_ATTACHMENT_READ_NONCOHERENT_BIT_EXT = VK_ACCESS_COLOR_ATTACHMENT_READ_NONCOHERENT_BIT_EXT;
const uint32_t ACCESS_FLAG_BITS_MAX_ENUM = VK_ACCESS_FLAG_BITS_MAX_ENUM;

const uint32_t DEPENDENCY_BY_REGION_BIT = VK_DEPENDENCY_BY_REGION_BIT;
const uint32_t DEPENDENCY_DEVICE_GROUP_BIT = VK_DEPENDENCY_DEVICE_GROUP_BIT;
const uint32_t DEPENDENCY_VIEW_LOCAL_BIT = VK_DEPENDENCY_VIEW_LOCAL_BIT;
const uint32_t DEPENDENCY_VIEW_LOCAL_BIT_KHR = VK_DEPENDENCY_VIEW_LOCAL_BIT_KHR;
const uint32_t DEPENDENCY_DEVICE_GROUP_BIT_KHR = VK_DEPENDENCY_DEVICE_GROUP_BIT_KHR;
const uint32_t DEPENDENCY_FLAG_BITS_MAX_ENUM = VK_DEPENDENCY_FLAG_BITS_MAX_ENUM;


/* DescriptorSetLayout */
DescriptorSetLayout::~DescriptorSetLayout() {
    if (_vk_descriptorSetLayout) {
        VkDevice dev = bg::native_cast<VkDevice>(_vk_device);
        VkDescriptorSetLayout lo = bg::native_cast<VkDescriptorSetLayout>(_vk_descriptorSetLayout);
        vkDestroyDescriptorSetLayout(dev, lo, nullptr);
        _vk_descriptorSetLayout = nullptr;
        _vk_device = nullptr;
    }
}

void DescriptorSetLayout::create(Device * dev) {
    VkDevice vkDev = bg::native_cast<VkDevice>(dev->vkDevice());
    _vk_device = vkDev;
    
    std::vector<VkDescriptorSetLayoutBinding> loBinding;
    for (auto b : createInfo.bindings) {
        VkDescriptorSetLayoutBinding vkBind = {};
        vkBind.binding = b.binding;
        vkBind.descriptorType = static_cast<VkDescriptorType>(b.descriptorType);
        vkBind.descriptorCount = b.descriptorCount;
        vkBind.stageFlags = b.stageFlags;
        loBinding.push_back(vkBind);
    }
    
    VkDescriptorSetLayoutCreateInfo info = {};
    info.sType = VK_STRUCTURE_TYPE_DESCRIPTOR_SET_LAYOUT_CREATE_INFO;
    info.bindingCount = static_cast<uint32_t>(loBinding.size());
    info.pBindings = loBinding.data();
    
    VkDescriptorSetLayout descriptorSetLayout;
    if (vkCreateDescriptorSetLayout(vkDev, &info, nullptr, &descriptorSetLayout) != VK_SUCCESS) {
        throw bg::base::VulkanEngineException("Could not create descriptor set layout.");
    }
    _vk_descriptorSetLayout = descriptorSetLayout;
}
/* End DescriptorSetLayout */

/* BufferView */
BufferView::~BufferView() {
}
/* End BufferView */

/* DescriptorSet */
DescriptorSet::~DescriptorSet() {
	if (_vk_descriptorSet) {

	}
}

void DescriptorSet::allocateDescriptorSets(Device * dev) {
	VkDevice vkDev = bg::native_cast<VkDevice>(dev->vkDevice());
	_vk_device = vkDev;

	VkDescriptorSetAllocateInfo info = {};
	info.sType = VK_STRUCTURE_TYPE_DESCRIPTOR_SET_ALLOCATE_INFO;
	
	std::vector<VkDescriptorSetLayout> layouts;
	for (auto & lo : allocateInfo.setLayouts) {
		layouts.push_back(bg::native_cast<VkDescriptorSetLayout>(lo->vkDescriptorSetLayout()));
	}
	info.descriptorSetCount = static_cast<uint32_t>(layouts.size());
	info.pSetLayouts = layouts.data();

	info.descriptorPool = bg::native_cast<VkDescriptorPool>(allocateInfo.descriptorPool->vkDescriptorPool());

	VkDescriptorSet ds;
	if (vkAllocateDescriptorSets(vkDev, &info, &ds) != VK_SUCCESS) {
		throw bg::base::VulkanEngineException("Could not allocate descriptor set");
	}
	_vk_descriptorSet = ds;
}

void DescriptorSet::updateDescriptorSets(const std::vector<WriteDescriptorSet> & wds) {
	std::vector<VkWriteDescriptorSet> descriptorWrite;

	std::vector<VkDescriptorBufferInfo*> descBufferInfos;
	std::vector<VkDescriptorImageInfo*> descImageInfos;
	for (auto & w : wds) {
		VkWriteDescriptorSet writeDescriptorSet = {};
		writeDescriptorSet.sType = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET;
		writeDescriptorSet.dstSet = w.dstSet.valid() ? bg::native_cast<VkDescriptorSet>(w.dstSet->vkDescriptorSet()) : nullptr;
		writeDescriptorSet.dstBinding = w.dstBinding;
		writeDescriptorSet.dstArrayElement = w.dstArrayElement;
		writeDescriptorSet.descriptorType = static_cast<VkDescriptorType>(w.descriptorType);
		writeDescriptorSet.descriptorCount = w.descriptorCount;

		if (w.pBufferInfo) {
			VkDescriptorBufferInfo * dbi = new VkDescriptorBufferInfo;
			dbi->buffer = bg::native_cast<VkBuffer>(w.pBufferInfo->buffer->vkBuffer());
			dbi->offset = w.pBufferInfo->offset;
			dbi->range = w.pBufferInfo->range;
			descBufferInfos.push_back(dbi);
			writeDescriptorSet.pBufferInfo = dbi;
		}
		if (w.pImageInfo) {
			VkDescriptorImageInfo * dii = new VkDescriptorImageInfo;
			dii->imageLayout = static_cast<VkImageLayout>(w.pImageInfo->imageLayout);
			dii->imageView = bg::native_cast<VkImageView>(w.pImageInfo->imageView->vkImageView());
			dii->sampler = bg::native_cast<VkSampler>(w.pImageInfo->sampler->vkSampler());
			descImageInfos.push_back(dii);
			writeDescriptorSet.pImageInfo = dii;
		}
		if (w.pTexelBufferView.valid()) {
			// TODO: implement this
		}
		descriptorWrite.push_back(writeDescriptorSet);
	}

	vkUpdateDescriptorSets(bg::native_cast<VkDevice>(_vk_device), static_cast<uint32_t>(descriptorWrite.size()), descriptorWrite.data(), 0, nullptr);

	for (auto i : descBufferInfos) {
		delete i;
	}
	for (auto i : descImageInfos) {
		delete i;
	}
	descBufferInfos.clear();
	descImageInfos.clear();
}
/* End DescriptorSet */

/* ShaderModule */
ShaderModule::~ShaderModule() {
    if (_vk_shaderModule) {
        VkDevice dev = bg::native_cast<VkDevice>(_vk_device);
        VkShaderModule shaderModule = bg::native_cast<VkShaderModule>(_vk_shaderModule);
        vkDestroyShaderModule(dev, shaderModule, nullptr);
        _vk_shaderModule = nullptr;
        _vk_device = nullptr;
    }
}

void ShaderModule::create(Device * dev, const Buffer & buffer) {
    VkDevice vkDev = bg::native_cast<VkDevice>(dev->vkDevice());
    VkShaderModule shaderModule;
    VkShaderModuleCreateInfo info = {};
    info.sType = VK_STRUCTURE_TYPE_SHADER_MODULE_CREATE_INFO;
    info.codeSize = buffer.size();
    info.pCode = reinterpret_cast<const uint32_t*>(buffer.data());
    if (vkCreateShaderModule(vkDev, &info, nullptr, &shaderModule)!=VK_SUCCESS) {
        throw bg::base::VulkanEngineException("Error creating shader module.");
    }
    _vk_shaderModule = shaderModule;
    _vk_device = vkDev;
}
/* End ShaderModule */

/* PipelineLayout */
PipelineLayout::~PipelineLayout() {
    if (_vk_pipelineLayout) {
        VkDevice dev = bg::native_cast<VkDevice>(_vk_device);
        VkPipelineLayout lo = bg::native_cast<VkPipelineLayout>(_vk_pipelineLayout);
        vkDestroyPipelineLayout(dev, lo, nullptr);
        _vk_pipelineLayout = nullptr;
        _vk_device = nullptr;
    }
}

void PipelineLayout::create(Device * dev) {
    VkDevice vkDev = bg::native_cast<VkDevice>(dev->vkDevice());
    _vk_device = vkDev;

	std::vector<VkDescriptorSetLayout> layouts;
	for (auto lo : createInfo.setLayouts) {
		layouts.push_back(bg::native_cast<VkDescriptorSetLayout>(lo->vkDescriptorSetLayout()));
	}

	std::vector<VkPushConstantRange> pushConstants;
	for (auto pcr : createInfo.pushConstantRanges) {
		VkPushConstantRange range = {};
		range.offset = pcr.offset;
		range.size = pcr.size;
		range.stageFlags = range.stageFlags;
		pushConstants.push_back(range);
	}
    
    VkPipelineLayoutCreateInfo info = {};
    info.sType = VK_STRUCTURE_TYPE_PIPELINE_LAYOUT_CREATE_INFO;
    info.setLayoutCount = static_cast<uint32_t>(layouts.size());
    info.pSetLayouts = layouts.data();
    info.pushConstantRangeCount = static_cast<uint32_t>(pushConstants.size());
    info.pPushConstantRanges = pushConstants.data();
    
    VkPipelineLayout pipelineLayout;
    if (vkCreatePipelineLayout(vkDev, &info, nullptr, &pipelineLayout)!=VK_SUCCESS) {
        throw bg::base::VulkanEngineException("Could not create pipeline layout.");
    }
    _vk_pipelineLayout = pipelineLayout;
}
/* End PipelineLayout */

/* RenderPass */

const uint32_t ATTACHMENT_DESCRIPTION_MAY_ALIAS_BIT = VK_ATTACHMENT_DESCRIPTION_MAY_ALIAS_BIT;
const uint32_t ATTACHMENT_DESCRIPTION_FLAG_BITS_MAX_ENUM = VK_ATTACHMENT_DESCRIPTION_FLAG_BITS_MAX_ENUM;

RenderPass::~RenderPass() {
    if (_vk_renderPass) {
        VkRenderPass rp = bg::native_cast<VkRenderPass>(_vk_renderPass);
        VkDevice dev = bg::native_cast<VkDevice>(_vk_device);
        vkDestroyRenderPass(dev, rp, nullptr);
        _vk_renderPass = nullptr;
        _vk_device = nullptr;
    }
}

void RenderPass::create(Device * dev) {
    VkDevice vkDev = bg::native_cast<VkDevice>(dev->vkDevice());
    _vk_device = vkDev;

    VkRenderPassCreateInfo createInfo = {};
    createInfo.sType = VK_STRUCTURE_TYPE_RENDER_PASS_CREATE_INFO;
    
    std::vector<VkAttachmentDescription> atts;
    std::vector<VkSubpassDescription> subpasses;
    std::vector<VkSubpassDependency> subpassDeps;
    if (this->createInfo.attachments.size()>0) {
        for (auto & a : this->createInfo.attachments) {
            VkAttachmentDescription att = {};
            att.flags = static_cast<VkAttachmentDescriptionFlags>(a.flags);
            att.format = static_cast<VkFormat>(a.format);
            att.samples = static_cast<VkSampleCountFlagBits>(a.samples);
            att.loadOp = static_cast<VkAttachmentLoadOp>(a.loadOp);
            att.storeOp = static_cast<VkAttachmentStoreOp>(a.storeOp);
            att.stencilLoadOp = static_cast<VkAttachmentLoadOp>(a.stencilLoadOp);
            att.stencilStoreOp = static_cast<VkAttachmentStoreOp>(a.stencilStoreOp);
            att.initialLayout = static_cast<VkImageLayout>(a.initialLayout);
            att.finalLayout = static_cast<VkImageLayout>(a.finalLayout);
            atts.push_back(att);
        }
        createInfo.attachmentCount = static_cast<uint32_t>(atts.size());
        createInfo.pAttachments = atts.data();
    }
    
    std::vector<std::vector<VkAttachmentReference> *> attRefs;
	VkAttachmentReference * depthAttachmentRef = nullptr;
    if (this->createInfo.subpasses.size()>0) {
        for (auto & s : this->createInfo.subpasses) {
			VkSubpassDescription sd = {};
            sd.flags = static_cast<VkSubpassDescriptionFlags>(s.flags);
            sd.pipelineBindPoint = static_cast<VkPipelineBindPoint>(s.pipelineBindPoint);
            std::vector<VkAttachmentReference> * attRef = new std::vector<VkAttachmentReference>();
            for (auto & ref : s.inputAttachments) {
				attRef->push_back({ ref.attachment, static_cast<VkImageLayout>(ref.layout) });
            }
            attRefs.push_back(attRef);
			if (attRef->size() > 0) {
				sd.inputAttachmentCount = static_cast<int32_t>(attRef->size());
				sd.pInputAttachments = attRef->data();
			}
            
            std::vector<VkAttachmentReference> * cAttRef = new std::vector<VkAttachmentReference>();
            for (auto & ref : s.colorAttachments) {
                cAttRef->push_back({ ref.attachment, static_cast<VkImageLayout>(ref.layout) });
            }
            attRefs.push_back(cAttRef);
			if (cAttRef->size() > 0) {
				sd.colorAttachmentCount = static_cast<uint32_t>(cAttRef->size());
				sd.pColorAttachments = cAttRef->data();
			}
            
            std::vector<VkAttachmentReference> * rAttRef = new std::vector<VkAttachmentReference>();
            for (auto & ref : s.resolveAttachments) {
                rAttRef->push_back({ ref.attachment, static_cast<VkImageLayout>(ref.layout) });
            }
            attRefs.push_back(rAttRef);
			if (rAttRef->size() > 0) {
				sd.preserveAttachmentCount = static_cast<uint32_t>(rAttRef->size());
				sd.pResolveAttachments = rAttRef->data();
			}

			if (s.useDepthStencilAttachment) {
				depthAttachmentRef = new VkAttachmentReference;
				depthAttachmentRef->attachment = s.depthStencilAttachment.attachment;
				depthAttachmentRef->layout = static_cast<VkImageLayout>(s.depthStencilAttachment.layout);
				sd.pDepthStencilAttachment = depthAttachmentRef;
			}
            
            subpasses.push_back(sd);
        }
        createInfo.subpassCount = static_cast<uint32_t>(subpasses.size());
        createInfo.pSubpasses = subpasses.data();
    }
    
    if (this->createInfo.dependencies.size()>0) {
        for (auto & s : this->createInfo.dependencies) {
            VkSubpassDependency sd;
            sd.srcSubpass = s.srcSubpass;
            sd.dstSubpass = s.dstSubpass;
            sd.srcStageMask = static_cast<VkPipelineStageFlags>(s.srcStageMask);
            sd.dstStageMask = static_cast<VkPipelineStageFlags>(s.dstStageMask);
            sd.srcAccessMask = static_cast<VkAccessFlags>(s.srcAccessMask);
            sd.dstAccessMask = static_cast<VkAccessFlags>(s.dstAccessMask);
            sd.dependencyFlags = static_cast<VkDependencyFlags>(s.dependencyFlags);
            subpassDeps.push_back(sd);
        }
        createInfo.dependencyCount = static_cast<uint32_t>(subpassDeps.size());
        createInfo.pDependencies = subpassDeps.data();
    }
    
    VkRenderPass renderPass;
    if (vkCreateRenderPass(vkDev, &createInfo, nullptr, &renderPass)!=VK_SUCCESS) {
        throw bg::base::VulkanEngineException("Could not create render pass.");
    }
    _vk_renderPass = renderPass;

	for (auto vec : attRefs) {
		delete vec;
	}
	attRefs.clear();

	if (depthAttachmentRef) {
		delete depthAttachmentRef;
	}
}
/* End RenderPass */

/* Pipeline */
Pipeline::~Pipeline() {
    if (_vk_pipeline) {
        VkDevice dev = bg::native_cast<VkDevice>(_vk_device);
        VkPipeline pipe = bg::native_cast<VkPipeline>(_vk_pipeline);
        vkDestroyPipeline(dev, pipe, nullptr);
    }
    _pipelineLayout = nullptr;
}

void Pipeline::create(Device * dev) {
    VkDevice vkDev = bg::native_cast<VkDevice>(dev->vkDevice());
    _vk_device = vkDev;
    
    // Shader stages
    std::vector<VkPipelineShaderStageCreateInfo> shaderStages;
    for (auto & s : this->shaderStages) {
        VkPipelineShaderStageCreateInfo stageInfo = {};
        stageInfo.sType = VK_STRUCTURE_TYPE_PIPELINE_SHADER_STAGE_CREATE_INFO;
        stageInfo.stage = static_cast<VkShaderStageFlagBits>(s.stage);
        stageInfo.module = bg::native_cast<VkShaderModule>(s.module->vkShaderModule());
        stageInfo.pName = s.name.c_str();
        shaderStages.push_back(stageInfo);
    }
    
    // Vertex input
    VkPipelineVertexInputStateCreateInfo vertexInputInfo = {};
    vertexInputInfo.sType = VK_STRUCTURE_TYPE_PIPELINE_VERTEX_INPUT_STATE_CREATE_INFO;
    std::vector<VkVertexInputBindingDescription> vertexBinding;
    if (this->vertexInputState.vertexBindingDescriptions.size()>0) {
        for (auto & binding : this->vertexInputState.vertexBindingDescriptions) {
            VkVertexInputBindingDescription bindingDesc;
            bindingDesc.binding = binding.binding;
            bindingDesc.stride = binding.stride;
            bindingDesc.inputRate = static_cast<VkVertexInputRate>(binding.inputRate);
            vertexBinding.push_back(bindingDesc);
        }
        vertexInputInfo.vertexBindingDescriptionCount = static_cast<uint32_t>(vertexBinding.size());
        vertexInputInfo.pVertexBindingDescriptions = vertexBinding.data();
    }
    std::vector<VkVertexInputAttributeDescription> vertexAttrib;
    if (this->vertexInputState.vertexAttributeDescriptions.size()>0) {
        for (auto & attrib : this->vertexInputState.vertexAttributeDescriptions) {
            VkVertexInputAttributeDescription attribDesc;
            attribDesc.location = attrib.location;
            attribDesc.binding = attrib.binding;
            attribDesc.format = static_cast<VkFormat>(attrib.format);
            attribDesc.offset = attrib.offset;
            vertexAttrib.push_back(attribDesc);
        }
        vertexInputInfo.vertexAttributeDescriptionCount = static_cast<uint32_t>(vertexAttrib.size());
        vertexInputInfo.pVertexAttributeDescriptions = vertexAttrib.data();
    }
    
    // Input assembly
    VkPipelineInputAssemblyStateCreateInfo inputAssembly = {};
    inputAssembly.sType = VK_STRUCTURE_TYPE_PIPELINE_INPUT_ASSEMBLY_STATE_CREATE_INFO;
    inputAssembly.topology = static_cast<VkPrimitiveTopology>(this->inputAssemblyState.topology);
    inputAssembly.primitiveRestartEnable = static_cast<VkBool32>(this->inputAssemblyState.primitiveRestartEnable);
    
    // Viewport state
    VkPipelineViewportStateCreateInfo viewportState = {};
    viewportState.sType = VK_STRUCTURE_TYPE_PIPELINE_VIEWPORT_STATE_CREATE_INFO;
    std::vector<VkViewport> viewports;
    std::vector<VkRect2D> scissors;
    if (this->viewportState.viewports.size()>0) {
        for (auto & vp : this->viewportState.viewports) {
            VkViewport vkVport = {};
            vkVport.x = vp.x;
            vkVport.y = vp.y;
            vkVport.width = vp.width;
            vkVport.height = vp.height;
            vkVport.minDepth = vp.minDepth;
            vkVport.maxDepth = vp.maxDepth;
            viewports.push_back(vkVport);
        }
        viewportState.viewportCount = static_cast<uint32_t>(viewports.size());
        viewportState.pViewports = viewports.data();
    }
    if (this->viewportState.scissors.size()>0) {
        for (auto & sc : this->viewportState.scissors) {
            VkRect2D rect = {};
            rect.offset = { sc.offset.x, sc.offset.y };
            rect.extent = { sc.extent.width, sc.extent.height };
            scissors.push_back(rect);
        }
        viewportState.scissorCount = static_cast<uint32_t>(scissors.size());
        viewportState.pScissors = scissors.data();
    }
    
    VkPipelineRasterizationStateCreateInfo rasterizer = {};
    rasterizer.sType = VK_STRUCTURE_TYPE_PIPELINE_RASTERIZATION_STATE_CREATE_INFO;
	rasterizer.depthClampEnable = static_cast<VkBool32>(this->rasterizationState.depthClampEnable);
	rasterizer.rasterizerDiscardEnable = static_cast<VkBool32>(this->rasterizationState.rasterizerDiscardEnable);
    rasterizer.polygonMode = static_cast<VkPolygonMode>(this->rasterizationState.polygonMode);
    rasterizer.cullMode = static_cast<VkCullModeFlags>(this->rasterizationState.cullMode);
    rasterizer.frontFace = static_cast<VkFrontFace>(this->rasterizationState.frontFace);
	rasterizer.depthBiasEnable = static_cast<VkBool32>(this->rasterizationState.depthBiasEnable);
    rasterizer.depthBiasConstantFactor = this->rasterizationState.depthBiasConstantFactor;
    rasterizer.depthBiasClamp = this->rasterizationState.depthBiasClamp;
    rasterizer.depthBiasSlopeFactor = this->rasterizationState.depthBiasSlopeFactor;
    rasterizer.lineWidth = this->rasterizationState.lineWidth;
    
    VkPipelineMultisampleStateCreateInfo multisampling = {};
    multisampling.sType = VK_STRUCTURE_TYPE_PIPELINE_MULTISAMPLE_STATE_CREATE_INFO;
    multisampling.rasterizationSamples = static_cast<VkSampleCountFlagBits>(multisampleState.rasterizationSamples);
    multisampling.sampleShadingEnable = static_cast<VkBool32>(multisampleState.sampleShadingEnable);
    multisampling.minSampleShading = multisampleState.minSampleShading;
    multisampling.pSampleMask = multisampleState.pSampleMask;
    multisampling.alphaToCoverageEnable = static_cast<VkBool32>(multisampleState.alphaToCoverageEnable);
    multisampling.alphaToOneEnable = static_cast<VkBool32>(multisampleState.alphaToOneEnable);
    
    VkPipelineDepthStencilStateCreateInfo depthStencil = {};
    depthStencil.sType = VK_STRUCTURE_TYPE_PIPELINE_DEPTH_STENCIL_STATE_CREATE_INFO;
    depthStencil.depthTestEnable = depthStencilState.depthTestEnable;
    depthStencil.depthWriteEnable = depthStencilState.depthWriteEnable;
    depthStencil.depthCompareOp = static_cast<VkCompareOp>(depthStencilState.depthCompareOp);
    depthStencil.depthBoundsTestEnable = depthStencilState.depthBoundsTestEnable;
    depthStencil.stencilTestEnable = depthStencilState.stencilTestEnable;

    depthStencil.front.compareMask = depthStencilState.front.compareMask;
    depthStencil.front.failOp = static_cast<VkStencilOp>(depthStencilState.front.failOp);
    depthStencil.front.passOp = static_cast<VkStencilOp>(depthStencilState.front.passOp);
    depthStencil.front.depthFailOp = static_cast<VkStencilOp>(depthStencilState.front.depthFailOp);
    depthStencil.front.compareOp = static_cast<VkCompareOp>(depthStencilState.front.compareOp);
    depthStencil.front.compareMask = depthStencilState.front.compareMask;
    depthStencil.front.writeMask = depthStencilState.front.writeMask;
    depthStencil.front.reference = depthStencilState.front.reference;
    
    depthStencil.back.compareMask = depthStencilState.back.compareMask;
    depthStencil.back.failOp = static_cast<VkStencilOp>(depthStencilState.back.failOp);
    depthStencil.back.passOp = static_cast<VkStencilOp>(depthStencilState.back.passOp);
    depthStencil.back.depthFailOp = static_cast<VkStencilOp>(depthStencilState.back.depthFailOp);
    depthStencil.back.compareOp = static_cast<VkCompareOp>(depthStencilState.back.compareOp);
    depthStencil.back.compareMask = depthStencilState.back.compareMask;
    depthStencil.back.writeMask = depthStencilState.back.writeMask;
    depthStencil.back.reference = depthStencilState.back.reference;
    
    depthStencil.minDepthBounds = depthStencilState.minDepthBounds;
    depthStencil.maxDepthBounds = depthStencilState.maxDepthBounds;
    
    if (colorBlendState.attachments.size()==0) {
        colorBlendState.attachments.push_back(PipelineColorBlendAttachmentState());
    }
    std::vector<VkPipelineColorBlendAttachmentState> attachments;
    for (auto & att : colorBlendState.attachments) {
        VkPipelineColorBlendAttachmentState state;
        state.blendEnable = static_cast<VkBool32>(att.blendEnable);
        state.srcColorBlendFactor = static_cast<VkBlendFactor>(att.srcColorBlendFactor);
        state.dstColorBlendFactor = static_cast<VkBlendFactor>(att.dstColorBlendFactor);
        state.colorBlendOp = static_cast<VkBlendOp>(att.colorBlendOp);
        state.srcAlphaBlendFactor = static_cast<VkBlendFactor>(att.srcAlphaBlendFactor);
        state.dstAlphaBlendFactor = static_cast<VkBlendFactor>(att.dstAlphaBlendFactor);
        state.alphaBlendOp = static_cast<VkBlendOp>(att.alphaBlendOp);
        state.colorWriteMask = att.colorWriteMask;
        attachments.push_back(state);
    }
    VkPipelineColorBlendStateCreateInfo colorBlend = {};
    colorBlend.sType = VK_STRUCTURE_TYPE_PIPELINE_COLOR_BLEND_STATE_CREATE_INFO;
    colorBlend.logicOpEnable = static_cast<VkBool32>(colorBlendState.logicOpEnable);
    colorBlend.logicOp = static_cast<VkLogicOp>(colorBlendState.logicOp);
    colorBlend.attachmentCount = static_cast<uint32_t>(attachments.size());
    colorBlend.pAttachments = attachments.data();
    colorBlend.blendConstants[0] = colorBlendState.blendConstants[0];
    colorBlend.blendConstants[1] = colorBlendState.blendConstants[1];
    colorBlend.blendConstants[2] = colorBlendState.blendConstants[2];
    colorBlend.blendConstants[3] = colorBlendState.blendConstants[3];
    
    VkPipelineDynamicStateCreateInfo dynamicState = {};
    std::vector<VkDynamicState> dynamicStates;
    if (this->dynamicState.dynamicStates.size()>0) {
        for (auto ds : this->dynamicState.dynamicStates) {
            dynamicStates.push_back(static_cast<VkDynamicState>(ds));
        }
        dynamicState.dynamicStateCount = static_cast<uint32_t>(dynamicStates.size());
        dynamicState.pDynamicStates = dynamicStates.data();
    }
    
    if (_pipelineLayout.isNull()) {
        _pipelineLayout = new PipelineLayout();
        _pipelineLayout->create(dev);
    }
    if (_renderPass.isNull()) {
        throw bg::base::VulkanEngineException("Error creating Vulkan pipeline: no render pass specified.");
    }
    
    VkGraphicsPipelineCreateInfo pipelineInfo = {};
    pipelineInfo.sType = VK_STRUCTURE_TYPE_GRAPHICS_PIPELINE_CREATE_INFO;
    pipelineInfo.stageCount = static_cast<uint32_t>(shaderStages.size());
    pipelineInfo.pStages = shaderStages.data();
    pipelineInfo.pVertexInputState = &vertexInputInfo;
    pipelineInfo.pInputAssemblyState = &inputAssembly;
    pipelineInfo.pViewportState = &viewportState;

    // TODO: Create pipeline with this data
    if (dynamicState.dynamicStateCount>0) {
        // dynamicState
    }
    else {
        // nullptr
    }
    
    pipelineInfo.pRasterizationState = &rasterizer;
    pipelineInfo.pMultisampleState = &multisampling;
    pipelineInfo.pDepthStencilState = &depthStencil;
    pipelineInfo.pColorBlendState = &colorBlend;
    pipelineInfo.layout = bg::native_cast<VkPipelineLayout>(_pipelineLayout->vkPipelineLayout());
    pipelineInfo.renderPass = bg::native_cast<VkRenderPass>(_renderPass->vkRenderPass());
    pipelineInfo.subpass = _subpass;
    
    // TODO: Derive pipeline
    pipelineInfo.basePipelineHandle = nullptr;
    pipelineInfo.basePipelineIndex = 0;
    
    VkPipeline pipeline;
    if (vkCreateGraphicsPipelines(vkDev, VK_NULL_HANDLE, 1, &pipelineInfo, nullptr, &pipeline)!=VK_SUCCESS) {
        throw bg::base::VulkanEngineException("Could not create Vulkan pipeline.");
    }
    _vk_pipeline = pipeline;
}
/* End Pipeline */

/* Buffer */
const uint32_t BUFFER_USAGE_TRANSFER_SRC_BIT = VK_BUFFER_USAGE_TRANSFER_SRC_BIT;
const uint32_t BUFFER_USAGE_TRANSFER_DST_BIT = VK_BUFFER_USAGE_TRANSFER_DST_BIT;
const uint32_t BUFFER_USAGE_UNIFORM_TEXEL_BUFFER_BIT = VK_BUFFER_USAGE_UNIFORM_TEXEL_BUFFER_BIT;
const uint32_t BUFFER_USAGE_STORAGE_TEXEL_BUFFER_BIT = VK_BUFFER_USAGE_STORAGE_TEXEL_BUFFER_BIT;
const uint32_t BUFFER_USAGE_UNIFORM_BUFFER_BIT = VK_BUFFER_USAGE_UNIFORM_BUFFER_BIT;
const uint32_t BUFFER_USAGE_STORAGE_BUFFER_BIT = VK_BUFFER_USAGE_STORAGE_BUFFER_BIT;
const uint32_t BUFFER_USAGE_INDEX_BUFFER_BIT = VK_BUFFER_USAGE_INDEX_BUFFER_BIT;
const uint32_t BUFFER_USAGE_VERTEX_BUFFER_BIT = VK_BUFFER_USAGE_VERTEX_BUFFER_BIT;
const uint32_t BUFFER_USAGE_INDIRECT_BUFFER_BIT = VK_BUFFER_USAGE_INDIRECT_BUFFER_BIT;
const uint32_t BUFFER_USAGE_FLAG_BITS_MAX_ENUM = VK_BUFFER_USAGE_FLAG_BITS_MAX_ENUM;

Buffer::~Buffer() {
    if (_vk_buffer) {
        VkDevice dev = bg::native_cast<VkDevice>(_vk_device);
        VkBuffer buf = bg::native_cast<VkBuffer>(_vk_buffer);
        vkDestroyBuffer(dev, buf, nullptr);
        _vk_buffer = nullptr;
        _vk_device = nullptr;
    }
}

void Buffer::create(Device * dev) {
    VkDevice vkDev = bg::native_cast<VkDevice>(dev->vkDevice());
    _vk_device = vkDev;
    
    VkBufferCreateInfo info = {};
    info.sType = VK_STRUCTURE_TYPE_BUFFER_CREATE_INFO;
    info.size = createInfo.size;
    info.usage = static_cast<VkBufferUsageFlags>(createInfo.usage);
    info.sharingMode = static_cast<VkSharingMode>(createInfo.sharingMode);
    info.queueFamilyIndexCount = static_cast<uint32_t>(createInfo.queueFamilyIndices.size());
    info.pQueueFamilyIndices = createInfo.queueFamilyIndices.data();
    
    VkBuffer buffer;
    if (vkCreateBuffer(vkDev, &info, nullptr, &buffer)!=VK_SUCCESS) {
        throw bg::base::VulkanEngineException("Error creating Vulkan buffer.");
    }
    _vk_buffer = buffer;
}

void Buffer::getBufferMemoryRequirements(MemoryRequirements & result) {
    vkGetBufferMemoryRequirements(
        bg::native_cast<VkDevice>(_vk_device),
        bg::native_cast<VkBuffer>(_vk_buffer),
        reinterpret_cast<VkMemoryRequirements*>(&result));
}
/* End Buffer */

/* DeviceMemory */
DeviceMemory::DeviceMemory() {

}

DeviceMemory::~DeviceMemory() {
    if (_vk_deviceMemory) {
        VkDevice dev = bg::native_cast<VkDevice>(_vk_device);
        vkFreeMemory(dev, bg::native_cast<VkDeviceMemory>(_vk_deviceMemory), nullptr);
        _vk_device = nullptr;
        _vk_deviceMemory = nullptr;
    }
}

void DeviceMemory::allocateMemory(Device * dev) {
    VkDevice vkDev = bg::native_cast<VkDevice>(dev->vkDevice());
    _vk_device = vkDev;
    VkMemoryAllocateInfo allocInfo = {};
    allocInfo.sType = VK_STRUCTURE_TYPE_MEMORY_ALLOCATE_INFO;
    allocInfo.allocationSize = static_cast<VkDeviceSize>(allocateInfo.allocationSize);
    allocInfo.memoryTypeIndex = allocateInfo.memoryTypeIndex;
    VkDeviceMemory mem;
    if (vkAllocateMemory(vkDev, &allocInfo, nullptr, &mem)!=VK_SUCCESS) {
        throw bg::base::VulkanEngineException("Error allocating device memory.");
    }
    _vk_deviceMemory = mem;
}

void DeviceMemory::bindBufferMemory(Buffer * buffer, DeviceSize offset) {
    VkDevice dev = bg::native_cast<VkDevice>(_vk_device);
    VkDeviceMemory mem = bg::native_cast<VkDeviceMemory>(_vk_deviceMemory);
    VkBuffer vkBuffer = bg::native_cast<VkBuffer>(buffer->vkBuffer());
    vkBindBufferMemory(dev, vkBuffer, mem, offset);
}

void DeviceMemory::bindImageMemory(Image * image, DeviceSize offset) {
    VkDevice dev = bg::native_cast<VkDevice>(_vk_device);
    VkDeviceMemory mem = bg::native_cast<VkDeviceMemory>(_vk_deviceMemory);
    VkImage vkImage = bg::native_cast<VkImage>(image->vkImage());
    vkBindImageMemory(dev, vkImage, mem, offset);
}

void DeviceMemory::mapMemory(DeviceSize offset, DeviceSize size, MemoryMapFlags flags, void ** pData) {
    VkDevice dev = bg::native_cast<VkDevice>(_vk_device);
    VkDeviceMemory mem = bg::native_cast<VkDeviceMemory>(_vk_deviceMemory);
    vkMapMemory(dev, mem, offset, size, flags, pData);
}

void DeviceMemory::unmapMemory() {
    VkDevice dev = bg::native_cast<VkDevice>(_vk_device);
    VkDeviceMemory mem = bg::native_cast<VkDeviceMemory>(_vk_deviceMemory);
    vkUnmapMemory(dev, mem);
}
/* End DeviceMemory */
    
/* Framebuffer */
Framebuffer::~Framebuffer() {
    if (_vk_framebuffer) {
        VkDevice dev = bg::native_cast<VkDevice>(_vk_device);
        VkFramebuffer fb = bg::native_cast<VkFramebuffer>(_vk_framebuffer);
        vkDestroyFramebuffer(dev, fb, nullptr);
        _vk_framebuffer = nullptr;
        _vk_device = nullptr;
    }
}

void Framebuffer::create(Device * dev) {
    VkDevice vkDev = bg::native_cast<VkDevice>(dev->vkDevice());
    _vk_device = vkDev;
    
    VkFramebufferCreateInfo info = {};
    info.sType = VK_STRUCTURE_TYPE_FRAMEBUFFER_CREATE_INFO;
    info.renderPass = createInfo.renderPass.valid() ? bg::native_cast<VkRenderPass>(createInfo.renderPass->vkRenderPass()) : nullptr;
    std::vector<VkImageView> attachments;
    for (auto att : createInfo.attachments) {
        attachments.push_back(bg::native_cast<VkImageView>(att->vkImageView()));
    }
    if (attachments.size()>0) {
        info.attachmentCount = static_cast<uint32_t>(attachments.size());
        info.pAttachments = attachments.data();
    }
    info.width = createInfo.width;
    info.height = createInfo.height;
    info.layers = createInfo.layers;

    VkFramebuffer fb;
    if (vkCreateFramebuffer(vkDev, &info, nullptr, &fb)!=VK_SUCCESS) {
        throw bg::base::VulkanEngineException("Error creating Vulkan framebuffer.");
    }
    _vk_framebuffer = fb;
}
/* End Framebuffer */


/* CommandPool */
const uint32_t COMMAND_POOL_CREATE_TRANSIENT_BIT = VK_COMMAND_POOL_CREATE_TRANSIENT_BIT;
const uint32_t COMMAND_POOL_CREATE_RESET_COMMAND_BUFFER_BIT = VK_COMMAND_POOL_CREATE_RESET_COMMAND_BUFFER_BIT;
const uint32_t COMMAND_POOL_CREATE_PROTECTED_BIT = VK_COMMAND_POOL_CREATE_PROTECTED_BIT;
const uint32_t COMMAND_POOL_CREATE_FLAG_BITS_MAX_ENUM = VK_COMMAND_POOL_CREATE_FLAG_BITS_MAX_ENUM;

CommandPool::~CommandPool() {
    if (_vk_commandPool) {
        VkDevice dev = bg::native_cast<VkDevice>(_vk_device);
        VkCommandPool cp = bg::native_cast<VkCommandPool>(_vk_commandPool);
        vkDestroyCommandPool(dev, cp, nullptr);
        _vk_commandPool = nullptr;
        _vk_device = nullptr;
    }
}

void CommandPool::create(Device * dev) {
    VkDevice vkDev = bg::native_cast<VkDevice>(dev->vkDevice());
    _vk_device = vkDev;
    
    VkCommandPoolCreateInfo info = {};
    info.sType = VK_STRUCTURE_TYPE_COMMAND_POOL_CREATE_INFO;
	info.queueFamilyIndex = this->createInfo.queueFamilyIndex;
    info.flags = static_cast<VkCommandPoolCreateFlags>(this->createInfo.flags);
    VkCommandPool commandPool;
    if (vkCreateCommandPool(vkDev, &info, nullptr, &commandPool)!=VK_SUCCESS) {
        throw bg::base::VulkanEngineException("Error creating Vulkan command pool.");
    }
    _vk_commandPool = commandPool;
}
/* End CommandPool */

/* DescriptorPool */
DescriptorPool::~DescriptorPool() {
	if (_vk_descriptorPool) {
		vkDestroyDescriptorPool(bg::native_cast<VkDevice>(_vk_device), bg::native_cast<VkDescriptorPool>(_vk_descriptorPool), nullptr);
		_vk_descriptorPool = nullptr;
		_vk_device = nullptr;
	}
}

void DescriptorPool::create(Device * dev) {
	VkDevice vkDev = bg::native_cast<VkDevice>(dev->vkDevice());
	_vk_device = vkDev;
	VkDescriptorPool dp;

	VkDescriptorPoolCreateInfo info = {};
	info.sType = VK_STRUCTURE_TYPE_DESCRIPTOR_POOL_CREATE_INFO;
	std::vector<VkDescriptorPoolSize> poolSizes;
	for (auto s : createInfo.poolSizes) {
		VkDescriptorPoolSize vkSize = {};
		vkSize.descriptorCount = s.descriptorCount;
		vkSize.type = static_cast<VkDescriptorType>(s.type);
		poolSizes.push_back(vkSize);
	}
	info.maxSets = createInfo.maxSets;
	info.poolSizeCount = static_cast<uint32_t>(poolSizes.size());
	info.pPoolSizes = poolSizes.data();

	if (vkCreateDescriptorPool(vkDev, &info, nullptr, &dp) != VK_SUCCESS) {
		throw bg::base::VulkanEngineException("Could not create pool.");
	}
	_vk_descriptorPool = dp;
}
/* End DescriptorPool */

/* CommandBuffer */
const uint32_t COMMAND_BUFFER_LEVEL_PRIMARY = VK_COMMAND_BUFFER_LEVEL_PRIMARY;
const uint32_t COMMAND_BUFFER_LEVEL_SECONDARY = VK_COMMAND_BUFFER_LEVEL_SECONDARY;
const uint32_t COMMAND_BUFFER_LEVEL_BEGIN_RANGE = VK_COMMAND_BUFFER_LEVEL_BEGIN_RANGE;
const uint32_t COMMAND_BUFFER_LEVEL_END_RANGE = VK_COMMAND_BUFFER_LEVEL_END_RANGE;
const uint32_t COMMAND_BUFFER_LEVEL_RANGE_SIZE = VK_COMMAND_BUFFER_LEVEL_RANGE_SIZE;
const uint32_t COMMAND_BUFFER_LEVEL_MAX_ENUM = VK_COMMAND_BUFFER_LEVEL_MAX_ENUM;

const uint32_t COMMAND_BUFFER_USAGE_ONE_TIME_SUBMIT_BIT = VK_COMMAND_BUFFER_USAGE_ONE_TIME_SUBMIT_BIT;
const uint32_t COMMAND_BUFFER_USAGE_RENDER_PASS_CONTINUE_BIT = VK_COMMAND_BUFFER_USAGE_RENDER_PASS_CONTINUE_BIT;
const uint32_t COMMAND_BUFFER_USAGE_SIMULTANEOUS_USE_BIT = VK_COMMAND_BUFFER_USAGE_SIMULTANEOUS_USE_BIT;
const uint32_t COMMAND_BUFFER_USAGE_FLAG_BITS_MAX_ENUM = VK_COMMAND_BUFFER_USAGE_FLAG_BITS_MAX_ENUM;

const uint32_t QUERY_CONTROL_PRECISE_BIT = VK_QUERY_CONTROL_PRECISE_BIT;
const uint32_t QUERY_CONTROL_FLAG_BITS_MAX_ENUM = VK_QUERY_CONTROL_PRECISE_BIT;

const uint32_t QUERY_PIPELINE_STATISTIC_INPUT_ASSEMBLY_VERTICES_BIT = VK_QUERY_PIPELINE_STATISTIC_INPUT_ASSEMBLY_VERTICES_BIT;
const uint32_t QUERY_PIPELINE_STATISTIC_INPUT_ASSEMBLY_PRIMITIVES_BIT = VK_QUERY_PIPELINE_STATISTIC_INPUT_ASSEMBLY_PRIMITIVES_BIT;
const uint32_t QUERY_PIPELINE_STATISTIC_VERTEX_SHADER_INVOCATIONS_BIT = VK_QUERY_PIPELINE_STATISTIC_VERTEX_SHADER_INVOCATIONS_BIT;
const uint32_t QUERY_PIPELINE_STATISTIC_GEOMETRY_SHADER_INVOCATIONS_BIT = VK_QUERY_PIPELINE_STATISTIC_GEOMETRY_SHADER_INVOCATIONS_BIT;
const uint32_t QUERY_PIPELINE_STATISTIC_GEOMETRY_SHADER_PRIMITIVES_BIT = VK_QUERY_PIPELINE_STATISTIC_GEOMETRY_SHADER_PRIMITIVES_BIT;
const uint32_t QUERY_PIPELINE_STATISTIC_CLIPPING_INVOCATIONS_BIT = VK_QUERY_PIPELINE_STATISTIC_CLIPPING_INVOCATIONS_BIT;
const uint32_t QUERY_PIPELINE_STATISTIC_CLIPPING_PRIMITIVES_BIT = VK_QUERY_PIPELINE_STATISTIC_CLIPPING_PRIMITIVES_BIT;
const uint32_t QUERY_PIPELINE_STATISTIC_FRAGMENT_SHADER_INVOCATIONS_BIT = VK_QUERY_PIPELINE_STATISTIC_FRAGMENT_SHADER_INVOCATIONS_BIT;
const uint32_t QUERY_PIPELINE_STATISTIC_TESSELLATION_CONTROL_SHADER_PATCHES_BIT = VK_QUERY_PIPELINE_STATISTIC_TESSELLATION_CONTROL_SHADER_PATCHES_BIT;
const uint32_t QUERY_PIPELINE_STATISTIC_TESSELLATION_EVALUATION_SHADER_INVOCATIONS_BIT = VK_QUERY_PIPELINE_STATISTIC_TESSELLATION_EVALUATION_SHADER_INVOCATIONS_BIT;
const uint32_t QUERY_PIPELINE_STATISTIC_COMPUTE_SHADER_INVOCATIONS_BIT = VK_QUERY_PIPELINE_STATISTIC_COMPUTE_SHADER_INVOCATIONS_BIT;
const uint32_t QUERY_PIPELINE_STATISTIC_FLAG_BITS_MAX_ENUM = VK_QUERY_PIPELINE_STATISTIC_FLAG_BITS_MAX_ENUM;

const uint32_t SUBPASS_CONTENTS_INLINE = VK_SUBPASS_CONTENTS_INLINE;
const uint32_t SUBPASS_CONTENTS_SECONDARY_COMMAND_BUFFERS = VK_SUBPASS_CONTENTS_SECONDARY_COMMAND_BUFFERS;
const uint32_t SUBPASS_CONTENTS_BEGIN_RANGE = VK_SUBPASS_CONTENTS_BEGIN_RANGE;
const uint32_t SUBPASS_CONTENTS_END_RANGE = VK_SUBPASS_CONTENTS_END_RANGE;
const uint32_t SUBPASS_CONTENTS_RANGE_SIZE = VK_SUBPASS_CONTENTS_RANGE_SIZE;
const uint32_t SUBPASS_CONTENTS_MAX_ENUM = VK_SUBPASS_CONTENTS_MAX_ENUM;

const uint32_t COMMAND_BUFFER_RESET_RELEASE_RESOURCES_BIT = VK_COMMAND_BUFFER_RESET_RELEASE_RESOURCES_BIT;
const uint32_t COMMAND_BUFFER_RESET_FLAG_BITS_MAX_ENUM = VK_COMMAND_BUFFER_RESET_FLAG_BITS_MAX_ENUM;

const uint32_t INDEX_TYPE_UINT16 = VK_INDEX_TYPE_UINT16;
const uint32_t INDEX_TYPE_UINT32 = VK_INDEX_TYPE_UINT32;
const uint32_t INDEX_TYPE_BEGIN_RANGE = VK_INDEX_TYPE_BEGIN_RANGE;
const uint32_t INDEX_TYPE_END_RANGE = VK_INDEX_TYPE_END_RANGE;
const uint32_t INDEX_TYPE_RANGE_SIZE = VK_INDEX_TYPE_RANGE_SIZE;
const uint32_t INDEX_TYPE_MAX_ENUM = VK_INDEX_TYPE_MAX_ENUM;

CommandBuffer::CommandBuffer() {

}

CommandBuffer::~CommandBuffer() {
    _vk_commandBuffer = nullptr;
}

void CommandBuffer::Allocate(
    Device * dev,
    CommandPool * cp,
    CommandBufferLevel level,
    uint32_t commandBufferCount,
    std::vector<bg::ptr<CommandBuffer>> & result)
{
    VkDevice vkDev = bg::native_cast<VkDevice>(dev->vkDevice());
    
    VkCommandBufferAllocateInfo info = {};
    info.sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_ALLOCATE_INFO;
    info.commandPool = bg::native_cast<VkCommandPool>(cp->vkCommandPool());
    info.level = static_cast<VkCommandBufferLevel>(level);
    info.commandBufferCount = commandBufferCount;
    std::vector<VkCommandBuffer> buffers(commandBufferCount);
    if (vkAllocateCommandBuffers(vkDev, &info, buffers.data())!=VK_SUCCESS) {
        throw bg::base::VulkanEngineException("Error creating Vulkan command buffers.");
    }
    
    for (auto b : buffers) {
        CommandBuffer * buffer = new CommandBuffer();
        buffer->_vk_commandBuffer = b;
        result.push_back(buffer);
    }
}

void CommandBuffer::Allocate(
        Device * dev,
        CommandPool * cp,
        CommandBufferLevel level,
        bg::ptr<CommandBuffer> & result)
{
    std::vector<bg::ptr<CommandBuffer>> buffers;
    Allocate(dev, cp, level, 1, buffers);
    result = buffers[0];
}

void CommandBuffer::beginCommandBuffer(CommandBufferUsageFlags flags, CommandBufferInheritanceInfo * pInheritanceInfo) {
    VkCommandBufferBeginInfo beginInfo = {};
    beginInfo.sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_BEGIN_INFO;
    beginInfo.flags = static_cast<VkCommandBufferUsageFlags>(flags);
    VkCommandBufferInheritanceInfo inheritance;
    if (pInheritanceInfo) {
        inheritance.framebuffer = pInheritanceInfo->framebuffer ? bg::native_cast<VkFramebuffer>(pInheritanceInfo->framebuffer->vkFramebuffer()) : nullptr;
        inheritance.occlusionQueryEnable = static_cast<VkBool32>(pInheritanceInfo->occlusionQueryEnable);
        inheritance.pipelineStatistics = static_cast<VkQueryPipelineStatisticFlags>(pInheritanceInfo->pipelineStatistics);
        inheritance.queryFlags = static_cast<VkQueryControlFlags>(pInheritanceInfo->queryFlags);
        inheritance.subpass = pInheritanceInfo->subpass;
        inheritance.renderPass = pInheritanceInfo->renderPass ? bg::native_cast<VkRenderPass>(pInheritanceInfo->renderPass->vkRenderPass()) : nullptr;
        beginInfo.pInheritanceInfo = &inheritance;
    }
    
    if (vkBeginCommandBuffer(bg::native_cast<VkCommandBuffer>(_vk_commandBuffer), &beginInfo)!=VK_SUCCESS) {
        bg::log(bg::log::kWarning) << "CommandBuffer::beginCommandBuffer(): could not begin command buffer." << bg::endl;
    }
}

bool CommandBuffer::endCommandBuffer() {
	if (vkEndCommandBuffer(bg::native_cast<VkCommandBuffer>(_vk_commandBuffer)) != VK_SUCCESS) {
		bg::log(bg::log::kWarning) << "CommandBuffer::endCommandBuffer(): Error recording command buffer." << bg::endl;
		return false;
	}
	return true;
}

void CommandBuffer::resetCommandBuffer(CommandBufferResetFlags flags) {
    vkResetCommandBuffer(bg::native_cast<VkCommandBuffer>(_vk_commandBuffer), static_cast<VkCommandBufferResetFlags>(flags));
}

void CommandBuffer::cmdBeginRenderPass(RenderPass * rp, Framebuffer * fb, const Rect2D & area, const std::vector<vk::ClearValue> & clearValues, SubpassContents contents) {
	VkRenderPassBeginInfo info = {};
	info.sType = VK_STRUCTURE_TYPE_RENDER_PASS_BEGIN_INFO;
	info.renderPass = bg::native_cast<VkRenderPass>(rp->vkRenderPass());
	info.framebuffer = bg::native_cast<VkFramebuffer>(fb->vkFramebuffer());
	

    std::vector<VkClearValue> vkClearValues;
    //VkClearValue clearColor = {};
	//VkClearColorValue vkClearValue{ clearValue.r(), clearValue.g(), clearValue.b(), clearValue.a() };
	//clearColor.color = vkClearValue;
	for (auto & v : clearValues) {
		VkClearValue vkVal;
		vkVal.color.float32[0] = v.color.float32[0];
		vkVal.color.float32[1] = v.color.float32[1];
		vkVal.color.float32[2] = v.color.float32[2];
		vkVal.color.float32[3] = v.color.float32[3];
		vkClearValues.push_back(vkVal);
	}
	
	//std::array<VkClearValue, 2> vkClearValues;
	//vkClearValues[0].color = { 0.0f, 0.0f, 0.0f, 1.0f };
	//vkClearValues[1].depthStencil = { 1.0f, 0 };
	info.clearValueCount = static_cast<uint32_t>(vkClearValues.size());
	info.pClearValues = vkClearValues.data();

	info.renderArea.offset.x = area.offset.x;
	info.renderArea.offset.y = area.offset.y;
	info.renderArea.extent.width = area.extent.width;
	info.renderArea.extent.height = area.extent.height;

	vkCmdBeginRenderPass(bg::native_cast<VkCommandBuffer>(_vk_commandBuffer), &info, static_cast<VkSubpassContents>(contents));
}

void CommandBuffer::cmdBindPipeline(PipelineBindPoint bindPoint, Pipeline * pipeline) {
	vkCmdBindPipeline(bg::native_cast<VkCommandBuffer>(_vk_commandBuffer), static_cast<VkPipelineBindPoint>(bindPoint), bg::native_cast<VkPipeline>(pipeline->vkPipeline()));
}

void CommandBuffer::cmdDraw(uint32_t vertexCount, uint32_t instanceCount, uint32_t firstVertex, uint32_t firstInstance) {
	vkCmdDraw(bg::native_cast<VkCommandBuffer>(_vk_commandBuffer), vertexCount, instanceCount, firstVertex, firstInstance);
}

void CommandBuffer::cmdDrawIndexed(uint32_t indexCount, uint32_t instanceCount, uint32_t firstIndex, uint32_t vertexOffset, uint32_t firstInstance) {
    vkCmdDrawIndexed(bg::native_cast<VkCommandBuffer>(_vk_commandBuffer), indexCount, instanceCount, firstIndex, vertexOffset, firstInstance);
}

void CommandBuffer::cmdEndRenderPass() {
	vkCmdEndRenderPass(bg::native_cast<VkCommandBuffer>(_vk_commandBuffer));
}

void CommandBuffer::cmdBindVertexBuffers(uint32_t firstBinding, uint32_t bindingCount, const std::vector<Buffer*> & buffers, const std::vector<DeviceSize> & offsets) {
    std::vector<VkBuffer> vkBuffers;
    std::vector<VkDeviceSize> vkOffsets;
    for (auto b : buffers) {
        vkBuffers.push_back(bg::native_cast<VkBuffer>(b->vkBuffer()));
    }
    for (auto f : offsets) {
        vkOffsets.push_back(static_cast<VkDeviceSize>(f));
    }
    vkCmdBindVertexBuffers(bg::native_cast<VkCommandBuffer>(_vk_commandBuffer), firstBinding, bindingCount, vkBuffers.data(), vkOffsets.data());
}

void CommandBuffer::cmdCopyBuffer(vk::DeviceSize size, vk::Buffer * src, vk::Buffer * dst) {
    VkBufferCopy copyRegion = {};
    copyRegion.srcOffset = 0;
    copyRegion.dstOffset = 0;
    copyRegion.size = size;
    vkCmdCopyBuffer(bg::native_cast<VkCommandBuffer>(_vk_commandBuffer), bg::native_cast<VkBuffer>(src->vkBuffer()), bg::native_cast<VkBuffer>(dst->vkBuffer()), 1, &copyRegion);
}

void CommandBuffer::cmdBindIndexBuffer(vk::Buffer * buffer, vk::DeviceSize offset, vk::IndexType indexType) {
    vkCmdBindIndexBuffer(bg::native_cast<VkCommandBuffer>(_vk_commandBuffer), bg::native_cast<VkBuffer>(buffer->vkBuffer()), static_cast<VkDeviceSize>(offset), static_cast<VkIndexType>(indexType));
}

void CommandBuffer::cmdBindDescriptorSets(
	PipelineBindPoint pipelineBindPoint,
	PipelineLayout * pipelineLayout, 
	uint32_t firstSet, 
	const std::vector<DescriptorSet*> & descSet,
	std::vector<uint32_t> dynamicOffsets
	)
{
	std::vector<VkDescriptorSet> descriptorSets;
	for (auto & ds : descSet) {
		descriptorSets.push_back(bg::native_cast<VkDescriptorSet>(ds->vkDescriptorSet()));
	}
	vkCmdBindDescriptorSets(
		bg::native_cast<VkCommandBuffer>(_vk_commandBuffer),
		static_cast<VkPipelineBindPoint>(pipelineBindPoint),
		bg::native_cast<VkPipelineLayout>(pipelineLayout->vkPipelineLayout()),
		firstSet,
		static_cast<uint32_t>(descriptorSets.size()),
		descriptorSets.data(),
		static_cast<uint32_t>(dynamicOffsets.size()),
		dynamicOffsets.data()
	);
}

void CommandBuffer::cmdPipelineBarrier(PipelineStageFlags srcStageMask, PipelineStageFlags dstStageMask, DependencyFlags depFlags, const std::vector<MemoryBarrier> & memoryBarriers, const std::vector<BufferMemoryBarrier> & bufferMemoryBarriers, const std::vector<ImageMemoryBarrier> & imgMemoryBarriers) {
    std::vector<VkMemoryBarrier> vkMemoryBarriers;
    std::vector<VkBufferMemoryBarrier> vkBufferMemBarriers;
    std::vector<VkImageMemoryBarrier> vkImgMemoryBarriers;
    for (auto & b : memoryBarriers) {
        VkMemoryBarrier barr = {};
        barr.sType = VK_STRUCTURE_TYPE_MEMORY_BARRIER;
        barr.dstAccessMask = b.dstAccessMask;
        barr.srcAccessMask = b.srcAccessMask;
        vkMemoryBarriers.push_back(barr);
    }
    
    for (auto & b : bufferMemoryBarriers) {
        VkBufferMemoryBarrier barr = {};
        barr.sType = VK_STRUCTURE_TYPE_BUFFER_MEMORY_BARRIER;
        barr.dstAccessMask = b.dstAccessMask;
        barr.dstQueueFamilyIndex = b.dstQueueFamilyIndex;
        barr.offset = b.offset;
        barr.size = b.size;
        barr.srcAccessMask = b.srcAccessMask;
        barr.srcQueueFamilyIndex = b.srcQueueFamilyIndex;
        barr.buffer = b.buffer ? bg::native_cast<VkBuffer>(b.buffer->vkBuffer()) : VK_NULL_HANDLE;
        vkBufferMemBarriers.push_back(barr);
    }
    
    for (auto & b : imgMemoryBarriers) {
        VkImageMemoryBarrier barr = {};
        barr.sType = VK_STRUCTURE_TYPE_IMAGE_MEMORY_BARRIER;
        barr.srcAccessMask = b.srcAccessMask;
        barr.dstAccessMask = b.dstAccessMask;
        barr.oldLayout = static_cast<VkImageLayout>(b.oldLayout);
        barr.newLayout = static_cast<VkImageLayout>(b.newLayout);
        barr.srcQueueFamilyIndex = b.srcQueueFamilyIndex;
        barr.dstQueueFamilyIndex = b.dstQueueFamilyIndex;
        barr.image = b.image ? bg::native_cast<VkImage>(b.image->vkImage()) : VK_NULL_HANDLE;
        barr.subresourceRange.aspectMask = b.subresourceRange.aspectMask;
        barr.subresourceRange.baseMipLevel = b.subresourceRange.baseMipLevel;
        barr.subresourceRange.levelCount = b.subresourceRange.levelCount;
        barr.subresourceRange.baseArrayLayer = b.subresourceRange.baseArrayLayer;
        barr.subresourceRange.layerCount = b.subresourceRange.layerCount;
		vkImgMemoryBarriers.push_back(barr);
    }
    vkCmdPipelineBarrier(
        bg::native_cast<VkCommandBuffer>(_vk_commandBuffer),
        srcStageMask, dstStageMask, depFlags,
        static_cast<uint32_t>(vkMemoryBarriers.size()), vkMemoryBarriers.data(),
        static_cast<uint32_t>(vkBufferMemBarriers.size()), vkBufferMemBarriers.data(),
        static_cast<uint32_t>(vkImgMemoryBarriers.size()), vkImgMemoryBarriers.data());
}

void CommandBuffer::cmdCopyBufferToImage(vk::Buffer * buffer, vk::Image * image, ImageLayout dstImgLayout, const std::vector<BufferImageCopy> & regions) {
    std::vector<VkBufferImageCopy> vkRegions;
    for (auto r : regions) {
        VkBufferImageCopy region;
        region.bufferOffset = r.bufferOffset;
        region.bufferRowLength = r.bufferRowLength;
        region.bufferImageHeight = r.bufferImageHeight;
        region.imageSubresource.aspectMask = r.imageSubresource.aspectMask;
        region.imageSubresource.baseArrayLayer = r.imageSubresource.baseArrayLayer;
        region.imageSubresource.layerCount = r.imageSubresource.layerCount;
        region.imageSubresource.mipLevel = r.imageSubresource.mipLevel;
		region.imageOffset.x = r.imageOffset.x;
		region.imageOffset.y = r.imageOffset.y;
		region.imageOffset.z = r.imageOffset.z;
		region.imageExtent.width = r.imageExtent.width;
		region.imageExtent.height = r.imageExtent.height;
		region.imageExtent.depth = r.imageExtent.depth;
        vkRegions.push_back(region);
    }
    vkCmdCopyBufferToImage(
        bg::native_cast<VkCommandBuffer>(_vk_commandBuffer),
        bg::native_cast<VkBuffer>(buffer->vkBuffer()),
        bg::native_cast<VkImage>(image->vkImage()),
        static_cast<VkImageLayout>(dstImgLayout),
        static_cast<uint32_t>(vkRegions.size()), vkRegions.data());
}
/* CommandBuffer */

/* Semaphore */
Semaphore::~Semaphore() {
	if (_vk_semaphore) {
		VkDevice dev = bg::native_cast<VkDevice>(_vk_device);
		vkDestroySemaphore(dev, bg::native_cast<VkSemaphore>(_vk_semaphore), nullptr);
		_vk_device = nullptr;
		_vk_semaphore = nullptr;
	}
}

void Semaphore::create(Device * dev) {
	VkDevice vkDev = bg::native_cast<VkDevice>(dev->vkDevice());
	_vk_device = vkDev;
	VkSemaphoreCreateInfo info = {};
	info.sType = VK_STRUCTURE_TYPE_SEMAPHORE_CREATE_INFO;
	VkSemaphore sem;
	if (vkCreateSemaphore(vkDev, &info, nullptr, &sem) != VK_SUCCESS) {
		throw bg::base::VulkanEngineException("Could not create semaphore.");
	}
	_vk_semaphore = sem;
}

/* End Semaphore */

/* Fence */
Fence::Fence() {

}

Fence::Fence(Device * dev)
{
	create(dev);
}

Fence::~Fence() {
	if (_vk_fence) {
		VkDevice vkDev = bg::native_cast<VkDevice>(_vk_device);
		VkFence fence = bg::native_cast<VkFence>(_vk_fence);
		vkDestroyFence(vkDev, fence, nullptr);
		_vk_device = nullptr;
		_vk_fence = nullptr;
	}
}

void Fence::create(Device * dev) {
	VkDevice vkDev = bg::native_cast<VkDevice>(dev->vkDevice());
	VkFenceCreateInfo info = {};
	info.sType = VK_STRUCTURE_TYPE_FENCE_CREATE_INFO;
	info.flags = VK_FENCE_CREATE_SIGNALED_BIT;
	VkFence fence;
	if (vkCreateFence(vkDev, &info, nullptr, &fence) != VK_SUCCESS) {
		throw bg::base::VulkanEngineException("Could not create fence.");
	}
	_vk_fence = fence;
	_vk_device = vkDev;
}
/* End Fence */

}

}
}
}
